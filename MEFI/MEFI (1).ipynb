{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook aims to integrate individual-level BRFSS (Behavioral Risk Factor Surveillance System) data with MEFI (Metro Area Economic Freedom Index) data. It focuses on standardizing, cleaning, and mapping various years of BRFSS data (2007, 2008, 2012, 2017, 2022) to a common set of current CBSA (Core Based Statistical Area) codes, and then enriching this data with corresponding MEFI scores and population figures.\n",
        "\n",
        "For BRFSS data from 2007, 2008, and 2012, the mapping process involves several steps:\n",
        "\n",
        "County-level FIPS Codes: First, 5-digit county FIPS codes are constructed for each record, either directly from a 'COUNTY_FIPS' column or by combining separate state and county FIPS columns (_STATE and _CNTY).\n",
        "\n",
        "Raw CBSA Codes: The original CBSA codes from the BRFSS data (from columns like CBSA_CODE or _MMSA) are extracted and normalized.\n",
        "Legacy to Current Mapping: These raw CBSA codes are then attempted to be mapped to their current 2023 equivalents using a 'deterministic map' (det_map). This det_map was built by analyzing overlaps between an older OMB list (list1.xls, 2013-2020 vintage) and the newer 2023 OMB list (list1_2023.xlsx) at the county level. The det_map ensures that if an older CBSA code consistently maps to a single new CBSA code via county FIPS, that mapping is applied.\n",
        "\n",
        "County FIPS Fallback: If the raw CBSA code cannot be deterministically remapped, the system falls back to using the county FIPS code to directly look up the current CBSA code from the 2023 OMB list.\n",
        "\n",
        "Handling 'Outside CBSA': Throughout this process, any records explicitly marked as '99999' (indicating outside a CBSA) in the raw data are preserved as such. If, after all mapping attempts, a record's current CBSA code remains unassigned, it is also designated as '99999'.\n",
        "\n",
        "This multi-step approach ensures that even older BRFSS data, which might use outdated CBSA definitions, is accurately linked to the most current metropolitan area classifications and subsequently to the MEFI scores."
      ],
      "metadata": {
        "id": "rqo58joFBGE-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy8eZbKz-UMk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRxpw-zg-Y1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c851b36"
      },
      "source": [
        "# Task\n",
        "List the column names for each sheet in the Excel files \"DCI-2019-2023-Full-Dataset.xlsx\", \"DCI_datasets_longitudinal_zip_scores.xlsx\", \"list1_2023.xlsx\", \"'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx'\", and \"ZIP_TRACT_062025.xlsx\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ae4654"
      },
      "source": [
        "## Identify excel files\n",
        "\n",
        "### Subtask:\n",
        "List all Excel files to be processed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1a8b4d4"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a list of the specified Excel file paths and store it in the `excel_files` variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fdc519a"
      },
      "source": [
        "excel_files = [\n",
        "    \"/content/DCI-2019-2023-Full-Dataset.xlsx\",\n",
        "    \"/content/DCI_datasets_longitudinal_zip_scores.xlsx\",\n",
        "    \"/content/list1_2023.xlsx\",\n",
        "    \"/content/'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx'\",\n",
        "    \"/content/ZIP_TRACT_062025.xlsx\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e48c480"
      },
      "source": [
        "## Load and inspect each file\n",
        "\n",
        "### Subtask:\n",
        "For each Excel file, load it and check for multiple sheets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c977cd46"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the list of excel files, open each one, and print the sheet names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "f40b10c0",
        "outputId": "cb99fa99-8038-4520-c60c-660a380475a1"
      },
      "source": [
        "for file_path in excel_files:\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "    excel_file = pd.ExcelFile(file_path)\n",
        "    print(f\"Sheets: {excel_file.sheet_names}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/DCI-2019-2023-Full-Dataset.xlsx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2418008922.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcel_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing file: {file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mexcel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sheets: {excel_file.sheet_names}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ede3b8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the pandas library was not imported using the alias 'pd'. I need to regenerate the code block with the import statement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "l_x9sGqziZ5d",
        "outputId": "6447182d-de8f-49e1-d082-a9073f84a163"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "for file_path in excel_files:\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "    excel_file = pd.ExcelFile(file_path)\n",
        "    print(f\"Sheets: {excel_file.sheet_names}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/DCI-2019-2023-Full-Dataset.xlsx\n",
            "Sheets: ['Zips', 'Counties']\n",
            "Processing file: /content/DCI_datasets_longitudinal_zip_scores.xlsx\n",
            "Sheets: ['2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
            "Processing file: /content/list1_2023.xlsx\n",
            "Sheets: ['List 1']\n",
            "Processing file: /content/'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: \"/content/'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx'\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2946802387.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexcel_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing file: {file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mexcel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sheets: {excel_file.sheet_names}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"/content/'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx'\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50705606"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because there was a typo in the file path for one of the Excel files. I need to correct the file path and rerun the code to process all files and list their sheets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkGa8C_Jib7h",
        "outputId": "9a4cd076-0de0-48b1-ac6a-8c1575d3729d"
      },
      "source": [
        "excel_files = [\n",
        "    \"/content/DCI-2019-2023-Full-Dataset.xlsx\",\n",
        "    \"/content/DCI_datasets_longitudinal_zip_scores.xlsx\",\n",
        "    \"/content/list1_2023.xlsx\",\n",
        "    \"/content/MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx\",\n",
        "    \"/content/ZIP_TRACT_062025.xlsx\"\n",
        "]\n",
        "\n",
        "for file_path in excel_files:\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "    excel_file = pd.ExcelFile(file_path)\n",
        "    print(f\"Sheets: {excel_file.sheet_names}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/DCI-2019-2023-Full-Dataset.xlsx\n",
            "Sheets: ['Zips', 'Counties']\n",
            "Processing file: /content/DCI_datasets_longitudinal_zip_scores.xlsx\n",
            "Sheets: ['2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
            "Processing file: /content/list1_2023.xlsx\n",
            "Sheets: ['List 1']\n",
            "Processing file: /content/MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx\n",
            "Sheets: ['citation', 'Index Components', 'scores (panel)', 'scores', '1A', '1B', '1C', '2A', '2B', '2C', '3A', '3B', '3C', 'BEA']\n",
            "Processing file: /content/ZIP_TRACT_062025.xlsx\n",
            "Sheets: ['Export Worksheet', 'SQL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "602811e5"
      },
      "source": [
        "## Process each sheet\n",
        "\n",
        "### Subtask:\n",
        "For each sheet in the file, load it into a DataFrame and display the column names.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdc8bb0f"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through each Excel file and each sheet within the file to load the data into a DataFrame and display the column names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "850f0a77",
        "outputId": "d7450583-c7f6-498c-9283-e77de0e1548f"
      },
      "source": [
        "for file_path in excel_files:\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "    excel_file = pd.ExcelFile(file_path)\n",
        "    for sheet_name in excel_file.sheet_names:\n",
        "        # Special handling for the file with potential multi-level headers\n",
        "        if \"MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx\" in file_path:\n",
        "            try:\n",
        "                df = excel_file.parse(sheet_name, header=[0, 1])  # Attempt to load with 2 header rows\n",
        "                print(f\"  Sheet: {sheet_name}\")\n",
        "                print(f\"    Columns: {df.columns.tolist()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Sheet: {sheet_name}\")\n",
        "                print(f\"    Could not read with two header rows: {e}\")\n",
        "                # Fallback to single header row if reading with two fails\n",
        "                try:\n",
        "                    df = excel_file.parse(sheet_name)\n",
        "                    print(f\"    Columns (single header): {df.columns.tolist()}\")\n",
        "                except Exception as e_single:\n",
        "                     print(f\"    Could not read with single header row: {e_single}\")\n",
        "\n",
        "        else:\n",
        "            df = excel_file.parse(sheet_name)\n",
        "            print(f\"  Sheet: {sheet_name}\")\n",
        "            print(f\"    Columns: {df.columns.tolist()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/DCI-2019-2023-Full-Dataset.xlsx\n",
            "  Sheet: Zips\n",
            "    Columns: ['Zip Code', 'Metro area', 'City or town', 'County', 'Zip Code Type', 'State', 'State Abbreviation', 'Census Region', 'Total Population', '% of Adults w/o a High School Degree', 'Poverty Rate', '% of Prime Age Adults Not in Work', 'Vacancy Rate', 'Median Income Ratio', '% Change in Employment', '% Change in Establishments', '2019-2023 Distress Score', 'Quintile (5=Distressed)', 'Employment 2019', 'Employment 2023', 'Establishments 2019', 'Establishments 2023', 'Median Household Income', 'Non-Hispanic White % of Population', 'Hispanic or Latino % of Population', 'Black or African-American % of Population', 'American Indian or Alaska Native % of Population', 'Asian or Pacific Islander % of Population', 'Other Race or Two or More Races % of Population', '% of the Population Foreign-Born', '% of 25+ Population w/ a High School Diploma', '% of 25+ Population Some College', '% of 25+ Population w/ a Bachelors Degree or Higher']\n",
            "  Sheet: Counties\n",
            "    Columns: ['County ID', 'County', 'State', 'State Abbreviation', 'Census Region', 'County Type', 'MSA', 'Total Population', '% of Adults w/o a High School Degree', 'Poverty Rate', '% of Adults Not in Work', 'Housing Vacancy Rate', 'Median Income Ratio', '% Change in Employment', '% Change in Establishments', '2019-2023 Distress Score', 'Quintile (5=Distressed)', 'Employment 2019', 'Employment 2023', 'Establishments 2019', 'Establishments 2023', 'Median Household Income', 'Non-Hispanic White % of Population', 'Hispanic or Latino % of Population', 'Black or African-American % of Population', 'American Indian or Alaska Native % of Population', 'Asian or Pacific Islander % of Population', 'Other Race or Two or More Races % of Population', '% of the Population Foreign-Born', '% of 25+ Population w/ a High School Diploma', '% of 25+ Population Some College', '% of 25+ Population w/ a Bachelors Degree or Higher']\n",
            "Processing file: /content/DCI_datasets_longitudinal_zip_scores.xlsx\n",
            "  Sheet: 2013\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2014\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2015\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2016\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2017\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2018\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2019\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2020\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2021\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2022\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "  Sheet: 2023\n",
            "    Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
            "Processing file: /content/list1_2023.xlsx\n",
            "  Sheet: List 1\n",
            "    Columns: ['Table with row headers in column A and column headers in row 3', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
            "Processing file: /content/MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx\n",
            "  Sheet: citation\n",
            "    Columns: [('Please cite as:', 'Stansel, Dean. 2019. “Economic Freedom in U.S. Metropolitan Areas,” Journal of Regional Analysis and Policy, 49, 1, 40-48.')]\n",
            "  Sheet: Index Components\n",
            "    Columns: [('The Areas and Components of the U.S. Metro Area Economic Freedom Index', 'Unnamed: 0_level_1')]\n",
            "  Sheet: scores (panel)\n",
            "    Columns: [('MSA order', 1), ('CBSA Code', 10180), ('CBSA Code', 'Abilene, TX MSA'), ('Primary\\nState', 'Texas'), ('multi-state', 'Unnamed: 4_level_1'), ('year', 2017), ('Overall', 7.892122890680684), ('Area 1: Govern-ment Spending', 7.884566752643454), ('Area 2: Taxes', 7.291512333007934), ('Area 3: Labor Market Regulation', 8.500289586390663)]\n",
            "  Sheet: scores\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSA order'), ('Unnamed: 1_level_0', 'CBSA Code'), ('Unnamed: 2_level_0', 'CBSA Code'), ('Unnamed: 3_level_0', 'Primary\\nState'), ('Unnamed: 4_level_0', 'Area'), ('Unnamed: 5_level_0', '2017 population'), ('multi-state', 51), ('Overall', 2017), ('Overall', 2012), ('Overall', 2007), ('Overall', 2002), ('Overall', 1997), ('Overall', 1992), ('Overall', 1987), ('Overall', 1982), ('Overall', 1977), ('Overall', 1972), ('Overall', '1972.1'), ('Area 1: Government Spending', 2017), ('Area 1: Government Spending', 2012), ('Area 1: Government Spending', 2007), ('Area 1: Government Spending', 2002), ('Area 1: Government Spending', 1997), ('Area 1: Government Spending', 1992), ('Area 1: Government Spending', 1987), ('Area 1: Government Spending', 1982), ('Area 1: Government Spending', 1977), ('Area 1: Government Spending', 1972), ('Area 1: Government Spending', '1972.1'), ('Area 2: Taxes', 2017), ('Area 2: Taxes', 2012), ('Area 2: Taxes', 2007), ('Area 2: Taxes', 2002), ('Area 2: Taxes', 1997), ('Area 2: Taxes', 1992), ('Area 2: Taxes', 1987), ('Area 2: Taxes', 1982), ('Area 2: Taxes', 1977), ('Area 2: Taxes', 1972), ('Area 2: Taxes', '1972.1'), ('Area 3: Labor Market Regulation', 2017), ('Area 3: Labor Market Regulation', 2012), ('Area 3: Labor Market Regulation', 2007), ('Area 3: Labor Market Regulation', 2002), ('Area 3: Labor Market Regulation', 1997), ('Area 3: Labor Market Regulation', 1992), ('Area 3: Labor Market Regulation', 1987), ('Area 3: Labor Market Regulation', 1982), ('Area 3: Labor Market Regulation', 1977), ('Area 3: Labor Market Regulation', 1972)]\n",
            "  Sheet: 1A\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('1A (score)', 2017), ('1A (score)', 2012), ('1A (score)', 2007), ('1A (score)', 2002), ('1A (score)', 1997), ('1A (score)', 1992), ('1A (score)', 1987), ('1A (score)', 1982), ('1A (score)', 1977), ('1A (score)', 1972), ('1A (score)', '1972.1'), ('1a (rank)', 2017), ('1a (rank)', '2017.1'), ('1a (rank)', '2017.2'), ('1A, State & Local (% of personal income)', 2017), ('1A, State & Local (% of personal income)', 2012), ('1A, State & Local (% of personal income)', 2007), ('1A, State & Local (% of personal income)', 2002), ('1A, State & Local (% of personal income)', 1997), ('1A, State & Local (% of personal income)', 1992), ('1A, State & Local (% of personal income)', 1987), ('1A, State & Local (% of personal income)', 1982), ('1A, State & Local (% of personal income)', 1977), ('1A, State & Local (% of personal income)', 1972), ('1A, State & Local (% of personal income)', '1972.1'), ('1A ($1000s)', 2017), ('1A ($1000s)', 2012), ('1A ($1000s)', 2007), ('1A ($1000s)', 2002), ('1A ($1000s)', 1997), ('1A ($1000s)', 1992), ('1A ($1000s)', 1987), ('1A ($1000s)', 1982), ('1A ($1000s)', 1977), ('1A ($1000s)', 1972), ('1A ($1000s)', '1972.1'), ('1A (% of personal income)', 2017), ('1A (% of personal income)', 2012), ('1A (% of personal income)', 2007), ('1A (% of personal income)', 2002), ('1A (% of personal income)', 1997), ('1A (% of personal income)', 1992), ('1A (% of personal income)', 1987), ('1A (% of personal income)', 1982), ('1A (% of personal income)', 1977), ('1A (% of personal income)', 1972), ('1A (% of personal income)', '1972.1'), ('1A (% of personal income)', 'Metro Area'), ('1A (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
            "  Sheet: 1B\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('1B (score)', 2017), ('1B (score)', 2012), ('1B (score)', 2007), ('1B (score)', 2002), ('1B (score)', 1997), ('1B (score)', 1992), ('1B (score)', 1987), ('1B (score)', 1982), ('1B (score)', 1977), ('1B (score)', 1972), ('1B (score)', '1972.1'), ('1B (rank)', 2017), ('1B (rank)', '2017.1'), ('1B (rank)', '2017.2'), ('1B, State & Local (% of personal income)', 2017), ('1B, State & Local (% of personal income)', 2012), ('1B, State & Local (% of personal income)', 2007), ('1B, State & Local (% of personal income)', 2002), ('1B, State & Local (% of personal income)', 1997), ('1B, State & Local (% of personal income)', 1992), ('1B, State & Local (% of personal income)', 1987), ('1B, State & Local (% of personal income)', 1982), ('1B, State & Local (% of personal income)', 1977), ('1B, State & Local (% of personal income)', 1972), ('1B, State & Local (% of personal income)', '1972.1'), ('1B ($1000s)', 2017), ('1B ($1000s)', 2012), ('1B ($1000s)', 2007), ('1B ($1000s)', 2002), ('1B ($1000s)', 1997), ('1B ($1000s)', 1992), ('1B ($1000s)', 1987), ('1B ($1000s)', 1982), ('1B ($1000s)', 1977), ('1B ($1000s)', 1972), ('1B ($1000s)', '1972.1'), ('1B (% of personal income)', 2017), ('1B (% of personal income)', 2012), ('1B (% of personal income)', 2007), ('1B (% of personal income)', 2002), ('1B (% of personal income)', 1997), ('1B (% of personal income)', 1992), ('1B (% of personal income)', 1987), ('1B (% of personal income)', 1982), ('1B (% of personal income)', 1977), ('1B (% of personal income)', 1972), ('1B (% of personal income)', '1972.1'), ('1B (% of personal income)', 'Metro Area'), ('1B (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
            "  Sheet: 1C\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('1C (score)', 2017), ('1C (score)', 2012), ('1C (score)', 2007), ('1C (score)', 2002), ('1C (score)', 1997), ('1C (score)', 1992), ('1C (score)', 1987), ('1C (score)', 1982), ('1C (score)', 1977), ('1C (score)', 1972), ('1C (score)', '1972.1'), ('1C (rank)', 2017), ('1C (rank)', '2017.1'), ('1C (rank)', '2017.2'), ('1C, State & Local (% of personal income)', 2017), ('1C, State & Local (% of personal income)', 2012), ('1C, State & Local (% of personal income)', 2007), ('1C, State & Local (% of personal income)', 2002), ('1C, State & Local (% of personal income)', 1997), ('1C, State & Local (% of personal income)', 1992), ('1C, State & Local (% of personal income)', 1987), ('1C, State & Local (% of personal income)', 1982), ('1C, State & Local (% of personal income)', 1977), ('1C, State & Local (% of personal income)', 1972), ('1C, State & Local (% of personal income)', '1972.1'), ('1C ($1000s)', 2017), ('1C ($1000s)', 2012), ('1C ($1000s)', 2007), ('1C ($1000s)', 2002), ('1C ($1000s)', 1997), ('1C ($1000s)', 1992), ('1C ($1000s)', 1987), ('1C ($1000s)', 1982), ('1C ($1000s)', 1977), ('1C ($1000s)', 1972), ('1C ($1000s)', '1972.1'), ('1C (% of personal income)', 2017), ('1C (% of personal income)', 2012), ('1C (% of personal income)', 2007), ('1C (% of personal income)', 2002), ('1C (% of personal income)', 1997), ('1C (% of personal income)', 1992), ('1C (% of personal income)', 1987), ('1C (% of personal income)', 1982), ('1C (% of personal income)', 1977), ('1C (% of personal income)', 1972), ('1C (% of personal income)', '1972.1'), ('1C (% of personal income)', 'Metro Area'), ('1C (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
            "  Sheet: 2A\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('2A (score)', 2017), ('2A (score)', 2012), ('2A (score)', 2007), ('2A (score)', 2002), ('2A (score)', 1997), ('2A (score)', 1992), ('2A (score)', 1987), ('2A (score)', 1982), ('2A (score)', 1977), ('2A (score)', 1972), ('2A (score)', '1972.1'), ('2A (rank)', 2017), ('2A (rank)', '2017.1'), ('2A (rank)', '2017.2'), ('2A, State & Local (% of personal income)', 2017), ('2A, State & Local (% of personal income)', 2012), ('2A, State & Local (% of personal income)', 2007), ('2A, State & Local (% of personal income)', 2002), ('2A, State & Local (% of personal income)', 1997), ('2A, State & Local (% of personal income)', 1992), ('2A, State & Local (% of personal income)', 1987), ('2A, State & Local (% of personal income)', 1982), ('2A, State & Local (% of personal income)', 1977), ('2A, State & Local (% of personal income)', 1972), ('2A, State & Local (% of personal income)', '1972.1'), ('2A ($1000s)', 2017), ('2A ($1000s)', 2012), ('2A ($1000s)', 2007), ('2A ($1000s)', 2002), ('2A ($1000s)', 1997), ('2A ($1000s)', 1992), ('2A ($1000s)', 1987), ('2A ($1000s)', 1982), ('2A ($1000s)', 1977), ('2A ($1000s)', 1972), ('2A ($1000s)', '1972.1'), ('2A (% of personal income)', 2017), ('2A (% of personal income)', 2012), ('2A (% of personal income)', 2007), ('2A (% of personal income)', 2002), ('2A (% of personal income)', 1997), ('2A (% of personal income)', 1992), ('2A (% of personal income)', 1987), ('2A (% of personal income)', 1982), ('2A (% of personal income)', 1977), ('2A (% of personal income)', 1972), ('2A (% of personal income)', '1972.1'), ('2A (% of personal income)', 'Metro Area'), ('2A (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
            "  Sheet: 2B\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('2B (score)', 2017), ('2B (score)', 2012), ('2B (score)', 2007), ('2B (score)', 2002), ('2B (score)', 1997), ('2B (score)', 1992), ('2B (score)', 1987), ('2B (score)', 1982), ('2B (score)', 1977), ('2B (score)', 1972), ('2B (score)', '1972.1'), ('2B (rank)', 2017), ('2B (rank)', '2017.1'), ('2B (rank)', '2017.2'), ('2B, State & Local (% of personal income)', 2017), ('2B, State & Local (% of personal income)', 2012), ('2B, State & Local (% of personal income)', 2007), ('2B, State & Local (% of personal income)', 2002), ('2B, State & Local (% of personal income)', 1997), ('2B, State & Local (% of personal income)', 1992), ('2B, State & Local (% of personal income)', 1987), ('2B, State & Local (% of personal income)', 1982), ('2B, State & Local (% of personal income)', 1977), ('2B, State & Local (% of personal income)', 1972), ('2B, State & Local (% of personal income)', '1972.1'), ('2B ($1000s)', 2017), ('2B ($1000s)', 2012), ('2B ($1000s)', 2007), ('2B ($1000s)', 2002), ('2B ($1000s)', 1997), ('2B ($1000s)', 1992), ('2B ($1000s)', 1987), ('2B ($1000s)', 1982), ('2B ($1000s)', 1977), ('2B ($1000s)', 1972), ('2B ($1000s)', '1972.1'), ('2B (% of personal income)', 2017), ('2B (% of personal income)', 2012), ('2B (% of personal income)', 2007), ('2B (% of personal income)', 2002), ('2B (% of personal income)', 1997), ('2B (% of personal income)', 1992), ('2B (% of personal income)', 1987), ('2B (% of personal income)', 1982), ('2B (% of personal income)', 1977), ('2B (% of personal income)', 1972), ('2B (% of personal income)', '1972.1'), ('2B (% of personal income)', 'Metro Area'), ('2B (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
            "  Sheet: 2C\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('2C (score)', 2017), ('2C (score)', 2012), ('2C (score)', 2007), ('2C (score)', 2002), ('2C (score)', 1997), ('2C (score)', 1992), ('2C (score)', 1987), ('2C (score)', 1982), ('2C (score)', 1977), ('2C (score)', 1972), ('2C (score)', '1972.1'), ('2C (rank)', 2017), ('2C (rank)', '2017.1'), ('2C (rank)', '2017.2'), ('2C, State & Local (% of personal income)', 2017), ('2C, State & Local (% of personal income)', 2012), ('2C, State & Local (% of personal income)', 2007), ('2C, State & Local (% of personal income)', 2002), ('2C, State & Local (% of personal income)', 1997), ('2C, State & Local (% of personal income)', 1992), ('2C, State & Local (% of personal income)', 1987), ('2C, State & Local (% of personal income)', 1982), ('2C, State & Local (% of personal income)', 1977), ('2C, State & Local (% of personal income)', 1972), ('2C, State & Local (% of personal income)', '1972.1'), ('2C ($1000s)', 2017), ('2C ($1000s)', 2012), ('2C ($1000s)', 2007), ('2C ($1000s)', 2002), ('2C ($1000s)', 1997), ('2C ($1000s)', 1992), ('2C ($1000s)', 1987), ('2C ($1000s)', 1982), ('2C ($1000s)', 1977), ('2C ($1000s)', 1972), ('2C ($1000s)', '1972.1'), ('2C (% of personal income)', 2017), ('2C (% of personal income)', 2012), ('2C (% of personal income)', 2007), ('2C (% of personal income)', 2002), ('2C (% of personal income)', 1997), ('2C (% of personal income)', 1992), ('2C (% of personal income)', 1987), ('2C (% of personal income)', 1982), ('2C (% of personal income)', 1977), ('2C (% of personal income)', 1972), ('2C (% of personal income)', '1972.1'), ('2C (% of personal income)', 'Metro Area'), ('2C (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
            "  Sheet: 3A\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('3A (score)', 2017), ('3A (score)', 2012), ('3A (score)', 2007), ('3A (score)', 2002), ('3A (score)', 1997), ('3A (score)', 1992), ('3A (score)', 1987), ('3A (score)', 1982), ('3A (score)', 1977), ('3A (score)', 1972), ('3A (score)', '1972.1'), ('3A (rank)', 2017), ('3A (rank)', '2017.1'), ('3A (rank)', '2017.2'), ('Minimum Wage, full-time income, % of per capita personal income', 2017), ('Minimum Wage, full-time income, % of per capita personal income', 2012), ('Minimum Wage, full-time income, % of per capita personal income', 2007), ('Minimum Wage, full-time income, % of per capita personal income', 2002), ('Minimum Wage, full-time income, % of per capita personal income', 1997), ('Minimum Wage, full-time income, % of per capita personal income', 1992), ('Minimum Wage, full-time income, % of per capita personal income', 1987), ('Minimum Wage, full-time income, % of per capita personal income', 1982), ('Minimum Wage, full-time income, % of per capita personal income', 1977), ('Minimum Wage, full-time income, % of per capita personal income', 1972), ('Minimum Wage, full-time income, % of per capita personal income', '1972.1'), ('Minimum Wage, full-time income, % of per capita personal income', 'Metro Area'), ('Minimum Wage, full-time income, % of per capita personal income', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('Minimum Wage, full-time income', 2017), ('Minimum Wage, full-time income', 2012), ('Minimum Wage, full-time income', 2007), ('Minimum Wage, full-time income', 2002), ('Minimum Wage, full-time income', 1997), ('Minimum Wage, full-time income', 1992), ('Minimum Wage, full-time income', 1987), ('Minimum Wage, full-time income', 1982), ('Minimum Wage, full-time income', 1977), ('Minimum Wage, full-time income', 1972)]\n",
            "  Sheet: 3B\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('3B (score)', 2017), ('3B (score)', 2012), ('3B (score)', 2007), ('3B (score)', 2002), ('3B (score)', 1997), ('3B (score)', 1992), ('3B (score)', 1987), ('3B (score)', 1982), ('3B (score)', 1977), ('3B (score)', 1972), ('3B (score)', '1972.1'), ('3B (rank)', 2017), ('3B (rank)', '2017.1'), ('3B (rank)', '2017.2'), ('3B, State & Local (% of total employment)', 2017), ('3B, State & Local (% of total employment)', 2012), ('3B, State & Local (% of total employment)', 2007), ('3B, State & Local (% of total employment)', 2002), ('3B, State & Local (% of total employment)', 1997), ('3B, State & Local (% of total employment)', 1992), ('3B, State & Local (% of total employment)', 1987), ('3B, State & Local (% of total employment)', 1982), ('3B, State & Local (% of total employment)', 1977), ('3B, State & Local (% of total employment)', 1972), ('3B, State & Local (% of total employment)', '1972.1'), ('3B (# of local emps)', 2017), ('3B (# of local emps)', 2012), ('3B (# of local emps)', 2007), ('3B (# of local emps)', 2002), ('3B (# of local emps)', 1997), ('3B (# of local emps)', 1992), ('3B (# of local emps)', 1987), ('3B (# of local emps)', 1982), ('3B (# of local emps)', 1977), ('3B (# of local emps)', 1972), ('3B (# of local emps)', '1972.1'), ('3B (local govt % of total emp)', 2017), ('3B (local govt % of total emp)', 2012), ('3B (local govt % of total emp)', 2007), ('3B (local govt % of total emp)', 2002), ('3B (local govt % of total emp)', 1997), ('3B (local govt % of total emp)', 1992), ('3B (local govt % of total emp)', 1987), ('3B (local govt % of total emp)', 1982), ('3B (local govt % of total emp)', 1977), ('3B (local govt % of total emp)', 1972), ('3B (local govt % of total emp)', '2012 rank'), ('3B (local govt % of total emp)', '2012 rank.1'), ('3B (local govt % of total emp)', 'Metro Area'), ('3B (local govt % of total emp)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State govt emps (% of total state employment)', 2017), ('State govt emps (% of total state employment)', 2012), ('State govt emps (% of total state employment)', 2007), ('State govt emps (% of total state employment)', 2002), ('State govt emps (% of total state employment)', 1997), ('State govt emps (% of total state employment)', 1992), ('State govt emps (% of total state employment)', 1987), ('State govt emps (% of total state employment)', 1982), ('State govt emps (% of total state employment)', 1977), ('State govt emps (% of total state employment)', 1972)]\n",
            "  Sheet: 3C\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('3C (score)', 2017), ('3C (score)', 2012), ('3C (score)', 2007), ('3C (score)', 2002), ('3C (score)', 1997), ('3C (score)', 1992), ('3C (score)', 1987), ('3C (score)', 1982), ('3C (score)', 1977), ('3C (score)', 1972), ('3C (score)', '1972.1'), ('3C (rank)', 2017), ('3C (rank)', '2017.1'), ('3C (rank)', '2017.2'), ('Union Density, % members, private employees', 2017), ('Union Density, % members, private employees', 2012), ('Union Density, % members, private employees', 2007), ('Union Density, % members, private employees', 2002), ('Union Density, % members, private employees', 1997), ('Union Density, % members, private employees', 1992), ('Union Density, % members, private employees', 1987), ('Union Density, % members, private employees', 1982), ('Union Density, % members, private employees', 1977), ('Union Density, % members, private employees', 1972), ('Union Density, % members, private employees', '1972.1'), ('Union Density, % members, private employees', 'Metro Area'), ('Union Density, % members, private employees', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('Union Density, % members, private employees', 'Unnamed: 43_level_1'), ('Union Density, % members, private employees', '2017.1'), ('Union Density, % members, private employees', '2012.1'), ('Union Density, % members, private employees', '2007.1'), ('Union Density, % members, private employees', '2002.1'), ('Union Density, % members, private employees', '1997.1'), ('Union Density, % members, private employees', '1992.1'), ('Union Density, % members, private employees', '1987.1'), ('Union Density, % members, private employees', '1982.1'), ('Union Density, % members, private employees', '1977.1'), ('Union Density, % members, private employees', '1972.2')]\n",
            "  Sheet: BEA\n",
            "    Columns: [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('Personal income (thousands of dollars)', '2017'), ('Personal income (thousands of dollars)', '2012'), ('Personal income (thousands of dollars)', '2007'), ('Personal income (thousands of dollars)', '2002'), ('Personal income (thousands of dollars)', 1997), ('Personal income (thousands of dollars)', 1992), ('Personal income (thousands of dollars)', 1987), ('Personal income (thousands of dollars)', 1982), ('Personal income (thousands of dollars)', 1977), ('Personal income (thousands of dollars)', 1972), ('Personal income (thousands of dollars)', '1972.1'), ('Total employment', '2017'), ('Total employment', 2012), ('Total employment', 2007), ('Total employment', 2002), ('Total employment', 1997), ('Total employment', 1992), ('Total employment', 1987), ('Total employment', 1982), ('Total employment', 1977), ('Total employment', 1972), ('Total employment', '1972.1'), ('Total population', '2017'), ('Total population', '2012'), ('Total population', 2007), ('Total population', 2002), ('Total population', 1997), ('Total population', 1992), ('Total population', 1987), ('Total population', 1982), ('Total population', 1977), ('Total population', 1972)]\n",
            "Processing file: /content/ZIP_TRACT_062025.xlsx\n",
            "  Sheet: Export Worksheet\n",
            "    Columns: ['ZIP', 'TRACT', 'USPS_ZIP_PREF_CITY', 'USPS_ZIP_PREF_STATE', 'RES_RATIO', 'BUS_RATIO', 'OTH_RATIO', 'TOT_RATIO']\n",
            "  Sheet: SQL\n",
            "    Columns: ['Unnamed: 0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5055ada7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The analysis successfully identified and listed the column names for each sheet across all five specified Excel files: \"DCI-2019-2023-Full-Dataset.xlsx\", \"DCI\\_datasets\\_longitudinal\\_zip\\_scores.xlsx\", \"list1\\_2023.xlsx\", \"'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx'\", and \"ZIP\\_TRACT\\_062025.xlsx\".\n",
        "*   The file \"DCI-2019-2023-Full-Dataset.xlsx\" contains sheets named \"Zips\" and \"Counties\" with columns related to demographic and economic indicators at the zip and county levels, respectively.\n",
        "*   The file \"DCI\\_datasets\\_longitudinal\\_zip\\_scores.xlsx\" includes sheets for each year from 2013 to 2023, each with columns for ZCTA, FIPS codes, Total Population, Distress Score, and Quintile.\n",
        "*   The file \"list1\\_2023.xlsx\" has a sheet named \"List 1\" which appears to have header issues based on the presence of many \"Unnamed\" columns.\n",
        "*   The file \"'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx'\" contains multiple sheets with column names related to economic freedom index components and scores. Several sheets also contain \"Unnamed\" columns, suggesting potential multi-level headers or introductory text.\n",
        "*   The file \"ZIP\\_TRACT\\_062025.xlsx\" includes an \"Export Worksheet\" sheet mapping ZIP codes to TRACTs and ratio data, as well as a \"SQL\" sheet with a single \"Unnamed: 0\" column.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Further investigation is needed for files with \"Unnamed\" columns to correctly identify the data headers and structure.\n",
        "*   Cleaning and preparing the data from these files, especially addressing header issues, will be necessary before any further analysis can be performed.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/SMART_2007_individual.csv')\n",
        "print('/content/SMART_2007_individual.csv')\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DudPgYgVjU7i",
        "outputId": "2aa716e4-fc11-418a-d2b2-c0d346121ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SMART_2007_individual.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CHILDREN', 'MARITAL', 'PREGNANT', 'EMPLOY1', '_EDUCAG', '_INCOMG1',\n",
              "       '_AGEG5YR', '_AGEG65YR', '_RACEG22', '_RACEGR4', '_HLTHPLN', 'SEXVAR',\n",
              "       'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', '_RFHLTH', 'BMI_RAW',\n",
              "       'BMI_CATEGORY', 'EXERCISE_30D', '_STATE', '_CNTY', '_WT2', '_CNTYWT',\n",
              "       '_STSTR', '_PSU', 'COUNTY_FIPS', 'CBSA_CODE', 'CBSA_NAME', 'YEAR'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-e2FbG6jjUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f751e2a"
      },
      "source": [
        "# Task\n",
        "List all CSV files in the working directory and print their column names. Additionally, copy all files from the working directory to a new directory named \"Saksham_MEFI\" in Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72465f7a"
      },
      "source": [
        "## List csv files\n",
        "\n",
        "### Subtask:\n",
        "Identify all CSV files in the working directory and print their paths.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dacb12ef"
      },
      "source": [
        "**Reasoning**:\n",
        "Identify all CSV files in the working directory and print their paths.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6e95ead",
        "outputId": "5bb6df28-dfe5-4399-fa0c-1d4c4c3204b0"
      },
      "source": [
        "import os\n",
        "\n",
        "# List all files in the current working directory\n",
        "files_in_directory = os.listdir('.')\n",
        "\n",
        "# Iterate through the files and print the full path of CSV files\n",
        "for file_name in files_in_directory:\n",
        "    if file_name.endswith('.csv'):\n",
        "        print(os.path.join('.', file_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./SMART_2007_individual.csv\n",
            "./SMART_2022_individual.csv\n",
            "./SMART_2017_individual.csv\n",
            "./SMART_2012_individual.csv\n",
            "./SMART_2008_individual.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ab54cfc"
      },
      "source": [
        "## Get columns for each csv\n",
        "\n",
        "### Subtask:\n",
        "Load each identified CSV file and print its column names.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e3f096d"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the list of CSV files and print the column names for each.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79429485",
        "outputId": "91f78f6d-43b1-40cb-f6ef-79cc8fbd5d01"
      },
      "source": [
        "csv_files = [\n",
        "    './SMART_2007_individual.csv',\n",
        "    './SMART_2022_individual.csv',\n",
        "    './SMART_2017_individual.csv',\n",
        "    './SMART_2012_individual.csv',\n",
        "    './SMART_2008_individual.csv'\n",
        "]\n",
        "\n",
        "for file_path in csv_files:\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Columns: {df.columns.tolist()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read file: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: ./SMART_2007_individual.csv\n",
            "Columns: ['CHILDREN', 'MARITAL', 'PREGNANT', 'EMPLOY1', '_EDUCAG', '_INCOMG1', '_AGEG5YR', '_AGEG65YR', '_RACEG22', '_RACEGR4', '_HLTHPLN', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', '_RFHLTH', 'BMI_RAW', 'BMI_CATEGORY', 'EXERCISE_30D', '_STATE', '_CNTY', '_WT2', '_CNTYWT', '_STSTR', '_PSU', 'COUNTY_FIPS', 'CBSA_CODE', 'CBSA_NAME', 'YEAR']\n",
            "Processing file: ./SMART_2022_individual.csv\n",
            "Columns: ['MMSANAME', 'CHILDREN', 'MARITAL', 'PREGNANT', 'EMPLOY1', '_EDUCAG', '_INCOMG1', '_AGEG5YR', '_AGEG65YR', '_RACEG22', '_RACEGR4', '_PHYS14D', '_MENT14D', '_HLTHPLN', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', '_RFHLTH', 'BMI_RAW', 'BMI_CATEGORY', 'EXERCISE_30D', '_MMSA', '_MMSAWT', '_STSTR', 'COUNTY_FIPS', 'CBSA_CODE', 'CBSA_NAME', 'YEAR']\n",
            "Processing file: ./SMART_2017_individual.csv\n",
            "Columns: ['MMSANAME', 'CHILDREN', 'MARITAL', 'PREGNANT', 'EMPLOY1', '_EDUCAG', '_INCOMG1', '_AGEG5YR', '_AGEG65YR', '_RACEG22', '_RACEGR4', '_PHYS14D', '_MENT14D', '_HLTHPLN', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', '_RFHLTH', 'BMI_RAW', 'BMI_CATEGORY', 'EXERCISE_30D', '_MMSA', '_MMSAWT', '_STSTR', 'COUNTY_FIPS', 'CBSA_CODE', 'CBSA_NAME', 'YEAR']\n",
            "Processing file: ./SMART_2012_individual.csv\n",
            "Columns: ['CHILDREN', 'MARITAL', 'PREGNANT', 'EMPLOY1', '_EDUCAG', '_INCOMG1', '_AGEG5YR', '_AGEG65YR', '_RACEG22', '_RACEGR4', '_HLTHPLN', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', '_RFHLTH', 'BMI_RAW', 'BMI_CATEGORY', 'EXERCISE_30D', '_STATE', '_CNTY', '_CNTYWT', '_STSTR', '_PSU', 'COUNTY_FIPS', 'CBSA_CODE', 'CBSA_NAME', 'YEAR']\n",
            "Processing file: ./SMART_2008_individual.csv\n",
            "Columns: ['CHILDREN', 'MARITAL', 'PREGNANT', 'EMPLOY1', '_EDUCAG', '_INCOMG1', '_AGEG5YR', '_AGEG65YR', '_RACEG22', '_RACEGR4', '_HLTHPLN', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', '_RFHLTH', 'BMI_RAW', 'BMI_CATEGORY', 'EXERCISE_30D', '_STATE', '_CNTY', '_WT2', '_CNTYWT', '_STSTR', '_PSU', 'COUNTY_FIPS', 'CBSA_CODE', 'CBSA_NAME', 'YEAR']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a90fc56f"
      },
      "source": [
        "## Consolidated Column Names\n",
        "\n",
        "This section provides a consolidated list of column names from all the processed Excel and CSV files.\n",
        "\n",
        "**Excel Files:**\n",
        "\n",
        "*   **DCI-2019-2023-Full-Dataset.xlsx**\n",
        "    *   **Sheet: Zips**\n",
        "        *   Columns: ['Zip Code', 'Metro area', 'City or town', 'County', 'Zip Code Type', 'State', 'State Abbreviation', 'Census Region', 'Total Population', '% of Adults w/o a High School Degree', 'Poverty Rate', '% of Prime Age Adults Not in Work', 'Vacancy Rate', 'Median Income Ratio', '% Change in Employment', '% Change in Establishments', '2019-2023 Distress Score', 'Quintile (5=Distressed)', 'Employment 2019', 'Employment 2023', 'Establishments 2019', 'Establishments 2023', 'Median Household Income', 'Non-Hispanic White % of Population', 'Hispanic or Latino % of Population', 'Black or African-American % of Population', 'American Indian or Alaska Native % of Population', 'Asian or Pacific Islander % of Population', 'Other Race or Two or More Races % of Population', '% of the Population Foreign-Born', '% of 25+ Population w/ a High School Diploma', '% of 25+ Population Some College', '% of 25+ Population w/ a Bachelors Degree or Higher']\n",
        "    *   **Sheet: Counties**\n",
        "        *   Columns: ['County ID', 'County', 'State', 'State Abbreviation', 'Census Region', 'County Type', 'MSA', 'Total Population', '% of Adults w/o a High School Degree', 'Poverty Rate', '% of Adults Not in Work', 'Housing Vacancy Rate', 'Median Income Ratio', '% Change in Employment', '% Change in Establishments', '2019-2023 Distress Score', 'Quintile (5=Distressed)', 'Employment 2019', 'Employment 2023', 'Establishments 2019', 'Establishments 2023', 'Median Household Income', 'Non-Hispanic White % of Population', 'Hispanic or Latino % of Population', 'Black or African-American % of Population', 'American Indian or Alaska Native % of Population', 'Asian or Pacific Islander % of Population', 'Other Race or Two or More Races % of Population', '% of the Population Foreign-Born', '% of 25+ Population w/ a High School Diploma', '% of 25+ Population Some College', '% of 25+ Population w/ a Bachelors Degree or Higher']\n",
        "\n",
        "*   **DCI_datasets_longitudinal_zip_scores.xlsx**\n",
        "    *   Sheets: '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023'\n",
        "    *   Common Columns: ['ZCTA', 'State FIPS', 'County FIPS', 'Total Population', 'Distress Score', 'Quintile (5=Distressed)']\n",
        "    *   *Note: All yearly sheets in this file have the same column structure.*\n",
        "\n",
        "*   **list1_2023.xlsx**\n",
        "    *   **Sheet: List 1**\n",
        "        *   Columns: ['Table with row headers in column A and column headers in row 3', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11']\n",
        "        *   *Note: This sheet appears to have header issues with many 'Unnamed' columns.*\n",
        "\n",
        "*   **MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx**\n",
        "    *   **Sheet: citation**\n",
        "        *   Columns: [('Please cite as:', 'Stansel, Dean. 2019. “Economic Freedom in U.S. Metropolitan Areas,” Journal of Regional Analysis and Policy, 49, 1, 40-48.')]\n",
        "    *   **Sheet: Index Components**\n",
        "        *   Columns: [('The Areas and Components of the U.S. Metro Area Economic Freedom Index', 'Unnamed: 0_level_1')]\n",
        "    *   **Sheet: scores (panel)**\n",
        "        *   Columns: [('MSA order', 1), ('CBSA Code', 10180), ('CBSA Code', 'Abilene, TX MSA'), ('Primary\\nState', 'Texas'), ('multi-state', 'Unnamed: 4_level_1'), ('year', 2017), ('Overall', 7.892122890680684), ('Area 1: Govern-ment Spending', 7.884566752643454), ('Area 2: Taxes', 7.291512333007934), ('Area 3: Labor Market Regulation', 8.500289586390663)]\n",
        "    *   **Sheet: scores**\n",
        "        *   Columns: [('Unnamed: 0_level_0', 'MSA order'), ('Unnamed: 1_level_0', 'CBSA Code'), ('Unnamed: 2_level_0', 'CBSA Code'), ('Unnamed: 3_level_0', 'Primary\\nState'), ('Unnamed: 4_level_0', 'Area'), ('Unnamed: 5_level_0', '2017 population'), ('multi-state', 51), ('Overall', 2017), ('Overall', 2012), ('Overall', 2007), ('Overall', 2002), ('Overall', 1997), ('Overall', 1992), ('Overall', 1987), ('Overall', 1982), ('Overall', 1977), ('Overall', 1972), ('Overall', '1972.1'), ('Area 1: Government Spending', 2017), ('Area 1: Government Spending', 2012), ('Area 1: Government Spending', 2007), ('Area 1: Government Spending', 2002), ('Area 1: Government Spending', 1997), ('Area 1: Government Spending', 1992), ('Area 1: Government Spending', 1987), ('Area 1: Government Spending', 1982), ('Area 1: Government Spending', 1977), ('Area 1: Government Spending', 1972), ('Area 2: Taxes', 2017), ('Area 2: Taxes', 2012), ('Area 2: Taxes', 2007), ('Area 2: Taxes', 2002), ('Area 2: Taxes', 1997), ('Area 2: Taxes', 1992), ('Area 2: Taxes', 1987), ('Area 2: Taxes', 1982), ('Area 2: Taxes', 1977), ('Area 2: Taxes', 1972), ('Area 3: Labor Market Regulation', 2017), ('Area 3: Labor Market Regulation', 2012), ('Area 3: Labor Market Regulation', 2007), ('Area 3: Labor Market Regulation', 2002), ('Area 3: Labor Market Regulation', 1997), ('Area 3: Labor Market Regulation', 1992), ('Area 3: Labor Market Regulation', 1987), ('Area 3: Labor Market Regulation', 1982), ('Area 3: Labor Market Regulation', 1977), ('Area 3: Labor Market Regulation', 1972)]\n",
        "    *   **Sheet: 1A**\n",
        "        *   Columns (Partial list due to length and multi-level headers): [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('1A (score)', 2017), ('1A (score)', 2012), ('1A (score)', 2007), ('1A (score)', 2002), ('1A (score)', 1997), ('1A (score)', 1992), ('1A (score)', 1987), ('1A (score)', 1982), ('1A (score)', 1977), ('1A (score)', 1972), ('1A (score)', '1972.1'), ('1a (rank)', 2017), ('1a (rank)', '2017.1'), ('1a (rank)', '2017.2'), ('1A, State & Local (% of personal income)', 2017), ('1A, State & Local (% of personal income)', 2012), ('1A, State & Local (% of personal income)', 2007), ('1A, State & Local (% of personal income)', 2002), ('1A, State & Local (% of personal income)', 1997), ('1A, State & Local (% of personal income)', 1992), ('1A, State & Local (% of personal income)', 1987), ('1A, State & Local (% of personal income)', 1982), ('1A, State & Local (% of personal income)', 1977), ('1A, State & Local (% of personal income)', 1972), ('1A, State & Local (% of personal income)', '1972.1'), ('1A ($1000s)', 2017), ('1A ($1000s)', 2012), ('1A ($1000s)', 2007), ('1A ($1000s)', 2002), ('1A ($1000s)', 1997), ('1A ($1000s)', 1992), ('1A ($1000s)', 1987), ('1A ($1000s)', 1982), ('1A ($1000s)', 1977), ('1A ($1000s)', 1972), ('1A ($1000s)', '1972.1'), ('1A (% of personal income)', 2017), ('1A (% of personal income)', 2012), ('1A (% of personal income)', 2007), ('1A (% of personal income)', 2002), ('1A (% of personal income)', 1997), ('1A (% of personal income)', 1992), ('1A (% of personal income)', 1987), ('1A (% of personal income)', 1982), ('1A (% of personal income)', 1977), ('1A (% of personal income)', 1972), ('1A (% of personal income)', '1972.1'), ('1A (% of personal income)', 'Metro Area'), ('1A (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
        "    *   **Sheet: 1B**\n",
        "        *   Columns (Partial list due to length and multi-level headers): [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('1B (score)', 2017), ('1B (score)', 2012), ('1B (score)', 2007), ('1B (score)', 2002), ('1B (score)', 1997), ('1B (score)', 1992), ('1B (score)', 1987), ('1B (score)', 1982), ('1B (score)', 1977), ('1B (score)', 1972), ('1B (score)', '1972.1'), ('1B (rank)', 2017), ('1B (rank)', '2017.1'), ('1B (rank)', '2017.2'), ('1B, State & Local (% of personal income)', 2017), ('1B, State & Local (% of personal income)', 2012), ('1B, State & Local (% of personal income)', 2007), ('1B, State & Local (% of personal income)', 2002), ('1B, State & Local (% of personal income)', 1997), ('1B, State & Local (% of personal income)', 1992), ('1B, State & Local (% of personal income)', 1987), ('1B, State & Local (% of personal income)', 1982), ('1B, State & Local (% of personal income)', 1977), ('1B, State & Local (% of personal income)', 1972), ('1B, State & Local (% of personal income)', '1972.1'), ('1B ($1000s)', 2017), ('1B ($1000s)', 2012), ('1B ($1000s)', 2007), ('1B ($1000s)', 2002), ('1B ($1000s)', 1997), ('1B ($1000s)', 1992), ('1B ($1000s)', 1987), ('1B ($1000s)', 1982), ('1B ($1000s)', 1977), ('1B ($1000s)', 1972), ('1B ($1000s)', '1972.1'), ('1B (% of personal income)', 2017), ('1B (% of personal income)', 2012), ('1B (% of personal income)', 2007), ('1B (% of personal income)', 2002), ('1B (% of personal income)', 1997), ('1B (% of personal income)', 1992), ('1B (% of personal income)', 1987), ('1B (% of personal income)', 1982), ('1B (% of personal income)', 1977), ('1B (% of personal income)', 1972), ('1B (% of personal income)', '1972.1'), ('1B (% of personal income)', 'Metro Area'), ('1B (% of personal income)', 'Area'), ('multi-state', '51.1'), ('multi-state', '#'), ('multi-state', 'Primary\\nState'), ('multi-state', 'State 2'), ('multi-state', 'State 3'), ('multi-state', 'State 4'), ('multi-state', 'State 4.1'), ('multi-state', 'State 4.2'), ('State (% of pers. Inc.)', 2017), ('State (% of pers. Inc.)', 2012), ('State (% of pers. Inc.)', 2007), ('State (% of pers. Inc.)', 2002), ('State (% of pers. Inc.)', 1997), ('State (% of pers. Inc.)', 1992), ('State (% of pers. Inc.)', 1987), ('State (% of pers. Inc.)', 1982), ('State (% of pers. Inc.)', 1977), ('State (% of pers. Inc.)', 1972)]\n",
        "    *   **Sheet: 1C**\n",
        "        *   Columns (Partial list due to length and multi-level headers): [('Unnamed: 0_level_0', 'MSAs &\\ncounties\\nABC'), ('Unnamed: 1_level_0', 'MSA&MD order'), ('Unnamed: 2_level_0', 'MSA/MD order'), ('Unnamed: 3_level_0', 'MSA order'), ('Unnamed: 4_level_0', 'State/MSA order'), ('Unnamed: 5_level_0', 'Metro Area'), ('Unnamed: 6_level_0', 'Primary\\nState'), ('Unnamed: 7_level_0', 'Area'), ('multi-state', 51), ('1C (score)', 2017), ('1C (score)', 2012), ('1C (score)', 2007), ('1C (score)', 2002), ('1C (score)', 1997), ('1C (score)', 1992), ('1C (score)', 1987), ('1C (score)', 1982), ('1C (score)', 1977), ('1C (score)', 1972), ('1C (score)', '1972.1'), ('1C (rank)', 2017), ('1C (rank)', '2017.1'), ('1C (rank)', '2017.2'), ('1C ...\n",
        "\n",
        "*   **ZIP_TRACT_062025.xlsx**\n",
        "    *   **Sheet: Export Worksheet**\n",
        "        *   Columns: ['ZIP', 'TRACT', 'RES_RATIO', 'BUS_RATIO', 'OTH_RATIO', 'TOT_RATIO']\n",
        "    *   **Sheet: SQL**\n",
        "        *   Columns: ['Unnamed: 0']\n",
        "        *   *Note: This sheet appears to contain only an index or similar data.*\n",
        "\n",
        "**CSV Files:**\n",
        "\n",
        "*   **SMART_2007_individual.csv, SMART_2008_individual.csv, SMART_2012_individual.csv, SMART_2017_individual.csv, SMART_2022_individual.csv**\n",
        "    *   Common Columns: ['CHILDREN', 'MARITAL', 'PREGNANT', 'EMPLOY1', '_EDUCAG', '_INCOMG1', '_AGEG5YR', '_AGEG65YR', '_RACEG22', '_RACEGR4', '_HLTHPLN', 'SEXVAR', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', '_RFHLTH', 'BMI_RAW', 'BMI_CATEGORY', 'EXERCISE_30D', '_STATE', '_CNTY', '_WT2', '_CNTYWT', '_STSTR', '_PSU', 'COUNTY_FIPS', 'CBSA_CODE', 'CBSA_NAME', 'YEAR']\n",
        "    *   *Note: The SMART BRFSS files for different years have largely the same column structure, with minor variations in some columns (e.g., presence of 'MMSANAME', '_PHYS14D', '_MENT14D', '_MMSA', '_MMSAWT' in later years). The columns listed above are representative of the common structure across these files.*\n",
        "\n",
        "This consolidated list should provide a comprehensive overview of the available columns in your datasets for the AI data analysis agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c65a6e6"
      },
      "source": [
        "## Create a directory in google drive\n",
        "\n",
        "### Subtask:\n",
        "Create a new directory named `Saksham_MEFI` in your Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8abcc9fc"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a new directory named `Saksham_MEFI` in Google Drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "111ce6ef",
        "outputId": "12ec5dca-c483-4692-b667-960b017e452b"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path for the new directory\n",
        "new_directory_path = '/content/drive/MyDrive/Saksham_MEFI'\n",
        "\n",
        "# Create the directory\n",
        "os.makedirs(new_directory_path, exist_ok=True)\n",
        "\n",
        "print(f\"Directory '{new_directory_path}' created successfully (or already exists).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory '/content/drive/MyDrive/Saksham_MEFI' created successfully (or already exists).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "663596d2"
      },
      "source": [
        "## Copy files to google drive\n",
        "\n",
        "### Subtask:\n",
        "Copy all files from the working directory to the newly created directory in Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f068e64"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to list all files in the working directory, define the destination path, and then iterate through the files to copy them to the Google Drive directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60c78925",
        "outputId": "f17b25e7-a807-4882-b2dc-0b50ae9c886e"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# List all files in the current working directory\n",
        "files_in_directory = os.listdir('.')\n",
        "\n",
        "# Define the destination directory path in Google Drive\n",
        "destination_directory = '/content/drive/MyDrive/Saksham_MEFI'\n",
        "\n",
        "# Iterate through the list of files and copy them\n",
        "for file_name in files_in_directory:\n",
        "    source_path = os.path.join('.', file_name)\n",
        "    destination_path = os.path.join(destination_directory, file_name)\n",
        "\n",
        "    # Check if the source is a file before attempting to copy\n",
        "    if os.path.isfile(source_path):\n",
        "        try:\n",
        "            shutil.copy2(source_path, destination_path)\n",
        "            print(f\"Copied '{file_name}' to '{destination_directory}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying '{file_name}': {e}\")\n",
        "    else:\n",
        "        print(f\"Skipping '{file_name}' as it is not a file.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping '.config' as it is not a file.\n",
            "Copied 'list1_2023.xlsx' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'SMART_2007_individual.csv' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Skipping '.ipynb_checkpoints' as it is not a file.\n",
            "Skipping 'drive' as it is not a file.\n",
            "Copied 'SMART_2022_individual.csv' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'SMART_2017_individual.csv' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'DCI-2019-2023-Full-Dataset.xlsx' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'SMART_2012_individual.csv' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'ZIP_TRACT_062025.xlsx' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'DCI_datasets_longitudinal_zip_scores.xlsx' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Copied 'SMART_2008_individual.csv' to '/content/drive/MyDrive/Saksham_MEFI'\n",
            "Skipping 'sample_data' as it is not a file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "c4bb50b2",
        "outputId": "e6f7eac4-98a1-46f1-b847-b814e30a3f21"
      },
      "source": [
        "file_path = \"/content/list1_2023.xlsx\"\n",
        "sheet_name = \"List 1\"\n",
        "\n",
        "print(f\"Processing file: {file_path}, Sheet: {sheet_name}\")\n",
        "\n",
        "try:\n",
        "    # Attempt to read with no header, then look at the first few rows\n",
        "    df_no_header = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
        "    print(\"\\nLoaded with no header (first 5 rows):\")\n",
        "    display(df_no_header.head())\n",
        "\n",
        "    # Attempt to read with header on the 3rd row (index 2) based on previous output\n",
        "    df_header_row_3 = pd.read_excel(file_path, sheet_name=sheet_name, header=2)\n",
        "    print(\"\\nLoaded with header on row 3 (first 5 rows):\")\n",
        "    display(df_header_row_3.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not read sheet '{sheet_name}' from file '{file_path}': {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/list1_2023.xlsx, Sheet: List 1\n",
            "\n",
            "Loaded with no header (first 5 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  0   \\\n",
              "0  Table with row headers in column A and column ...   \n",
              "1  List 1. CORE BASED STATISTICAL AREAS (CBSAs), ...   \n",
              "2                                          CBSA Code   \n",
              "3                                              10100   \n",
              "4                                              10100   \n",
              "\n",
              "                           1         2             3   \\\n",
              "0                         NaN       NaN           NaN   \n",
              "1                         NaN       NaN           NaN   \n",
              "2  Metropolitan Division Code  CSA Code    CBSA Title   \n",
              "3                         NaN       NaN  Aberdeen, SD   \n",
              "4                         NaN       NaN  Aberdeen, SD   \n",
              "\n",
              "                                           4                            5   \\\n",
              "0                                         NaN                          NaN   \n",
              "1                                         NaN                          NaN   \n",
              "2  Metropolitan/Micropolitan Statistical Area  Metropolitan Division Title   \n",
              "3               Micropolitan Statistical Area                          NaN   \n",
              "4               Micropolitan Statistical Area                          NaN   \n",
              "\n",
              "          6                         7             8                9   \\\n",
              "0        NaN                       NaN           NaN              NaN   \n",
              "1        NaN                       NaN           NaN              NaN   \n",
              "2  CSA Title  County/County Equivalent    State Name  FIPS State Code   \n",
              "3        NaN              Brown County  South Dakota               46   \n",
              "4        NaN            Edmunds County  South Dakota               46   \n",
              "\n",
              "                 10                       11  \n",
              "0               NaN                      NaN  \n",
              "1               NaN                      NaN  \n",
              "2  FIPS County Code  Central/Outlying County  \n",
              "3               013                  Central  \n",
              "4               045                 Outlying  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49dfd0af-ba13-4ea0-bb89-31b0d5589afd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Table with row headers in column A and column ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>List 1. CORE BASED STATISTICAL AREAS (CBSAs), ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CBSA Code</td>\n",
              "      <td>Metropolitan Division Code</td>\n",
              "      <td>CSA Code</td>\n",
              "      <td>CBSA Title</td>\n",
              "      <td>Metropolitan/Micropolitan Statistical Area</td>\n",
              "      <td>Metropolitan Division Title</td>\n",
              "      <td>CSA Title</td>\n",
              "      <td>County/County Equivalent</td>\n",
              "      <td>State Name</td>\n",
              "      <td>FIPS State Code</td>\n",
              "      <td>FIPS County Code</td>\n",
              "      <td>Central/Outlying County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aberdeen, SD</td>\n",
              "      <td>Micropolitan Statistical Area</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Brown County</td>\n",
              "      <td>South Dakota</td>\n",
              "      <td>46</td>\n",
              "      <td>013</td>\n",
              "      <td>Central</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aberdeen, SD</td>\n",
              "      <td>Micropolitan Statistical Area</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Edmunds County</td>\n",
              "      <td>South Dakota</td>\n",
              "      <td>46</td>\n",
              "      <td>045</td>\n",
              "      <td>Outlying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49dfd0af-ba13-4ea0-bb89-31b0d5589afd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49dfd0af-ba13-4ea0-bb89-31b0d5589afd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49dfd0af-ba13-4ea0-bb89-31b0d5589afd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a04c06a6-9f1a-425e-a8a0-2fc57ac79f2b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a04c06a6-9f1a-425e-a8a0-2fc57ac79f2b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a04c06a6-9f1a-425e-a8a0-2fc57ac79f2b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(f\\\"Could not read sheet '{sheet_name}' from file '{file_path}': {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"List 1. CORE BASED STATISTICAL AREAS (CBSAs), METROPOLITAN DIVISIONS, AND COMBINED STATISTICAL AREAS (CSAs), JULY 2023\",\n          \"10100\",\n          \"Table with row headers in column A and column headers in row 3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Metropolitan Division Code\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CSA Code\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Aberdeen, SD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Micropolitan Statistical Area\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Metropolitan Division Title\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CSA Title\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"County/County Equivalent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"South Dakota\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"46\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FIPS County Code\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Central/Outlying County\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded with header on row 3 (first 5 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  CBSA Code  Metropolitan Division Code  CSA Code    CBSA Title  \\\n",
              "0     10100                         NaN       NaN  Aberdeen, SD   \n",
              "1     10100                         NaN       NaN  Aberdeen, SD   \n",
              "2     10140                         NaN       NaN  Aberdeen, WA   \n",
              "3     10180                         NaN     101.0   Abilene, TX   \n",
              "4     10180                         NaN     101.0   Abilene, TX   \n",
              "\n",
              "  Metropolitan/Micropolitan Statistical Area Metropolitan Division Title  \\\n",
              "0              Micropolitan Statistical Area                         NaN   \n",
              "1              Micropolitan Statistical Area                         NaN   \n",
              "2              Micropolitan Statistical Area                         NaN   \n",
              "3              Metropolitan Statistical Area                         NaN   \n",
              "4              Metropolitan Statistical Area                         NaN   \n",
              "\n",
              "                CSA Title County/County Equivalent    State Name  \\\n",
              "0                     NaN             Brown County  South Dakota   \n",
              "1                     NaN           Edmunds County  South Dakota   \n",
              "2                     NaN      Grays Harbor County    Washington   \n",
              "3  Abilene-Sweetwater, TX          Callahan County         Texas   \n",
              "4  Abilene-Sweetwater, TX             Jones County         Texas   \n",
              "\n",
              "   FIPS State Code  FIPS County Code Central/Outlying County  \n",
              "0             46.0              13.0                 Central  \n",
              "1             46.0              45.0                Outlying  \n",
              "2             53.0              27.0                 Central  \n",
              "3             48.0              59.0                Outlying  \n",
              "4             48.0             253.0                Outlying  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60abb835-8e6f-4503-b305-63e673b980e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CBSA Code</th>\n",
              "      <th>Metropolitan Division Code</th>\n",
              "      <th>CSA Code</th>\n",
              "      <th>CBSA Title</th>\n",
              "      <th>Metropolitan/Micropolitan Statistical Area</th>\n",
              "      <th>Metropolitan Division Title</th>\n",
              "      <th>CSA Title</th>\n",
              "      <th>County/County Equivalent</th>\n",
              "      <th>State Name</th>\n",
              "      <th>FIPS State Code</th>\n",
              "      <th>FIPS County Code</th>\n",
              "      <th>Central/Outlying County</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aberdeen, SD</td>\n",
              "      <td>Micropolitan Statistical Area</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Brown County</td>\n",
              "      <td>South Dakota</td>\n",
              "      <td>46.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Central</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aberdeen, SD</td>\n",
              "      <td>Micropolitan Statistical Area</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Edmunds County</td>\n",
              "      <td>South Dakota</td>\n",
              "      <td>46.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>Outlying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10140</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aberdeen, WA</td>\n",
              "      <td>Micropolitan Statistical Area</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Grays Harbor County</td>\n",
              "      <td>Washington</td>\n",
              "      <td>53.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>Central</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10180</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101.0</td>\n",
              "      <td>Abilene, TX</td>\n",
              "      <td>Metropolitan Statistical Area</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Abilene-Sweetwater, TX</td>\n",
              "      <td>Callahan County</td>\n",
              "      <td>Texas</td>\n",
              "      <td>48.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>Outlying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10180</td>\n",
              "      <td>NaN</td>\n",
              "      <td>101.0</td>\n",
              "      <td>Abilene, TX</td>\n",
              "      <td>Metropolitan Statistical Area</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Abilene-Sweetwater, TX</td>\n",
              "      <td>Jones County</td>\n",
              "      <td>Texas</td>\n",
              "      <td>48.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>Outlying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60abb835-8e6f-4503-b305-63e673b980e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60abb835-8e6f-4503-b305-63e673b980e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60abb835-8e6f-4503-b305-63e673b980e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2497b8d4-888f-4cda-a877-226728bed2cf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2497b8d4-888f-4cda-a877-226728bed2cf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2497b8d4-888f-4cda-a877-226728bed2cf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "997a77ec"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The following CSV files were identified in the working directory: `./SMART_2007_individual.csv`, `./SMART_2022_individual.csv`, `./SMART_2017_individual.csv`, `./SMART_2012_individual.csv`, and `./SMART_2008_individual.csv`.\n",
        "*   The column names for each identified CSV file were successfully extracted and printed.\n",
        "*   A new directory named `Saksham_MEFI` was successfully created in Google Drive.\n",
        "*   All files from the working directory, including the CSV files, were successfully copied to the newly created `Saksham_MEFI` directory in Google Drive. Directories within the working directory were skipped during the copy process.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Verify the contents of the `Saksham_MEFI` directory in Google Drive to ensure all expected files were copied correctly.\n",
        "*   Proceed with further analysis or processing of the copied CSV files now that they are stored in Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 02 — Imports, paths, helpers (REVISED)\n",
        "\n",
        "import os, pandas as pd, numpy as np\n",
        "\n",
        "IN  = \"/content\"                 # change if you mount Drive\n",
        "OUT = \"/content/phase1_out\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "# --- helpers ---\n",
        "def _as_str(s):\n",
        "    s = pd.Series(s)\n",
        "    return s.astype(str).str.strip()\n",
        "\n",
        "def zpad(s, n):\n",
        "    s = _as_str(s)\n",
        "    s = s.mask(s.str.lower().isin([\"nan\",\"none\",\"\"]), np.nan)\n",
        "    # extract 0–9 only (useful if Excel auto-formatted)\n",
        "    s = s.str.extract(r\"(\\d+)\")[0]\n",
        "    return s.str.zfill(n)\n",
        "\n",
        "def pad_cbsa(s):   # 5-digit CBSA, but keep NaN as NaN (avoid '00nan')\n",
        "    s = _as_str(s)\n",
        "    s = s.mask(s.str.lower().isin([\"nan\",\"none\",\"\"]), np.nan)\n",
        "    s = s.str.extract(r\"(\\d{1,5})\")[0]\n",
        "    s = s.str.zfill(5)\n",
        "    # if we zfilled NaN → becomes '00nan'; turn those back to NaN safely\n",
        "    s = s.where(s.str.fullmatch(r\"\\d{5}\"), np.nan)\n",
        "    return s\n",
        "\n",
        "def pad_state(s):  return zpad(s, 2)\n",
        "def pad_county(s): return zpad(s, 3)\n",
        "\n",
        "# sentinel set for \"Outside CBSA\"\n",
        "NON_CBSA_CODES = {\"99999\"}\n",
        "\n",
        "# Phase‑1 BRFSS→MEFI mapping (from execution guide)\n",
        "BRFSS_TO_MEFI = {2007:2007, 2008:2007, 2012:2012, 2017:2017, 2022:2017}  # 2022 intentionally maps to 2017 :contentReference[oaicite:2]{index=2}\n"
      ],
      "metadata": {
        "id": "FOHYtOYzTLTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_path = f\"{IN}/list1_2023.xlsx\"\n",
        "df_list = pd.read_excel(list_path, sheet_name=\"List 1\", header=2, dtype=str)\n",
        "\n",
        "# Standardize columns\n",
        "df_list = df_list.rename(columns={\n",
        "    \"FIPS State Code\": \"state_fips\",\n",
        "    \"FIPS County Code\": \"county_fips\",\n",
        "    \"CBSA Code\": \"cbsa_code_current\",\n",
        "    \"CBSA Title\": \"cbsa_title\",\n",
        "    \"Metropolitan/Micropolitan Statistical Area\": \"cbsa_type\"\n",
        "})\n",
        "\n",
        "# Zero-pad\n",
        "df_list[\"state_fips\"] = pad_state(df_list[\"state_fips\"])\n",
        "df_list[\"county_fips\"] = pad_county(df_list[\"county_fips\"])\n",
        "df_list[\"cbsa_code_current\"] = pad_cbsa(df_list[\"cbsa_code_current\"])\n",
        "\n",
        "# Optional: keep Metropolitan only to align with MEFI scope\n",
        "df_list_metro = df_list[df_list[\"cbsa_type\"].str.contains(\"Metropolitan\", na=False)].copy()\n",
        "\n",
        "# Deduplicate on county\n",
        "dups = df_list_metro.duplicated([\"state_fips\",\"county_fips\"], keep=False)\n",
        "assert df_list_metro.loc[dups, [\"state_fips\",\"county_fips\"]].empty, \\\n",
        "    \"A county maps to multiple CBSAs in list1_2023.xlsx; inspect and resolve.\"\n",
        "\n",
        "# Write 3-col and 4-col (QC) masters\n",
        "df_list_metro[[\"state_fips\",\"county_fips\",\"cbsa_code_current\"]].to_csv(\n",
        "    f\"{OUT}/county_to_cbsa_3col_master.csv\", index=False)\n",
        "\n",
        "df_list_metro[[\"state_fips\",\"county_fips\",\"cbsa_code_current\",\"cbsa_title\"]].to_csv(\n",
        "    f\"{OUT}/county_to_cbsa_4col_qc.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "AlONvsYfTLpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1: Exploring Initial MEFI data\n"
      ],
      "metadata": {
        "id": "L3JX6phjVdIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If your runtime already has these, you can skip\n",
        "!pip install --quiet pandas numpy openpyxl pyarrow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "OA88zUu-VgSZ",
        "outputId": "f97ca73b-3433-4dba-d70f-4edbbe30ebbe",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_drv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-664215522.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If your runtime already has these, you can skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --quiet pandas numpy openpyxl pyarrow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             self._str = self._format_parsed_parts(self.drive, self.root,\n\u001b[0m\u001b[1;32m    444\u001b[0m                                                   self._tail) or '.'\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mdrive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_load_parts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m_parse_path\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;31m# e.g. //?/unc/server/share\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 02 — Imports, paths, helpers (REVISED)\n",
        "\n",
        "import os, pandas as pd, numpy as np\n",
        "\n",
        "IN  = \"/content\"                 # change if you mount Drive\n",
        "OUT = \"/content/phase1_out\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "# --- helpers ---\n",
        "def _as_str(s):\n",
        "    s = pd.Series(s)\n",
        "    return s.astype(str).str.strip()\n",
        "\n",
        "def zpad(s, n):\n",
        "    s = _as_str(s)\n",
        "    s = s.mask(s.str.lower().isin([\"nan\",\"none\",\"\"]), np.nan)\n",
        "    # extract 0–9 only (useful if Excel auto-formatted)\n",
        "    s = s.str.extract(r\"(\\d+)\")[0]\n",
        "    return s.str.zfill(n)\n",
        "\n",
        "def pad_cbsa(s):   # 5-digit CBSA, but keep NaN as NaN (avoid '00nan')\n",
        "    s = _as_str(s)\n",
        "    s = s.mask(s.str.lower().isin([\"nan\",\"none\",\"\"]), np.nan)\n",
        "    s = s.str.extract(r\"(\\d{1,5})\")[0]\n",
        "    s = s.str.zfill(5)\n",
        "    # if we zfilled NaN → becomes '00nan'; turn those back to NaN safely\n",
        "    s = s.where(s.str.fullmatch(r\"\\d{5}\"), np.nan)\n",
        "    return s\n",
        "\n",
        "def pad_state(s):  return zpad(s, 2)\n",
        "def pad_county(s): return zpad(s, 3)\n",
        "\n",
        "# sentinel set for \"Outside CBSA\"\n",
        "NON_CBSA_CODES = {\"99999\"}\n",
        "\n",
        "# Phase‑1 BRFSS→MEFI mapping (from execution guide)\n",
        "BRFSS_TO_MEFI = {2007:2007, 2008:2007, 2012:2012, 2017:2017, 2022:2017}  # 2022 intentionally maps to 2017 :contentReference[oaicite:2]{index=2}\n"
      ],
      "metadata": {
        "id": "QfFo-epPVgf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cbsa_list(path, sheet=\"List 1\", header=2):\n",
        "    df = pd.read_excel(path, sheet_name=sheet, header=header, dtype=str)\n",
        "    df = df.rename(columns={\n",
        "        \"FIPS State Code\": \"state_fips\",\n",
        "        \"FIPS County Code\": \"county_fips\",\n",
        "        \"CBSA Code\": \"cbsa_code\",\n",
        "        \"CBSA Title\": \"cbsa_title\",\n",
        "        \"Metropolitan/Micropolitan Statistical Area\": \"cbsa_type\"\n",
        "    })\n",
        "    df[\"state_fips\"] = pad_state(df[\"state_fips\"])\n",
        "    df[\"county_fips\"] = pad_county(df[\"county_fips\"])\n",
        "    df[\"cbsa_code\"]  = pad_cbsa(df[\"cbsa_code\"])\n",
        "    # Restrict to Metropolitan areas (MEFI scope)\n",
        "    df = df[df[\"cbsa_type\"].str.contains(\"Metropolitan\", na=False)].copy()\n",
        "    # Ensure one CBSA per county in the list vintage\n",
        "    if df.duplicated([\"state_fips\",\"county_fips\"], keep=False).any():\n",
        "        dupes = df[df.duplicated([\"state_fips\",\"county_fips\"], keep=False)]\n",
        "        raise ValueError(f\"County appears in multiple CBSAs in {path}, inspect:\\n{dupes.head(10)}\")\n",
        "    return df[[\"state_fips\",\"county_fips\",\"cbsa_code\",\"cbsa_title\"]].copy()\n",
        "\n",
        "list_old = load_cbsa_list(f\"{IN}/list1.xls\")          # 2013–2020 vintage\n",
        "list_new = load_cbsa_list(f\"{IN}/list1_2023.xlsx\")     # current\n",
        "\n",
        "# Save canonical county→current CBSA (3‑col master for reference)\n",
        "(list_new.rename(columns={\"cbsa_code\":\"cbsa_code_current\"})\n",
        "         [[\"state_fips\",\"county_fips\",\"cbsa_code_current\"]]\n",
        "         .to_csv(f\"{OUT}/county_to_cbsa_3col_master_2023.csv\", index=False))\n"
      ],
      "metadata": {
        "id": "o5RnIuGNVikG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# County-level pairs of (legacy, current) CBSA codes across vintages\n",
        "pairs = (list_old.merge(list_new, on=[\"state_fips\",\"county_fips\"], suffixes=(\"_old\",\"_new\"))\n",
        "                [[\"state_fips\",\"county_fips\",\"cbsa_code_old\",\"cbsa_code_new\"]])\n",
        "\n",
        "# Count how many counties support each legacy→current mapping pair\n",
        "remap_counts = (pairs.value_counts([\"cbsa_code_old\",\"cbsa_code_new\"])\n",
        "                      .reset_index(name=\"n_counties\"))\n",
        "remap_counts.to_csv(f\"{OUT}/cbsa_legacy_to_current_by_county.csv\", index=False)\n",
        "\n",
        "# Determine deterministic (maps to exactly one current) vs ambiguous legacy codes\n",
        "targets_per_legacy = remap_counts.groupby(\"cbsa_code_old\")[\"cbsa_code_new\"].nunique()\n",
        "deterministic = targets_per_legacy[targets_per_legacy==1].index.tolist()\n",
        "ambiguous     = targets_per_legacy[targets_per_legacy> 1].index.tolist()\n",
        "\n",
        "# Deterministic legacy→current code remap dictionary\n",
        "det_map = (remap_counts[remap_counts[\"cbsa_code_old\"].isin(deterministic)]\n",
        "           .drop_duplicates(\"cbsa_code_old\")\n",
        "           .set_index(\"cbsa_code_old\")[\"cbsa_code_new\"]\n",
        "           .to_dict())\n",
        "\n",
        "pd.Series(ambiguous, name=\"legacy_cbsa_with_splits\").to_csv(f\"{OUT}/cbsa_legacy_splits.csv\", index=False)\n",
        "\n",
        "print(f\"Deterministic legacy→current mappings: {len(det_map)}\")\n",
        "print(f\"Ambiguous legacy CBSA codes (splits): {len(ambiguous)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUpQtkMtVkK2",
        "outputId": "0aedf91d-f803-42d2-bf0a-bc6c43b99d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deterministic legacy→current mappings: 370\n",
            "Ambiguous legacy CBSA codes (splits): 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mefi_path = f\"{IN}/MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx\"\n",
        "\n",
        "def load_mefi_core(mefi_path):\n",
        "    df = pd.read_excel(mefi_path, sheet_name=\"scores (panel)\", dtype=str)\n",
        "    # Normalize column names we need\n",
        "    df = df.rename(columns={\n",
        "        \"CBSA Code\": \"cbsa_code\",\n",
        "        \"year\": \"mefi_year\",\n",
        "        \"Overall\": \"mefi_overall\",\n",
        "        \"Area 1: Govern-ment Spending\": \"mefi_area1\",   # observed hyphenated break\n",
        "        \"Area 1: Government Spending\": \"mefi_area1\",\n",
        "        \"Area 2: Taxes\": \"mefi_area2\",\n",
        "        \"Area 3: Labor Market Regulation\": \"mefi_area3\"\n",
        "    })\n",
        "    # Keep minimal columns (we’ll append population & sub-areas later if present elsewhere)\n",
        "    keep = [\"cbsa_code\",\"mefi_year\",\"mefi_overall\",\"mefi_area1\",\"mefi_area2\",\"mefi_area3\"]\n",
        "    df = df[[c for c in keep if c in df.columns]].copy()\n",
        "\n",
        "    # Types & filters\n",
        "    df[\"cbsa_code\"] = pad_cbsa(df[\"cbsa_code\"])\n",
        "    df[\"mefi_year\"] = df[\"mefi_year\"].astype(int)\n",
        "    df = df[df[\"mefi_year\"].isin([2007,2012,2017])].copy()\n",
        "    # Coerce numeric\n",
        "    for c in [\"mefi_overall\",\"mefi_area1\",\"mefi_area2\",\"mefi_area3\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "mefi_core = load_mefi_core(mefi_path)\n",
        "print(mefi_core[\"mefi_year\"].value_counts().sort_index())\n",
        "mefi_core.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Uwys8EFZVqdC",
        "outputId": "437f1706-7e24-47ca-b770-5158fef087d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mefi_year\n",
            "2007    383\n",
            "2012    383\n",
            "2017    383\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cbsa_code  mefi_year  mefi_overall  mefi_area1  mefi_area2  mefi_area3\n",
              "0     10180       2017      7.892123    7.884567    7.291512    8.500290\n",
              "1     10420       2017      6.240566    5.594453    5.385247    7.741998\n",
              "2     10500       2017      6.839055    6.786531    6.101177    7.629456\n",
              "3     10540       2017      5.558961    5.205432    5.561946    5.909504\n",
              "4     10580       2017      5.858823    7.050117    4.245872    6.280479"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf1ba5fc-b601-4841-87e8-5266591a894b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cbsa_code</th>\n",
              "      <th>mefi_year</th>\n",
              "      <th>mefi_overall</th>\n",
              "      <th>mefi_area1</th>\n",
              "      <th>mefi_area2</th>\n",
              "      <th>mefi_area3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10180</td>\n",
              "      <td>2017</td>\n",
              "      <td>7.892123</td>\n",
              "      <td>7.884567</td>\n",
              "      <td>7.291512</td>\n",
              "      <td>8.500290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10420</td>\n",
              "      <td>2017</td>\n",
              "      <td>6.240566</td>\n",
              "      <td>5.594453</td>\n",
              "      <td>5.385247</td>\n",
              "      <td>7.741998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10500</td>\n",
              "      <td>2017</td>\n",
              "      <td>6.839055</td>\n",
              "      <td>6.786531</td>\n",
              "      <td>6.101177</td>\n",
              "      <td>7.629456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10540</td>\n",
              "      <td>2017</td>\n",
              "      <td>5.558961</td>\n",
              "      <td>5.205432</td>\n",
              "      <td>5.561946</td>\n",
              "      <td>5.909504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10580</td>\n",
              "      <td>2017</td>\n",
              "      <td>5.858823</td>\n",
              "      <td>7.050117</td>\n",
              "      <td>4.245872</td>\n",
              "      <td>6.280479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf1ba5fc-b601-4841-87e8-5266591a894b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf1ba5fc-b601-4841-87e8-5266591a894b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf1ba5fc-b601-4841-87e8-5266591a894b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2de2d3d5-68e6-464b-a150-861825f817be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2de2d3d5-68e6-464b-a150-861825f817be')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2de2d3d5-68e6-464b-a150-861825f817be button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mefi_core",
              "summary": "{\n  \"name\": \"mefi_core\",\n  \"rows\": 1149,\n  \"fields\": [\n    {\n      \"column\": \"cbsa_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 383,\n        \"samples\": [\n          \"37900\",\n          \"35660\",\n          \"42540\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mefi_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2007,\n        \"max\": 2017,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2017,\n          2012,\n          2007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mefi_overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8055484515415157,\n        \"min\": 3.748376394064794,\n        \"max\": 8.911633315578884,\n        \"num_unique_values\": 1149,\n        \"samples\": [\n          6.5040625325201935,\n          5.731088285907717,\n          7.931324771154197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mefi_area1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.092176538382846,\n        \"min\": 2.1140048628500416,\n        \"max\": 9.084912430725964,\n        \"num_unique_values\": 1144,\n        \"samples\": [\n          6.568946862068337,\n          6.827770612084585,\n          5.78291996430541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mefi_area2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.901113130616179,\n        \"min\": 1.6873637905778935,\n        \"max\": 9.07141806834808,\n        \"num_unique_values\": 1149,\n        \"samples\": [\n          6.114449664035508,\n          6.541252076282171,\n          7.178192527509483\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mefi_area3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0213585366749325,\n        \"min\": 3.802167992521808,\n        \"max\": 10.0,\n        \"num_unique_values\": 1149,\n        \"samples\": [\n          7.417479812729156,\n          5.616755278705291,\n          8.676506362077182\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 06 — Load MEFI sub-areas (REVISED)\n",
        "\n",
        "SUBSHEETS = [\"1A\",\"1B\",\"1C\",\"2A\",\"2B\",\"2C\",\"3A\",\"3B\",\"3C\"]\n",
        "\n",
        "def norm_name(s):\n",
        "    s = _as_str(s).str.lower()\n",
        "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "    # remove common suffix tokens\n",
        "    s = (s.str.replace(\" msa\", \"\", regex=False)\n",
        "           .str.replace(\" metropolitan statistical area\", \"\", regex=False)\n",
        "           .str.replace(\" metropolitan division\", \"\", regex=False))\n",
        "    return s\n",
        "\n",
        "def build_name_to_cbsa_map(mefi_path, list_new):  # list_new already loaded in Cell 03\n",
        "    # From MEFI 'scores' wide\n",
        "    sw = pd.read_excel(mefi_path, sheet_name=\"scores\", header=[0,1], dtype=str)\n",
        "    # ID col (CBSA code)\n",
        "    id_col = None\n",
        "    for c in sw.columns:\n",
        "        if c[1] == \"CBSA Code\":\n",
        "            id_col = c; break\n",
        "    if id_col is None:\n",
        "        for c in sw.columns:\n",
        "            s = sw[c].astype(str).str.fullmatch(r\"\\d{5}\")\n",
        "            if s.mean() > 0.3:\n",
        "                id_col = c; break\n",
        "    # Name col\n",
        "    name_col = None\n",
        "    for c in sw.columns:\n",
        "        if c[1] in [\"Metro Area\",\"CBSA Name\"]:\n",
        "            name_col = c; break\n",
        "    if id_col is not None and name_col is not None:\n",
        "        m1 = sw[[id_col, name_col]].copy()\n",
        "        m1.columns = [\"cbsa_code\",\"metro_area\"]\n",
        "        m1[\"cbsa_code\"] = pad_cbsa(m1[\"cbsa_code\"])\n",
        "        m1[\"metro_area_norm\"] = norm_name(m1[\"metro_area\"])\n",
        "    else:\n",
        "        m1 = pd.DataFrame(columns=[\"cbsa_code\",\"metro_area_norm\"])\n",
        "\n",
        "    # From list1_2023.xlsx (fallback)\n",
        "    m2 = (list_new.rename(columns={\"cbsa_code\":\"cbsa_code\", \"cbsa_title\":\"metro_area\"})\n",
        "                  [[\"cbsa_code\",\"metro_area\"]].copy())\n",
        "    m2[\"cbsa_code\"] = pad_cbsa(m2[\"cbsa_code\"])\n",
        "    m2[\"metro_area_norm\"] = norm_name(m2[\"metro_area\"])\n",
        "\n",
        "    nm = (pd.concat([m1[[\"cbsa_code\",\"metro_area_norm\"]],\n",
        "                     m2[[\"cbsa_code\",\"metro_area_norm\"]]], ignore_index=True)\n",
        "            .dropna(subset=[\"cbsa_code\",\"metro_area_norm\"])\n",
        "            .drop_duplicates(\"metro_area_norm\"))\n",
        "    return nm  # columns: cbsa_code, metro_area_norm\n",
        "\n",
        "def wide_subarea_to_long(df_mi, subtag):\n",
        "    \"\"\"Extract '<subtag> (score)' columns for 2007/2012/2017 into long with metro name.\"\"\"\n",
        "    # Find a 'Metro Area' column in this sheet\n",
        "    metro_cols = [c for c in df_mi.columns if isinstance(c, tuple) and c[1] == \"Metro Area\"]\n",
        "    if not metro_cols:\n",
        "        return None\n",
        "    metro_col = metro_cols[0]\n",
        "    out = df_mi[[metro_col]].copy()\n",
        "    out.columns = [\"metro_area\"]\n",
        "\n",
        "    want_prefix = f\"{subtag} (score)\"\n",
        "    score_cols = [c for c in df_mi.columns\n",
        "                  if isinstance(c, tuple)\n",
        "                  and c[0]==want_prefix\n",
        "                  and c[1] in [2007,2012,2017]]\n",
        "    if not score_cols:\n",
        "        return None\n",
        "\n",
        "    for (top, yr) in score_cols:\n",
        "        colname = f\"mefi_{subtag.lower()}_{yr}\"\n",
        "        out[colname] = pd.to_numeric(df_mi[(top, yr)], errors=\"coerce\")\n",
        "\n",
        "    # Remove rows with all-NaN metrics\n",
        "    if out.filter(like=\"mefi_\", axis=1).notna().sum(axis=1).eq(0).all():\n",
        "        return None\n",
        "    return out\n",
        "\n",
        "def load_mefi_subareas(mefi_path, list_new):\n",
        "    name_map = build_name_to_cbsa_map(mefi_path, list_new)  # cbsa_code, metro_area_norm\n",
        "    long_parts = []\n",
        "    for subtag in SUBSHEETS:\n",
        "        try:\n",
        "            df_mi = pd.read_excel(mefi_path, sheet_name=subtag, header=[0,1], dtype=str)\n",
        "            sub_long = wide_subarea_to_long(df_mi, subtag)\n",
        "            if sub_long is None:\n",
        "                print(f\"Sub-area {subtag}: no usable '(score)' columns for 2007/2012/2017; skipping.\")\n",
        "                continue\n",
        "            tmp = sub_long.copy()\n",
        "            tmp[\"metro_area_norm\"] = norm_name(tmp[\"metro_area\"])\n",
        "\n",
        "            # Join to CBSA code via normalized names\n",
        "            tmp = tmp.merge(name_map, on=\"metro_area_norm\", how=\"left\")\n",
        "\n",
        "            # Reshape to long\n",
        "            value_cols = [c for c in tmp.columns\n",
        "                          if c.startswith(\"mefi_\") and c.split(\"_\")[-1] in [\"2007\",\"2012\",\"2017\"]]\n",
        "            melted = tmp.melt(id_vars=[\"cbsa_code\"], value_vars=value_cols,\n",
        "                              var_name=\"metric_year\", value_name=\"value\")\n",
        "            # Keep valid codes only (avoid '00nan')\n",
        "            melted[\"cbsa_code\"] = pad_cbsa(melted[\"cbsa_code\"])\n",
        "            melted = melted[melted[\"cbsa_code\"].notna()].copy()\n",
        "\n",
        "            # Parse metric/year\n",
        "            melted[\"metric\"] = melted[\"metric_year\"].str.rsplit(\"_\", n=1).str[0]\n",
        "            melted[\"mefi_year\"] = melted[\"metric_year\"].str.rsplit(\"_\", n=1).str[1].astype(int)\n",
        "            melted = melted.drop(columns=[\"metric_year\"]).drop_duplicates()\n",
        "            long_parts.append(melted[[\"cbsa_code\",\"mefi_year\",\"metric\",\"value\"]])\n",
        "            years = sorted(melted[\"mefi_year\"].unique())\n",
        "            print(f\"Sub-area {subtag}: captured metrics for years {years}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Sub-area {subtag}: error parsing ({e}); skipping.\")\n",
        "\n",
        "    if not long_parts:\n",
        "        return pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\",\"metric\",\"value\"])\n",
        "    return pd.concat(long_parts, ignore_index=True)\n",
        "\n",
        "# re-run subareas with revised function\n",
        "mefi_sub_long = load_mefi_subareas(mefi_path, list_new)\n",
        "mefi_sub_long.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "q8rdDbp-Vtmo",
        "outputId": "a55381f5-7692-46ec-ba7e-235ff6e6d6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-area 1A: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 1B: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 1C: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 2A: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 2B: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 2C: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 3A: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 3B: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 3C: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cbsa_code  mefi_year   metric     value\n",
              "0     10180       2017  mefi_1a  8.406780\n",
              "1     10420       2017  mefi_1a  7.718515\n",
              "2     10500       2017  mefi_1a  6.407737\n",
              "3     10540       2017  mefi_1a  5.391028\n",
              "4     10580       2017  mefi_1a  7.604738"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0546345d-db0c-4745-9890-a1b1349d7c14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cbsa_code</th>\n",
              "      <th>mefi_year</th>\n",
              "      <th>metric</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10180</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>8.406780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10420</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>7.718515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10500</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>6.407737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10540</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>5.391028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10580</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>7.604738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0546345d-db0c-4745-9890-a1b1349d7c14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0546345d-db0c-4745-9890-a1b1349d7c14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0546345d-db0c-4745-9890-a1b1349d7c14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-94e9751b-9af5-496b-a01d-a3db126792f3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94e9751b-9af5-496b-a01d-a3db126792f3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-94e9751b-9af5-496b-a01d-a3db126792f3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mefi_sub_long",
              "summary": "{\n  \"name\": \"mefi_sub_long\",\n  \"rows\": 7938,\n  \"fields\": [\n    {\n      \"column\": \"cbsa_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 294,\n        \"samples\": [\n          \"14010\",\n          \"11100\",\n          \"29020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mefi_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2007,\n        \"max\": 2017,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2017,\n          2012,\n          2007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"mefi_3b\",\n          \"mefi_1b\",\n          \"mefi_2c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2693591606288,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 5907,\n        \"samples\": [\n          5.066980463358704,\n          7.864333056591474,\n          7.441719096192301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 06 — Load MEFI sub-areas (R2: same as your working version)\n",
        "SUBSHEETS = [\"1A\",\"1B\",\"1C\",\"2A\",\"2B\",\"2C\",\"3A\",\"3B\",\"3C\"]\n",
        "\n",
        "def norm_name(s):\n",
        "    s = _as_str(s).str.lower()\n",
        "    # unify hyphens/dashes\n",
        "    s = (s.str.replace(\"–\", \"-\", regex=False)\n",
        "           .str.replace(\"—\", \"-\", regex=False)\n",
        "           .str.replace(\"‑\", \"-\", regex=False))  # non-breaking hyphen\n",
        "    # collapse spaces and strip\n",
        "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "    # remove common suffix tokens\n",
        "    s = (s.str.replace(\" msa\", \"\", regex=False)\n",
        "           .str.replace(\" metropolitan statistical area\", \"\", regex=False)\n",
        "           .str.replace(\" metropolitan division\", \"\", regex=False))\n",
        "    return s\n",
        "\n",
        "def build_name_to_cbsa_map(mefi_path, list_new):\n",
        "    sw = pd.read_excel(mefi_path, sheet_name=\"scores\", header=[0,1], dtype=str)\n",
        "    id_col = None\n",
        "    for c in sw.columns:\n",
        "        if c[1] == \"CBSA Code\":\n",
        "            id_col = c; break\n",
        "    if id_col is None:\n",
        "        for c in sw.columns:\n",
        "            s = sw[c].astype(str).str.fullmatch(r\"\\d{5}\")\n",
        "            if s.mean() > 0.3: id_col = c; break\n",
        "\n",
        "    name_col = None\n",
        "    for c in sw.columns:\n",
        "        if c[1] in [\"Metro Area\",\"CBSA Name\"]:\n",
        "            name_col = c; break\n",
        "\n",
        "    if (id_col is not None) and (name_col is not None):\n",
        "        m1 = sw[[id_col, name_col]].copy()\n",
        "        m1.columns = [\"cbsa_code\",\"metro_area\"]\n",
        "        m1[\"cbsa_code\"] = pad_cbsa(m1[\"cbsa_code\"])\n",
        "        m1[\"metro_area_norm\"] = norm_name(m1[\"metro_area\"])\n",
        "    else:\n",
        "        m1 = pd.DataFrame(columns=[\"cbsa_code\",\"metro_area_norm\"])\n",
        "\n",
        "    m2 = (list_new.rename(columns={\"cbsa_code\":\"cbsa_code\", \"cbsa_title\":\"metro_area\"})\n",
        "                  [[\"cbsa_code\",\"metro_area\"]].copy())\n",
        "    m2[\"cbsa_code\"] = pad_cbsa(m2[\"cbsa_code\"])\n",
        "    m2[\"metro_area_norm\"] = norm_name(m2[\"metro_area\"])\n",
        "\n",
        "    nm = (pd.concat([m1[[\"cbsa_code\",\"metro_area_norm\"]],\n",
        "                     m2[[\"cbsa_code\",\"metro_area_norm\"]]], ignore_index=True)\n",
        "            .dropna(subset=[\"cbsa_code\",\"metro_area_norm\"])\n",
        "            .drop_duplicates(\"metro_area_norm\"))\n",
        "    return nm\n",
        "\n",
        "def wide_subarea_to_long(df_mi, subtag):\n",
        "    metro_cols = [c for c in df_mi.columns if isinstance(c, tuple) and c[1] == \"Metro Area\"]\n",
        "    if not metro_cols:\n",
        "        return None\n",
        "    metro_col = metro_cols[0]\n",
        "    out = df_mi[[metro_col]].copy()\n",
        "    out.columns = [\"metro_area\"]\n",
        "\n",
        "    want_prefix = f\"{subtag} (score)\"\n",
        "    score_cols = [c for c in df_mi.columns if isinstance(c, tuple) and c[0]==want_prefix and c[1] in [2007,2012,2017]]\n",
        "    if not score_cols:\n",
        "        return None\n",
        "    for (top, yr) in score_cols:\n",
        "        out[f\"mefi_{subtag.lower()}_{yr}\"] = pd.to_numeric(df_mi[(top, yr)], errors=\"coerce\")\n",
        "\n",
        "    if out.filter(like=\"mefi_\", axis=1).notna().sum(axis=1).eq(0).all():\n",
        "        return None\n",
        "    return out\n",
        "\n",
        "def load_mefi_subareas(mefi_path, list_new):\n",
        "    name_map = build_name_to_cbsa_map(mefi_path, list_new)\n",
        "    long_parts = []\n",
        "    for subtag in SUBSHEETS:\n",
        "        try:\n",
        "            df_mi = pd.read_excel(mefi_path, sheet_name=subtag, header=[0,1], dtype=str)\n",
        "            sub_long = wide_subarea_to_long(df_mi, subtag)\n",
        "            if sub_long is None:\n",
        "                print(f\"Sub-area {subtag}: no usable '(score)' columns for 2007/2012/2017; skipping.\")\n",
        "                continue\n",
        "            tmp = sub_long.copy()\n",
        "            tmp[\"metro_area_norm\"] = norm_name(tmp[\"metro_area\"])\n",
        "            tmp = tmp.merge(name_map, on=\"metro_area_norm\", how=\"left\")\n",
        "\n",
        "            value_cols = [c for c in tmp.columns if c.startswith(\"mefi_\") and c.split(\"_\")[-1] in [\"2007\",\"2012\",\"2017\"]]\n",
        "            melted = tmp.melt(id_vars=[\"cbsa_code\"], value_vars=value_cols, var_name=\"metric_year\", value_name=\"value\")\n",
        "            melted[\"cbsa_code\"] = pad_cbsa(melted[\"cbsa_code\"])\n",
        "            melted = melted[melted[\"cbsa_code\"].notna()].copy()\n",
        "            melted[\"metric\"] = melted[\"metric_year\"].str.rsplit(\"_\", n=1).str[0]\n",
        "            melted[\"mefi_year\"] = melted[\"metric_year\"].str.rsplit(\"_\", n=1).str[1].astype(int)\n",
        "            melted = melted.drop(columns=[\"metric_year\"]).drop_duplicates()\n",
        "            long_parts.append(melted[[\"cbsa_code\",\"mefi_year\",\"metric\",\"value\"]])\n",
        "            print(f\"Sub-area {subtag}: captured metrics for years {sorted(melted['mefi_year'].unique())}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Sub-area {subtag}: error parsing ({e}); skipping.\")\n",
        "    return pd.concat(long_parts, ignore_index=True) if long_parts else pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\",\"metric\",\"value\"])\n",
        "\n",
        "# Run\n",
        "mefi_sub_long = load_mefi_subareas(mefi_path, list_new)\n",
        "mefi_sub_long.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "RW4yjdGPVyTX",
        "outputId": "017e2404-1f0b-4b67-ab34-107f1fc1e15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sub-area 1A: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 1B: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 1C: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 2A: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 2B: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 2C: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 3A: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 3B: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Sub-area 3C: captured metrics for years [np.int64(2007), np.int64(2012), np.int64(2017)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  cbsa_code  mefi_year   metric     value\n",
              "0     10180       2017  mefi_1a  8.406780\n",
              "1     10420       2017  mefi_1a  7.718515\n",
              "2     10500       2017  mefi_1a  6.407737\n",
              "3     10540       2017  mefi_1a  5.391028\n",
              "4     10580       2017  mefi_1a  7.604738"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a20ba776-ae5a-4f49-92d9-17d9193c802d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cbsa_code</th>\n",
              "      <th>mefi_year</th>\n",
              "      <th>metric</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10180</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>8.406780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10420</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>7.718515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10500</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>6.407737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10540</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>5.391028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10580</td>\n",
              "      <td>2017</td>\n",
              "      <td>mefi_1a</td>\n",
              "      <td>7.604738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a20ba776-ae5a-4f49-92d9-17d9193c802d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a20ba776-ae5a-4f49-92d9-17d9193c802d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a20ba776-ae5a-4f49-92d9-17d9193c802d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-24d4b830-09a0-4bfb-9f17-143aa3160409\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24d4b830-09a0-4bfb-9f17-143aa3160409')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-24d4b830-09a0-4bfb-9f17-143aa3160409 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mefi_sub_long",
              "summary": "{\n  \"name\": \"mefi_sub_long\",\n  \"rows\": 7938,\n  \"fields\": [\n    {\n      \"column\": \"cbsa_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 294,\n        \"samples\": [\n          \"14010\",\n          \"11100\",\n          \"29020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mefi_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2007,\n        \"max\": 2017,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2017,\n          2012,\n          2007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"mefi_3b\",\n          \"mefi_1b\",\n          \"mefi_2c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2693591606288,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 5907,\n        \"samples\": [\n          5.066980463358704,\n          7.864333056591474,\n          7.441719096192301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 06.QA — Sub-area QA\n",
        "print(\"mefi_sub_long years:\", sorted(mefi_sub_long[\"mefi_year\"].unique()))\n",
        "bad_codes = mefi_sub_long[\"cbsa_code\"].isna().sum()\n",
        "has_99999 = (mefi_sub_long[\"cbsa_code\"] == \"99999\").any()\n",
        "print(f\"Null cbsa_code rows in sub-areas: {bad_codes}\")\n",
        "print(f\"'99999' present in sub-areas?: {has_99999}\")\n",
        "\n",
        "core_keys = mefi_core[[\"cbsa_code\",\"mefi_year\"]].drop_duplicates()\n",
        "sub_keys  = mefi_sub_long[[\"cbsa_code\",\"mefi_year\"]].drop_duplicates()\n",
        "cov = core_keys.merge(sub_keys, on=[\"cbsa_code\",\"mefi_year\"], how=\"left\")[\"mefi_year\"].notna().mean()\n",
        "print(f\"Share of MEFI core keys with >=1 sub-area metric: {cov:.2%}\")\n",
        "\n",
        "dups = mefi_sub_long.duplicated([\"cbsa_code\",\"mefi_year\",\"metric\"], keep=False).sum()\n",
        "print(f\"Duplicate (cbsa,year,metric) rows in sub-areas: {dups}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B80DNFRhe0Mf",
        "outputId": "63708d38-a476-4d30-eb8a-018e98fc3462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mefi_sub_long years: [np.int64(2007), np.int64(2012), np.int64(2017)]\n",
            "Null cbsa_code rows in sub-areas: 0\n",
            "'99999' present in sub-areas?: False\n",
            "Share of MEFI core keys with >=1 sub-area metric: 100.00%\n",
            "Duplicate (cbsa,year,metric) rows in sub-areas: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping CBSA to MSAs"
      ],
      "metadata": {
        "id": "cNfB9dbh_kUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 07 (R5) — Build mefi_long with 100% population coverage\n",
        "import difflib, re\n",
        "\n",
        "def extract_states_key(title: pd.Series) -> pd.Series:\n",
        "    t = _as_str(title)\n",
        "    tail = t.str.split(\",\", n=1).str[-1].str.strip()\n",
        "    tokens = tail.str.replace(r\"[^A-Z\\-]\", \"\", regex=True).str.split(\"-\")\n",
        "    states = tokens.apply(lambda xs: sorted({x for x in xs if re.fullmatch(r\"[A-Z]{2}\", str(x))}))\n",
        "    return states.apply(lambda ss: \"|\".join(ss) if ss else \"\")\n",
        "\n",
        "def expand_abbrev_norm(s):\n",
        "    s = s.str.replace(r\"\\bst[\\. ]\", \"saint \",  regex=True)\n",
        "    s = s.str.replace(r\"\\bft[\\. ]\", \"fort \",   regex=True)\n",
        "    s = s.str.replace(r\"\\bmt[\\. ]\", \"mount \",  regex=True)\n",
        "    s = s.str.replace(r\"\\bste[\\. ]\", \"sainte \",regex=True)\n",
        "    return s\n",
        "\n",
        "def build_union_name_map(mefi_path, list_new, list_old):\n",
        "    sw = pd.read_excel(mefi_path, sheet_name=\"scores\", header=[0,1], dtype=str)\n",
        "    id_col = None\n",
        "    for c in sw.columns:\n",
        "        if c[1] == \"CBSA Code\": id_col = c; break\n",
        "    if id_col is None:\n",
        "        for c in sw.columns:\n",
        "            if sw[c].astype(str).str.fullmatch(r\"\\d{5}\").mean() > 0.3:\n",
        "                id_col = c; break\n",
        "    name_col = None\n",
        "    for c in sw.columns:\n",
        "        if c[1] in [\"Metro Area\",\"CBSA Name\"]:\n",
        "            name_col = c; break\n",
        "\n",
        "    parts = []\n",
        "    if (id_col is not None) and (name_col is not None):\n",
        "        m1 = sw[[id_col, name_col]].copy()\n",
        "        m1.columns = [\"cbsa_code\",\"metro_area\"]\n",
        "        m1[\"cbsa_code\"] = pad_cbsa(m1[\"cbsa_code\"])\n",
        "        m1[\"metro_area_norm\"] = expand_abbrev_norm(norm_name(m1[\"metro_area\"]))\n",
        "        m1[\"states_key\"] = extract_states_key(m1[\"metro_area\"])\n",
        "        parts.append(m1[[\"cbsa_code\",\"metro_area_norm\",\"states_key\"]])\n",
        "\n",
        "    for src in (list_new, list_old):\n",
        "        m = src.rename(columns={\"cbsa_code\":\"cbsa_code\", \"cbsa_title\":\"metro_area\"})[[\"cbsa_code\",\"metro_area\"]].copy()\n",
        "        m[\"cbsa_code\"] = pad_cbsa(m[\"cbsa_code\"])\n",
        "        m[\"metro_area_norm\"] = expand_abbrev_norm(norm_name(m[\"metro_area\"]))\n",
        "        m[\"states_key\"] = extract_states_key(m[\"metro_area\"])\n",
        "        parts.append(m[[\"cbsa_code\",\"metro_area_norm\",\"states_key\"]])\n",
        "\n",
        "    nm = (pd.concat(parts, ignore_index=True)\n",
        "            .dropna(subset=[\"cbsa_code\",\"metro_area_norm\"])\n",
        "            .drop_duplicates([\"metro_area_norm\",\"states_key\"]))\n",
        "    return nm  # cbsa_code, metro_area_norm, states_key\n",
        "\n",
        "def fuzzy_attach_codes(bea_pop_normed, name_map, min_ratio=0.94):\n",
        "    df = bea_pop_normed.copy()\n",
        "    need = df[\"cbsa_code\"].isna()\n",
        "    logs = []\n",
        "    if need.any():\n",
        "        by_state = {k: g for k,g in name_map.groupby(\"states_key\")}\n",
        "        for i in df[need].index:\n",
        "            nm = df.at[i, \"metro_area_norm\"]\n",
        "            sk = df.at[i, \"states_key\"]\n",
        "            cands = by_state.get(sk, name_map)\n",
        "            choices = cands[\"metro_area_norm\"].tolist()\n",
        "            if not choices: continue\n",
        "            best = difflib.get_close_matches(nm, choices, n=1, cutoff=min_ratio)\n",
        "            if best:\n",
        "                bm = best[0]\n",
        "                ratio = difflib.SequenceMatcher(None, nm, bm).ratio()\n",
        "                code = cands.loc[cands[\"metro_area_norm\"]==bm, \"cbsa_code\"].iloc[0]\n",
        "                df.at[i, \"cbsa_code\"] = code\n",
        "                logs.append({\"bea_name\": nm, \"states_key\": sk, \"best_match\": bm, \"ratio\": ratio, \"cbsa_code\": code})\n",
        "    return df, pd.DataFrame(logs)\n",
        "\n",
        "def load_mefi_population_v5(mefi_path, list_new, list_old,\n",
        "                            temporal_backfill=True, impute_from_2017=True):\n",
        "    # 1) Preferred: population from 'scores'\n",
        "    try:\n",
        "        sw = pd.read_excel(mefi_path, sheet_name=\"scores\", header=[0,1], dtype=str)\n",
        "        id_col = None\n",
        "        for c in sw.columns:\n",
        "            if c[1] == \"CBSA Code\": id_col = c; break\n",
        "        if id_col is None:\n",
        "            for c in sw.columns:\n",
        "                if sw[c].astype(str).str.fullmatch(r\"\\d{5}\").mean() > 0.3:\n",
        "                    id_col = c; break\n",
        "        scores_pop = pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\",\"mefi_population\",\"pop_source\"])\n",
        "        if id_col is not None:\n",
        "            sw = sw.copy()\n",
        "            sw[\"cbsa_code\"] = pad_cbsa(sw[id_col])\n",
        "            pop_cols = [c for c in sw.columns if isinstance(c, tuple) and \"population\" in str(c[1]).lower()]\n",
        "            rows = []\n",
        "            for c in pop_cols:\n",
        "                yr_str = str(c[1]).split()[0]\n",
        "                if yr_str.isdigit():\n",
        "                    yr = int(yr_str)\n",
        "                    if yr in [2007, 2012, 2017]:\n",
        "                        v = pd.to_numeric(sw[c], errors=\"coerce\")\n",
        "                        rows.append(pd.DataFrame({\n",
        "                            \"cbsa_code\": sw[\"cbsa_code\"], \"mefi_year\": yr,\n",
        "                            \"mefi_population\": v, \"pop_source\": \"scores\"\n",
        "                        }))\n",
        "            scores_pop = pd.concat(rows, ignore_index=True) if rows else scores_pop\n",
        "    except Exception:\n",
        "        scores_pop = pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\",\"mefi_population\",\"pop_source\"])\n",
        "\n",
        "    # 2) Fallback: BEA 'Total population' with enhanced mapping\n",
        "    try:\n",
        "        bea = pd.read_excel(mefi_path, sheet_name=\"BEA\", header=[0,1], dtype=str)\n",
        "        metro_cols = [c for c in bea.columns if isinstance(c, tuple) and c[1] == \"Metro Area\"]\n",
        "        if metro_cols:\n",
        "            metro_col = metro_cols[0]\n",
        "            base = bea[[metro_col]].copy()\n",
        "            base.columns = [\"metro_area\"]\n",
        "            base[\"metro_area_norm\"] = expand_abbrev_norm(norm_name(base[\"metro_area\"]))\n",
        "            base[\"states_key\"] = extract_states_key(base[\"metro_area\"])\n",
        "            popcols = [c for c in bea.columns if isinstance(c, tuple) and str(c[0]).strip().lower()==\"total population\"]\n",
        "            rows = []\n",
        "            for c in popcols:\n",
        "                yr_str = str(c[1]).split()[0]\n",
        "                if yr_str.isdigit():\n",
        "                    yr = int(yr_str)\n",
        "                    if yr in [2007, 2012, 2017]:\n",
        "                        vals = pd.to_numeric(bea[c], errors=\"coerce\")\n",
        "                        tmp = base.copy()\n",
        "                        tmp[\"mefi_year\"] = yr\n",
        "                        tmp[\"mefi_population\"] = vals\n",
        "                        rows.append(tmp)\n",
        "            bea_long = pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=[\"metro_area\",\"metro_area_norm\",\"states_key\",\"mefi_year\",\"mefi_population\"])\n",
        "        else:\n",
        "            bea_long = pd.DataFrame(columns=[\"metro_area\",\"metro_area_norm\",\"states_key\",\"mefi_year\",\"mefi_population\"])\n",
        "    except Exception:\n",
        "        bea_long = pd.DataFrame(columns=[\"metro_area\",\"metro_area_norm\",\"states_key\",\"mefi_year\",\"mefi_population\"])\n",
        "\n",
        "    # Exact name join + fuzzy within state set\n",
        "    name_map_union = build_union_name_map(mefi_path, list_new, list_old)\n",
        "    bea_joined = bea_long.merge(name_map_union, on=[\"metro_area_norm\",\"states_key\"], how=\"left\")\n",
        "    bea_joined.loc[:, \"cbsa_code\"] = pad_cbsa(bea_joined[\"cbsa_code\"])\n",
        "    bea_joined, fuzzy_log = fuzzy_attach_codes(bea_joined, name_map_union, min_ratio=0.94)\n",
        "\n",
        "    # Keep BEA rows that resolved to a code; tag source\n",
        "    bea_part = bea_joined.dropna(subset=[\"cbsa_code\"])[[\"cbsa_code\",\"mefi_year\",\"mefi_population\"]].copy()\n",
        "    if not bea_part.empty:\n",
        "        bea_part.loc[:, \"pop_source\"] = \"bea\"\n",
        "\n",
        "    # Combine, prefer 'scores' > 'bea'\n",
        "    parts = []\n",
        "    if not scores_pop.empty:\n",
        "        parts.append(scores_pop[[\"cbsa_code\",\"mefi_year\",\"mefi_population\",\"pop_source\"]])\n",
        "    if not bea_part.empty:\n",
        "        parts.append(bea_part[[\"cbsa_code\",\"mefi_year\",\"mefi_population\",\"pop_source\"]])\n",
        "    out = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\",\"mefi_population\",\"pop_source\"])\n",
        "    out = (out.sort_values(by=[\"cbsa_code\",\"mefi_year\",\"pop_source\"], key=lambda s: s.eq(\"scores\").map({True:0, False:1}))\n",
        "              .drop_duplicates([\"cbsa_code\",\"mefi_year\"], keep=\"first\"))\n",
        "\n",
        "    # ---- Temporal backfill to reach 100% coverage (imputed but flagged) ----\n",
        "    if temporal_backfill or impute_from_2017:\n",
        "        pop = out.pivot(index=\"cbsa_code\", columns=\"mefi_year\", values=\"mefi_population\")\n",
        "        src = out.pivot(index=\"cbsa_code\", columns=\"mefi_year\", values=\"pop_source\").astype(\"string\")\n",
        "\n",
        "        # Ensure columns present\n",
        "        for yr in [2007, 2012, 2017]:\n",
        "            if yr not in pop.columns: pop[yr] = np.nan\n",
        "            if yr not in src.columns: src[yr] = pd.NA\n",
        "\n",
        "        # 1) Fill 2007 from 2012 (if 2007 missing & 2012 present)\n",
        "        m = pop[2007].isna() & pop[2012].notna()\n",
        "        pop.loc[m, 2007] = pop.loc[m, 2012]\n",
        "        src.loc[m, 2007] = src.loc[m, 2007].fillna(\"imputed_from_2012\")\n",
        "\n",
        "        # 2) Fill 2012 from 2007 (if 2012 missing & 2007 present)\n",
        "        m = pop[2012].isna() & pop[2007].notna()\n",
        "        pop.loc[m, 2012] = pop.loc[m, 2007]\n",
        "        src.loc[m, 2012] = src.loc[m, 2012].fillna(\"imputed_from_2007\")\n",
        "\n",
        "        # 3) Optionally carry back from 2017\n",
        "        if impute_from_2017:\n",
        "            m = pop[2007].isna() & pop[2017].notna()\n",
        "            pop.loc[m, 2007] = pop.loc[m, 2017]\n",
        "            src.loc[m, 2007] = src.loc[m, 2007].fillna(\"imputed_from_2017\")\n",
        "\n",
        "            m = pop[2012].isna() & pop[2017].notna()\n",
        "            pop.loc[m, 2012] = pop.loc[m, 2017]\n",
        "            src.loc[m, 2012] = src.loc[m, 2012].fillna(\"imputed_from_2017\")\n",
        "\n",
        "        # Back to long; prefer original values\n",
        "        bf = pop.stack().reset_index(name=\"mefi_population\")\n",
        "        bf.columns = [\"cbsa_code\",\"mefi_year\",\"mefi_population\"]\n",
        "        bf_src = src.stack().reset_index(name=\"pop_source\")\n",
        "        bf_src.columns = [\"cbsa_code\",\"mefi_year\",\"pop_source\"]\n",
        "\n",
        "        merged = out.merge(bf, on=[\"cbsa_code\",\"mefi_year\"], how=\"outer\", suffixes=(\"\", \"_bf\"))\n",
        "        merged = merged.merge(bf_src, on=[\"cbsa_code\",\"mefi_year\"], how=\"left\", suffixes=(\"\", \"_bf\"))\n",
        "        merged[\"mefi_population\"] = merged[\"mefi_population\"].combine_first(merged[\"mefi_population_bf\"])\n",
        "        merged[\"pop_source\"]      = merged[\"pop_source\"].combine_first(merged[\"pop_source_bf\"])\n",
        "        out = merged[[\"cbsa_code\",\"mefi_year\",\"mefi_population\",\"pop_source\"]]\n",
        "\n",
        "    # Clean types\n",
        "    out = out.copy()\n",
        "    out.loc[:, \"cbsa_code\"] = pad_cbsa(out[\"cbsa_code\"])\n",
        "    out.loc[:, \"mefi_year\"] = out[\"mefi_year\"].astype(int)\n",
        "    out.loc[:, \"mefi_population\"] = pd.to_numeric(out[\"mefi_population\"], errors=\"coerce\")\n",
        "    out.loc[:, \"pop_source\"] = out[\"pop_source\"].astype(\"string\")\n",
        "    out = out.dropna(subset=[\"cbsa_code\"]).drop_duplicates([\"cbsa_code\",\"mefi_year\"])\n",
        "\n",
        "    # Save fuzzy log for audit\n",
        "    if 'fuzzy_log' in locals() and not fuzzy_log.empty:\n",
        "        fuzzy_log.to_csv(f\"{OUT}/bea_population_fuzzy_matches.csv\", index=False)\n",
        "    return out\n",
        "\n",
        "# Build population with aggressive backfill to reach ~100% cross-check coverage\n",
        "mefi_pop = load_mefi_population_v5(mefi_path, list_new, list_old,\n",
        "                                   temporal_backfill=True, impute_from_2017=True)\n",
        "\n",
        "# Sub-areas -> wide (same as before)\n",
        "if not mefi_sub_long.empty:\n",
        "    mefi_sub_wide = (mefi_sub_long\n",
        "                     .assign(value=lambda d: pd.to_numeric(d[\"value\"], errors=\"coerce\"))\n",
        "                     .pivot_table(index=[\"cbsa_code\",\"mefi_year\"], columns=\"metric\", values=\"value\", aggfunc=\"first\")\n",
        "                     .reset_index())\n",
        "else:\n",
        "    mefi_sub_wide = pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\"])\n",
        "\n",
        "# Merge core + subareas + population\n",
        "mefi_long = (mefi_core.merge(mefi_sub_wide, on=[\"cbsa_code\",\"mefi_year\"], how=\"left\")\n",
        "                      .merge(mefi_pop, on=[\"cbsa_code\",\"mefi_year\"], how=\"left\"))\n",
        "\n",
        "assert not mefi_long.duplicated([\"cbsa_code\",\"mefi_year\"]).any(), \"Duplicate (cbsa_code, mefi_year) in MEFI long.\"\n",
        "\n",
        "# Hard QA: require 100% population coverage across all MEFI years\n",
        "cov_by_mefi_year = (mefi_long.assign(has_pop=mefi_long[\"mefi_population\"].notna())\n",
        "                               .groupby(\"mefi_year\")[\"has_pop\"].mean().sort_index())\n",
        "print(\"MEFI population coverage by MEFI year (should be 1.0 each):\")\n",
        "print(cov_by_mefi_year.to_string())\n",
        "assert (cov_by_mefi_year == 1.0).all(), \"MEFI population coverage is not 100% for some MEFI years.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y4fr79ze3HE",
        "outputId": "bc6eb447-a548-44bf-c86b-c9cda62fb209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEFI population coverage by MEFI year (should be 1.0 each):\n",
            "mefi_year\n",
            "2007    1.0\n",
            "2012    1.0\n",
            "2017    1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 07.QA — population coverage check (optional)\n",
        "cov = (mefi_long.assign(has_pop=mefi_long[\"mefi_population\"].notna())\n",
        "                .groupby(\"mefi_year\")[\"has_pop\"].mean()\n",
        "                .sort_index())\n",
        "print(\"MEFI population coverage by year (share non-null):\")\n",
        "print(cov.to_string())\n",
        "\n",
        "# sanity: no negative or zero pop (if present, flag)\n",
        "if \"mefi_population\" in mefi_long.columns:\n",
        "    bad = mefi_long[\"mefi_population\"].dropna().le(0).sum()\n",
        "    print(\"Non-positive mefi_population rows:\", bad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDkX-7m1e7-N",
        "outputId": "9e707e57-79c0-4f6e-e2b1-f714205cb28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEFI population coverage by year (share non-null):\n",
            "mefi_year\n",
            "2007    1.0\n",
            "2012    1.0\n",
            "2017    1.0\n",
            "Non-positive mefi_population rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 08 — Mapping functions (REVISED)\n",
        "# Assumes: list_old, list_new, det_map, NON_CBSA_CODES, pad_cbsa, zpad, pad_state, pad_county defined\n",
        "\n",
        "def build_county_keys(df):\n",
        "    if \"COUNTY_FIPS\" in df.columns:\n",
        "        df[\"county_fips5\"] = zpad(df[\"COUNTY_FIPS\"], 5)\n",
        "    else:\n",
        "        df[\"county_fips5\"] = pad_state(df[\"_STATE\"]) + pad_county(df[\"_CNTY\"])\n",
        "    df[\"state_fips\"]  = df[\"county_fips5\"].str[:2]\n",
        "    df[\"county_fips\"] = df[\"county_fips5\"].str[2:]\n",
        "    return df\n",
        "\n",
        "def normalize_cbsa_raw(df):\n",
        "    df[\"cbsa_code_raw\"] = pad_cbsa(df.get(\"CBSA_CODE\"))\n",
        "    return df\n",
        "\n",
        "def preserve_outside_cbsa(raw_code, candidate):\n",
        "    if pd.notna(raw_code) and str(raw_code) in NON_CBSA_CODES:\n",
        "        return \"99999\"\n",
        "    return candidate\n",
        "\n",
        "def map_2007_2008_2012(df):\n",
        "    xw = list_new.rename(columns={\"cbsa_code\":\"cbsa_from_county_current\"})\n",
        "    m  = df.merge(xw, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "    m[\"cbsa_from_det_map\"] = m[\"cbsa_code_raw\"].map(det_map)\n",
        "    m[\"cbsa_code_current\"] = np.where(m[\"cbsa_from_det_map\"].notna(),\n",
        "                                      m[\"cbsa_from_det_map\"],\n",
        "                                      m[\"cbsa_from_county_current\"])\n",
        "    m[\"cbsa_code_current\"] = m.apply(\n",
        "        lambda r: preserve_outside_cbsa(r[\"cbsa_code_raw\"], r[\"cbsa_code_current\"]), axis=1\n",
        "    )\n",
        "    return m\n",
        "\n",
        "def map_2017(df):\n",
        "    m = df.merge(list_old.rename(columns={\"cbsa_code\":\"cbsa_legacy\"}),\n",
        "                 on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "    m[\"cbsa_from_det_map\"] = m[\"cbsa_legacy\"].map(det_map)\n",
        "    m = m.merge(list_new.rename(columns={\"cbsa_code\":\"cbsa_from_county_current\"}),\n",
        "                on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "    m[\"cbsa_code_current\"] = np.where(m[\"cbsa_from_det_map\"].notna(),\n",
        "                                      m[\"cbsa_from_det_map\"],\n",
        "                                      m[\"cbsa_from_county_current\"])\n",
        "    m[\"cbsa_code_current\"] = m.apply(\n",
        "        lambda r: preserve_outside_cbsa(r[\"cbsa_code_raw\"], r[\"cbsa_code_current\"]), axis=1\n",
        "    )\n",
        "    return m\n",
        "\n",
        "def map_2022(df):\n",
        "    m = df.copy()\n",
        "    m[\"cbsa_from_det_map\"] = m[\"cbsa_code_raw\"].map(det_map)\n",
        "    m = m.merge(list_new.rename(columns={\"cbsa_code\":\"cbsa_from_county_current\"}),\n",
        "                on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "    m[\"cbsa_code_current\"] = np.where(m[\"cbsa_from_det_map\"].notna(),\n",
        "                                      m[\"cbsa_from_det_map\"],\n",
        "                                      m[\"cbsa_from_county_current\"])\n",
        "    m[\"cbsa_code_current\"] = m.apply(\n",
        "        lambda r: preserve_outside_cbsa(r[\"cbsa_code_raw\"], r[\"cbsa_code_current\"]), axis=1\n",
        "    )\n",
        "    return m\n",
        "\n",
        "def load_brfss_year(year, path):\n",
        "    df = pd.read_csv(path, dtype=str, low_memory=False)\n",
        "    df[\"BRFSS_YEAR\"] = year\n",
        "    df = build_county_keys(df)\n",
        "    df = normalize_cbsa_raw(df)\n",
        "\n",
        "    if year in (2007, 2008, 2012):\n",
        "        m = map_2007_2008_2012(df)\n",
        "    elif year == 2017:\n",
        "        m = map_2017(df)\n",
        "    elif year == 2022:\n",
        "        m = map_2022(df)\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected year\")\n",
        "\n",
        "    # final padding & keep NaN if not numeric 5-digit\n",
        "    m[\"cbsa_code_current\"] = pad_cbsa(m[\"cbsa_code_current\"])\n",
        "    # Re‑impose 99999 if raw had it\n",
        "    m.loc[m[\"cbsa_code_raw\"].isin(NON_CBSA_CODES), \"cbsa_code_current\"] = \"99999\"\n",
        "    return m\n"
      ],
      "metadata": {
        "id": "i9r4_RCnhEcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 08.PATCH-1 — map_2017 must remap the RAW CBSA_CODE too (not only county-based legacy)\n",
        "\n",
        "def map_2017(df):\n",
        "    # 1) Try deterministic legacy→current on RAW CBSA codes from BRFSS 2017\n",
        "    df = df.copy()\n",
        "    df[\"cbsa_from_det_raw\"] = df[\"cbsa_code_raw\"].map(det_map)\n",
        "\n",
        "    # 2) Also build a county-based legacy code from the 2013–2020 list (list_old),\n",
        "    #    then convert via det_map as a fallback\n",
        "    m = df.merge(\n",
        "        list_old.rename(columns={\"cbsa_code\":\"cbsa_legacy\"})[[\"state_fips\",\"county_fips\",\"cbsa_legacy\"]],\n",
        "        on=[\"state_fips\",\"county_fips\"], how=\"left\"\n",
        "    )\n",
        "    m[\"cbsa_from_det_legacy\"] = m[\"cbsa_legacy\"].map(det_map)\n",
        "\n",
        "    # 3) Final fallback: current code via 2023 list (list_new) from county\n",
        "    m = m.merge(\n",
        "        list_new.rename(columns={\"cbsa_code\":\"cbsa_from_county_current\"})[[\"state_fips\",\"county_fips\",\"cbsa_from_county_current\"]],\n",
        "        on=[\"state_fips\",\"county_fips\"], how=\"left\"\n",
        "    )\n",
        "\n",
        "    # 4) Choose best available: RAW→det, then LEGACY→det, then county→current\n",
        "    m[\"cbsa_code_current\"] = (\n",
        "        m[\"cbsa_from_det_raw\"]\n",
        "        .combine_first(m[\"cbsa_from_det_legacy\"])\n",
        "        .combine_first(m[\"cbsa_from_county_current\"])\n",
        "    )\n",
        "\n",
        "    # 5) Preserve 99999 from raw\n",
        "    m[\"cbsa_code_current\"] = m.apply(\n",
        "        lambda r: \"99999\" if (pd.notna(r[\"cbsa_code_raw\"]) and str(r[\"cbsa_code_raw\"])==\"99999\") else r[\"cbsa_code_current\"],\n",
        "        axis=1\n",
        "    )\n",
        "    return m\n"
      ],
      "metadata": {
        "id": "zMqpD9o4x-W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 08.PATCH-2 — Use CBSA_CODE or _MMSA as raw key; propagate 99999 if present\n",
        "\n",
        "def normalize_cbsa_raw(df):\n",
        "    # Prefer CBSA_CODE; if missing/blank, fall back to _MMSA (present in 2017/2022 SMART)\n",
        "    if \"CBSA_CODE\" in df.columns and df[\"CBSA_CODE\"].notna().any():\n",
        "        raw = df[\"CBSA_CODE\"]\n",
        "    elif \"_MMSA\" in df.columns:\n",
        "        raw = df[\"_MMSA\"]\n",
        "    else:\n",
        "        raw = pd.Series([np.nan]*len(df))\n",
        "\n",
        "    df[\"cbsa_code_raw\"] = pad_cbsa(raw)\n",
        "\n",
        "    # Ensure 'outside CBSA' is carried through if either raw field flags it\n",
        "    if \"_MMSA\" in df.columns:\n",
        "        df.loc[_as_str(df[\"_MMSA\"]).str.strip() == \"99999\", \"cbsa_code_raw\"] = \"99999\"\n",
        "    if \"CBSA_CODE\" in df.columns:\n",
        "        df.loc[_as_str(df[\"CBSA_CODE\"]).str.strip() == \"99999\", \"cbsa_code_raw\"] = \"99999\"\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "z76Qomew3Lpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 08.PATCH-3 — Force 'outside CBSA' when nothing matches in 2017/2022\n",
        "\n",
        "def map_2017(df):\n",
        "    df = df.copy()\n",
        "    # 1) Try deterministic legacy→current on RAW CBSA\n",
        "    df[\"cbsa_from_det_raw\"] = df[\"cbsa_code_raw\"].map(det_map)\n",
        "\n",
        "    # 2) County-based LEGACY (2013–2020 list), then det_map\n",
        "    m = df.merge(\n",
        "        list_old.rename(columns={\"cbsa_code\":\"cbsa_legacy\"})[[\"state_fips\",\"county_fips\",\"cbsa_legacy\"]],\n",
        "        on=[\"state_fips\",\"county_fips\"], how=\"left\"\n",
        "    )\n",
        "    m[\"cbsa_from_det_legacy\"] = m[\"cbsa_legacy\"].map(det_map)\n",
        "\n",
        "    # 3) County-based CURRENT (2023 list)\n",
        "    m = m.merge(\n",
        "        list_new.rename(columns={\"cbsa_code\":\"cbsa_from_county_current\"})[[\"state_fips\",\"county_fips\",\"cbsa_from_county_current\"]],\n",
        "        on=[\"state_fips\",\"county_fips\"], how=\"left\"\n",
        "    )\n",
        "\n",
        "    # 4) Choose: RAW→det, then LEGACY→det, then county→current\n",
        "    m[\"cbsa_code_current\"] = (\n",
        "        m[\"cbsa_from_det_raw\"]\n",
        "          .combine_first(m[\"cbsa_from_det_legacy\"])\n",
        "          .combine_first(m[\"cbsa_from_county_current\"])\n",
        "    )\n",
        "\n",
        "    # 5) Preserve raw 99999\n",
        "    m.loc[_as_str(m[\"cbsa_code_raw\"]).str.strip()==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "\n",
        "    # 6) FINAL: if still null after all lookups, it is outside CBSA → 99999\n",
        "    m[\"cbsa_code_current\"] = pad_cbsa(m[\"cbsa_code_current\"])\n",
        "    m.loc[m[\"cbsa_code_current\"].isna(), \"cbsa_code_current\"] = \"99999\"\n",
        "    return m\n",
        "\n",
        "def map_2022(df):\n",
        "    m = df.copy()\n",
        "    # 1) RAW det_map\n",
        "    m[\"cbsa_from_det_raw\"] = m[\"cbsa_code_raw\"].map(det_map)\n",
        "    # 2) County-based CURRENT\n",
        "    m = m.merge(\n",
        "        list_new.rename(columns={\"cbsa_code\":\"cbsa_from_county_current\"})[[\"state_fips\",\"county_fips\",\"cbsa_from_county_current\"]],\n",
        "        on=[\"state_fips\",\"county_fips\"], how=\"left\"\n",
        "    )\n",
        "    # 3) Choose: RAW→det else county→current\n",
        "    m[\"cbsa_code_current\"] = m[\"cbsa_from_det_raw\"].combine_first(m[\"cbsa_from_county_current\"])\n",
        "\n",
        "    # 4) Preserve raw 99999\n",
        "    m.loc[_as_str(m[\"cbsa_code_raw\"]).str.strip()==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "\n",
        "    # 5) FINAL: if still null → outside CBSA\n",
        "    m[\"cbsa_code_current\"] = pad_cbsa(m[\"cbsa_code_current\"])\n",
        "    m.loc[m[\"cbsa_code_current\"].isna(), \"cbsa_code_current\"] = \"99999\"\n",
        "    return m\n"
      ],
      "metadata": {
        "id": "jrR8F4OQ3Mpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 09 — Build validation sets\n",
        "valid_cbsa_by_mefi_year = {\n",
        "    y: set(mefi_long.loc[mefi_long[\"mefi_year\"]==y, \"cbsa_code\"].unique())\n",
        "    for y in [2007, 2012, 2017]\n",
        "}\n",
        "{y: len(s) for y,s in valid_cbsa_by_mefi_year.items()}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsoLHAXBvN8M",
        "outputId": "6f457d6c-867e-4b5c-ccec-2373727e815c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2007: 383, 2012: 383, 2017: 383}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Mapping all 5 years ( starts here)"
      ],
      "metadata": {
        "id": "Rjzw7dmj_oWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 — Load & map all five BRFSS years\n",
        "BRFSS_FILES = {\n",
        "    2007: f\"{IN}/SMART_2007_individual.csv\",\n",
        "    2008: f\"{IN}/SMART_2008_individual.csv\",\n",
        "    2012: f\"{IN}/SMART_2012_individual.csv\",\n",
        "    2017: f\"{IN}/SMART_2017_individual.csv\",\n",
        "    2022: f\"{IN}/SMART_2022_individual.csv\",\n",
        "}\n",
        "\n",
        "mapped_by_year = {}\n",
        "for yr, p in BRFSS_FILES.items():\n",
        "    m = load_brfss_year(yr, p)\n",
        "    miss = m[\"cbsa_code_current\"].isna().mean()\n",
        "    n_outside = (m[\"cbsa_code_current\"]==\"99999\").sum()\n",
        "    print(f\"{yr}: cbsa_code_current missing ratio = {miss:.2%} | outside-CBSA rows (99999) = {n_outside:,}\")\n",
        "    mapped_by_year[yr] = m\n",
        "    (m[[\"state_fips\",\"county_fips\",\"cbsa_code_current\"]]\n",
        "      .dropna().drop_duplicates()\n",
        "      .to_csv(f\"{OUT}/county_to_cbsa_3col_{yr}.csv\", index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP5JrFJEvSah",
        "outputId": "ef2617fa-888f-48a0-eee3-d5c69378f2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2007: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 20,058\n",
            "2008: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 19,112\n",
            "2012: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 25,788\n",
            "2017: cbsa_code_current missing ratio = 26.45% | outside-CBSA rows (99999) = 0\n",
            "2022: cbsa_code_current missing ratio = 31.46% | outside-CBSA rows (99999) = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.PATCH-1 (R2) — Robust CBSA class lookup\n",
        "\n",
        "def _find_col_tokenized(df, must_have=(), any_of=()):\n",
        "    \"\"\"\n",
        "    Return the first column whose lower() name contains all tokens in must_have,\n",
        "    and at least one of tokens in any_of (if provided).\n",
        "    \"\"\"\n",
        "    cols = list(df.columns)\n",
        "    for c in cols:\n",
        "        name = str(c).strip().lower()\n",
        "        if all(tok in name for tok in must_have) and (not any_of or any(tok in name for tok in any_of)):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def _derive_class_from_values(series):\n",
        "    s = series.astype(str).str.lower()\n",
        "    mic = s.str.contains(\"micropolitan\")\n",
        "    met = s.str.contains(\"metropolitan\")\n",
        "    out = pd.Series(index=series.index, dtype=\"string\")\n",
        "    out.loc[mic] = \"Micropolitan\"\n",
        "    out.loc[met & ~mic] = \"Metropolitan\"\n",
        "    return out\n",
        "\n",
        "def _build_one_lut(df):\n",
        "    # Try to locate code, class, and title columns under many header variants\n",
        "    if df is None or df.empty:\n",
        "        return pd.DataFrame(columns=[\"cbsa_code\",\"cbsa_class\"])\n",
        "\n",
        "    # Prefer normalized names if present\n",
        "    code_col  = \"cbsa_code\"  if \"cbsa_code\"  in df.columns else _find_col_tokenized(df, must_have=(\"cbsa\",), any_of=(\"code\",))\n",
        "    class_col = _find_col_tokenized(df, any_of=(\"metropolitan/micropolitan\", \"metropolitan\", \"micropolitan\", \"statistical area\"))\n",
        "    title_col = \"cbsa_title\" if \"cbsa_title\" in df.columns else _find_col_tokenized(df, any_of=(\"cbsa title\",\"title\",\"metro area\",\"cbsa name\"))\n",
        "\n",
        "    if code_col is None:\n",
        "        return pd.DataFrame(columns=[\"cbsa_code\",\"cbsa_class\"])  # nothing we can do\n",
        "\n",
        "    tmp = df[[code_col]].copy()\n",
        "    tmp.columns = [\"cbsa_code\"]\n",
        "    tmp[\"cbsa_code\"] = pad_cbsa(tmp[\"cbsa_code\"])\n",
        "\n",
        "    # 1) Use explicit class if we found a class column\n",
        "    if class_col is not None:\n",
        "        raw = df[class_col]\n",
        "        tmp[\"cbsa_class\"] = _derive_class_from_values(raw)\n",
        "\n",
        "    # 2) Otherwise try to derive from title\n",
        "    if (\"cbsa_class\" not in tmp.columns or tmp[\"cbsa_class\"].isna().all()) and (title_col is not None):\n",
        "        derived = _derive_class_from_values(df[title_col])\n",
        "        if \"cbsa_class\" in tmp.columns:\n",
        "            tmp[\"cbsa_class\"] = tmp[\"cbsa_class\"].fillna(derived)\n",
        "        else:\n",
        "            tmp[\"cbsa_class\"] = derived\n",
        "\n",
        "    # 3) Final cleanup\n",
        "    tmp[\"cbsa_class\"] = tmp[\"cbsa_class\"].fillna(\"Unknown\")\n",
        "    tmp = tmp.dropna(subset=[\"cbsa_code\"]).drop_duplicates(subset=[\"cbsa_code\"])\n",
        "    return tmp[[\"cbsa_code\",\"cbsa_class\"]]\n",
        "\n",
        "def build_cbsa_class_lookup(list_new, list_old, mefi_long=None):\n",
        "    frames = []\n",
        "    frames.append(_build_one_lut(list_new))\n",
        "    frames.append(_build_one_lut(list_old))\n",
        "\n",
        "    # Fallback: if both empty, seed from MEFI (MEFI CBSAs are Metropolitan)\n",
        "    if all(f.empty for f in frames):\n",
        "        if mefi_long is not None and not mefi_long.empty:\n",
        "            seed = (mefi_long[[\"cbsa_code\"]].drop_duplicates().copy())\n",
        "            seed[\"cbsa_class\"] = \"Metropolitan\"\n",
        "            frames.append(seed)\n",
        "        else:\n",
        "            # last resort: empty lut (no crash)\n",
        "            return pd.DataFrame(columns=[\"cbsa_code\",\"cbsa_class\"])\n",
        "\n",
        "    lut = (pd.concat([f for f in frames if not f.empty], ignore_index=True)\n",
        "             .dropna(subset=[\"cbsa_code\"])\n",
        "             .drop_duplicates(subset=[\"cbsa_code\"]))\n",
        "    # Prefer 'Metropolitan' if the same code appears with conflicting labels\n",
        "    lut = (lut.sort_values(by=\"cbsa_class\", key=lambda s: s.eq(\"Metropolitan\").map({True:0, False:1}))\n",
        "             .drop_duplicates(\"cbsa_code\", keep=\"first\"))\n",
        "    return lut\n",
        "\n",
        "# Build/refresh the class lookup\n",
        "cbsa_class_lut = build_cbsa_class_lookup(list_new, list_old, mefi_long=mefi_long)\n",
        "\n",
        "# Quick QA\n",
        "print(\"CBSA class counts (lookup):\")\n",
        "print(cbsa_class_lut[\"cbsa_class\"].value_counts(dropna=False).to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihwEEoN_yDYp",
        "outputId": "bcaaff3d-da68-476f-9242-4aff076b677e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBSA class counts (lookup):\n",
            "cbsa_class\n",
            "Unknown    408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.PATCH-2 — Ensure 99999 is labeled as 'Outside' (not 'Unknown'), then rebuild mapped_by_year\n",
        "\n",
        "# (Re)build the class lookup (your robust R2 version):\n",
        "cbsa_class_lut = build_cbsa_class_lookup(list_new, list_old, mefi_long=mefi_long)\n",
        "\n",
        "mapped_by_year = {}\n",
        "for yr, p in BRFSS_FILES.items():\n",
        "    m = load_brfss_year(yr, p)   # uses patched normalize_cbsa_raw + map_2017/map_2022\n",
        "    m[\"cbsa_code_current\"] = pad_cbsa(m[\"cbsa_code_current\"])\n",
        "    m = m.merge(cbsa_class_lut, left_on=\"cbsa_code_current\", right_on=\"cbsa_code\", how=\"left\")\n",
        "    m.drop(columns=[\"cbsa_code\"], errors=\"ignore\", inplace=True)\n",
        "\n",
        "    # Explicitly mark Outside for 99999\n",
        "    m.loc[m[\"cbsa_code_current\"]==\"99999\", \"cbsa_class\"] = \"Outside\"\n",
        "    m[\"cbsa_class\"] = m[\"cbsa_class\"].fillna(\"Unknown\")\n",
        "\n",
        "    miss = m[\"cbsa_code_current\"].isna().mean()\n",
        "    n_outside = (m[\"cbsa_code_current\"]==\"99999\").sum()\n",
        "    print(f\"{yr}: cbsa_code_current missing ratio = {miss:.2%} | outside-CBSA rows (99999) = {n_outside:,}\")\n",
        "    mapped_by_year[yr] = m\n",
        "\n",
        "    # (keep your 3-col export)\n",
        "    (m[[\"state_fips\",\"county_fips\",\"cbsa_code_current\"]]\n",
        "      .dropna().drop_duplicates()\n",
        "      .to_csv(f\"{OUT}/county_to_cbsa_3col_{yr}.csv\", index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5qZMk9M3VVy",
        "outputId": "87047338-58c4-499a-e5cf-2c00a30290d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2007: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 20,058\n",
            "2008: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 19,112\n",
            "2012: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 25,788\n",
            "2017: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 61,072\n",
            "2022: cbsa_code_current missing ratio = 0.00% | outside-CBSA rows (99999) = 74,787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.RERUN — Attach using Metro-only in-scope, keep 99999 out of scope\n",
        "\n",
        "def attach_mefi_for_year_v2(brfss_df, survey_year, mefi_long, out_dir=OUT):\n",
        "    df = brfss_df.copy()\n",
        "    df[\"CBSA_CODE\"] = pad_cbsa(df[\"cbsa_code_current\"])\n",
        "    df[\"MEFI_YEAR\"] = {2007:2007, 2008:2007, 2012:2012, 2017:2017, 2022:2017}[survey_year]\n",
        "\n",
        "    # In-scope: Metropolitan only, excluding 99999 (MEFI is MSA-only)\n",
        "    in_scope = (df[\"CBSA_CODE\"] != \"99999\") & (df[\"cbsa_class\"] == \"Metropolitan\")\n",
        "\n",
        "    valid_set = set(mefi_long.loc[mefi_long[\"mefi_year\"]==df[\"MEFI_YEAR\"].iat[0], \"cbsa_code\"].unique())\n",
        "    df.loc[in_scope, \"in_mefi_universe\"] = df.loc[in_scope, \"CBSA_CODE\"].isin(valid_set)\n",
        "    print(f\"{survey_year}: MEFI {df['MEFI_YEAR'].iat[0]} universe coverage (METRO only) = {df.loc[in_scope, 'in_mefi_universe'].mean():.2%}\")\n",
        "\n",
        "    mefi_j = mefi_long.rename(columns={\"cbsa_code\":\"CBSA_CODE\",\"mefi_year\":\"MEFI_YEAR\"})\n",
        "    out = df.merge(mefi_j, on=[\"CBSA_CODE\",\"MEFI_YEAR\"], how=\"left\", validate=\"m:1\")\n",
        "\n",
        "    if \"mefi_overall\" in out.columns:\n",
        "        cov_scores = out.loc[in_scope, \"mefi_overall\"].notna().mean()\n",
        "        cov_pop    = out.loc[in_scope, \"mefi_population\"].notna().mean()\n",
        "        print(f\"{survey_year}: MEFI score coverage (METRO only) = {cov_scores:.2%} | population = {cov_pop:.2%}\")\n",
        "        assert cov_scores == 1.0, f\"{survey_year}: not 100% MEFI score coverage on METRO rows\"\n",
        "        assert cov_pop    == 1.0, f\"{survey_year}: not 100% MEFI population coverage on METRO rows\"\n",
        "\n",
        "    out_file = os.path.join(out_dir, f\"brfss_mefi_{survey_year}.csv\")\n",
        "    out.to_csv(out_file, index=False)\n",
        "    return out_file, out\n",
        "\n",
        "# Re-attach for all five years\n",
        "outputs = {}\n",
        "for yr, mdf in mapped_by_year.items():\n",
        "    outputs[yr] = attach_mefi_for_year_v2(mdf, yr, mefi_long)\n",
        "\n",
        "# Confirm the year mapping in outputs (shows 2008→2007, 2022→2017)\n",
        "pairs = []\n",
        "for yr, (_, df) in outputs.items():\n",
        "    pairs.append(df[[\"BRFSS_YEAR\",\"MEFI_YEAR\"]].drop_duplicates())\n",
        "print(\"\\nObserved (BRFSS_YEAR, MEFI_YEAR) pairs:\")\n",
        "print(pd.concat(pairs).drop_duplicates().sort_values([\"BRFSS_YEAR\",\"MEFI_YEAR\"]).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "XU78TTM83hZU",
        "outputId": "8143191e-58f8-4f3d-d7d3-317d5c1c2e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2007: MEFI 2007 universe coverage (METRO only) = nan%\n",
            "2007: MEFI score coverage (METRO only) = nan% | population = nan%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "2007: not 100% MEFI score coverage on METRO rows",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1078266086.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapped_by_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_mefi_for_year_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmefi_long\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Confirm the year mapping in outputs (shows 2008→2007, 2022→2017)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1078266086.py\u001b[0m in \u001b[0;36mattach_mefi_for_year_v2\u001b[0;34m(brfss_df, survey_year, mefi_long, out_dir)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcov_pop\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mefi_population\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{survey_year}: MEFI score coverage (METRO only) = {cov_scores:.2%} | population = {cov_pop:.2%}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mcov_scores\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{survey_year}: not 100% MEFI score coverage on METRO rows\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcov_pop\u001b[0m    \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{survey_year}: not 100% MEFI population coverage on METRO rows\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: 2007: not 100% MEFI score coverage on METRO rows"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep your patched map_2017 (RAW legacy → current first)\n",
        "def map_2017(df):\n",
        "    df = df.copy()\n",
        "    df[\"cbsa_from_det_raw\"] = df[\"cbsa_code_raw\"].map(det_map)\n",
        "    m = df.merge(\n",
        "        list_old.rename(columns={\"cbsa_code\":\"cbsa_legacy\"})[[\"state_fips\",\"county_fips\",\"cbsa_legacy\"]],\n",
        "        on=[\"state_fips\",\"county_fips\"], how=\"left\"\n",
        "    )\n",
        "    m[\"cbsa_from_det_legacy\"] = m[\"cbsa_legacy\"].map(det_map)\n",
        "    m = m.merge(\n",
        "        list_new.rename(columns={\"cbsa_code\":\"cbsa_from_county_current\"})[[\"state_fips\",\"county_fips\",\"cbsa_from_county_current\"]],\n",
        "        on=[\"state_fips\",\"county_fips\"], how=\"left\"\n",
        "    )\n",
        "    m[\"cbsa_code_current\"] = (\n",
        "        m[\"cbsa_from_det_raw\"]\n",
        "        .combine_first(m[\"cbsa_from_det_legacy\"])\n",
        "        .combine_first(m[\"cbsa_from_county_current\"])\n",
        "    )\n",
        "    # preserve 99999 from raw\n",
        "    m[\"cbsa_code_current\"] = m.apply(\n",
        "        lambda r: \"99999\" if (pd.notna(r[\"cbsa_code_raw\"]) and str(r[\"cbsa_code_raw\"])==\"99999\") else r[\"cbsa_code_current\"],\n",
        "        axis=1\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# Re-map all five BRFSS years and attach Metro/Micro class\n",
        "mapped_by_year = {}\n",
        "for yr, p in BRFSS_FILES.items():\n",
        "    m = load_brfss_year(yr, p)              # uses map_2017 above as needed\n",
        "    m[\"cbsa_code_current\"] = pad_cbsa(m[\"cbsa_code_current\"])\n",
        "    m = m.merge(cbsa_class_lut, left_on=\"cbsa_code_current\", right_on=\"cbsa_code\", how=\"left\")\n",
        "    m.drop(columns=[\"cbsa_code\"], errors=\"ignore\", inplace=True)\n",
        "    m[\"cbsa_class\"] = m[\"cbsa_class\"].fillna(\"Unknown\")\n",
        "    metro_share = np.mean((m[\"cbsa_code_current\"]!=\"99999\") & (m[\"cbsa_class\"]==\"Metropolitan\"))\n",
        "    print(f\"{yr}: rows={len(m):,} | 99999={int((m['cbsa_code_current']=='99999').sum()):,} | METRO share (non-99999)={metro_share:.2%}\")\n",
        "    mapped_by_year[yr] = m\n",
        "    # optional: keep your 3-col export\n",
        "    (m[[\"state_fips\",\"county_fips\",\"cbsa_code_current\"]]\n",
        "      .dropna().drop_duplicates()\n",
        "      .to_csv(f\"{OUT}/county_to_cbsa_3col_{yr}.csv\", index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6rwE2GKvtFc",
        "outputId": "53c34c95-0e80-4efc-84eb-5a7fcbd88054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2007: rows=222,499 | 99999=20,058 | METRO share (non-99999)=0.00%\n",
            "2008: rows=206,029 | 99999=19,112 | METRO share (non-99999)=0.00%\n",
            "2012: rows=223,988 | 99999=25,788 | METRO share (non-99999)=0.00%\n",
            "2017: rows=230,875 | 99999=0 | METRO share (non-99999)=0.00%\n",
            "2022: rows=237,730 | 99999=0 | METRO share (non-99999)=0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11 (R2) — Re-attach MEFI to BRFSS respondents using updated mefi_long\n",
        "\n",
        "outputs = {}\n",
        "for yr, mdf in mapped_by_year.items():\n",
        "    outputs[yr] = attach_mefi_for_year(mdf, yr, mefi_long)  # uses your existing function from Cell 11\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "TQKUfu0VvVbz",
        "outputId": "4eadedad-48dc-4c83-ddde-55ddbb2b5348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'attach_mefi_for_year' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2749567551.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapped_by_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_mefi_for_year\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmefi_long\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# uses your existing function from Cell 11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'attach_mefi_for_year' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Continued Experimentation for 2017, 2022 data\n"
      ],
      "metadata": {
        "id": "iispAb1XHyPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# P1 — Robust padding utils (no .str used)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _pad_any(series, width):\n",
        "    s = pd.Series(series)\n",
        "    def to_fixed(v):\n",
        "        if v is None or (isinstance(v, float) and np.isnan(v)):\n",
        "            return np.nan\n",
        "        try:\n",
        "            # Handle numbers safely (including '123.0')\n",
        "            iv = int(float(v))\n",
        "            return f\"{iv:0{width}d}\"\n",
        "        except Exception:\n",
        "            # Fall back to string\n",
        "            t = str(v).strip()\n",
        "            if t == \"\":\n",
        "                return np.nan\n",
        "            # common trailing \".0\"\n",
        "            if t.endswith(\".0\") and t[:-2].isdigit():\n",
        "                t = t[:-2]\n",
        "            return t.zfill(width)\n",
        "    return s.map(to_fixed)\n",
        "\n",
        "def pad_cbsa(s):   return _pad_any(s, 5)\n",
        "def pad_state(s):  return _pad_any(s, 2)\n",
        "def pad_county(s): return _pad_any(s, 3)\n",
        "\n",
        "def build_county_keys(df):\n",
        "    df = df.copy()\n",
        "    if \"COUNTY_FIPS\" in df.columns:\n",
        "        df[\"county_fips5\"] = _pad_any(df[\"COUNTY_FIPS\"], 5)\n",
        "    else:\n",
        "        # Fall back to _STATE + _CNTY if COUNTY_FIPS missing\n",
        "        df[\"county_fips5\"] = _pad_any(df[\"_STATE\"], 2) + _pad_any(df[\"_CNTY\"], 3)\n",
        "    # Safe slicing (after ensuring 5-char strings)\n",
        "    s = df[\"county_fips5\"].astype(str)\n",
        "    df[\"state_fips\"]  = s.str.slice(0, 2)\n",
        "    df[\"county_fips\"] = s.str.slice(2, 5)\n",
        "    return df\n",
        "\n",
        "def normalize_cbsa_raw(df):\n",
        "    df = df.copy()\n",
        "    # Prefer CBSA_CODE; else _MMSA (present for 2017/2022)\n",
        "    raw = df[\"CBSA_CODE\"] if \"CBSA_CODE\" in df.columns and df[\"CBSA_CODE\"].notna().any() \\\n",
        "          else (df[\"_MMSA\"] if \"_MMSA\" in df.columns else pd.Series([np.nan]*len(df)))\n",
        "    df[\"cbsa_code_raw\"] = pad_cbsa(raw)\n",
        "    # Respect explicit outside flag from either column\n",
        "    if \"_MMSA\" in df.columns:\n",
        "        df.loc[df[\"_MMSA\"].astype(str).str.strip()==\"99999\", \"cbsa_code_raw\"] = \"99999\"\n",
        "    if \"CBSA_CODE\" in df.columns:\n",
        "        df.loc[df[\"CBSA_CODE\"].astype(str).str.strip()==\"99999\", \"cbsa_code_raw\"] = \"99999\"\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "uVWoYpu8Hxxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load OMB lists and build a simple deterministic legacy→current map"
      ],
      "metadata": {
        "id": "vTox1nWa_3R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Load OMB lists and build a simple deterministic legacy→current map\n",
        "old_path = f\"{IN}/list1.xls\"          # 2013–2020 vintage\n",
        "new_path = f\"{IN}/list1_2023.xlsx\"     # 2023 vintage\n",
        "old = pd.read_excel(old_path, sheet_name=0, header=2, dtype=str)\n",
        "new = pd.read_excel(new_path, sheet_name=0, header=2, dtype=str)\n",
        "\n",
        "def tidy_omb(df):\n",
        "    df = df.copy()\n",
        "    ren = {}\n",
        "    for c in df.columns:\n",
        "        lc = str(c).strip().lower()\n",
        "        if lc.startswith(\"cbsa code\"): ren[c] = \"cbsa_code\"\n",
        "        if \"cbsa title\" in lc:         ren[c] = \"cbsa_title\"\n",
        "        if lc == \"fips state code\":    ren[c] = \"state_fips\"\n",
        "        if lc == \"fips county code\":   ren[c] = \"county_fips\"\n",
        "    df = df.rename(columns=ren)\n",
        "    if \"cbsa_code\"   in df.columns: df[\"cbsa_code\"] = pad_cbsa(df[\"cbsa_code\"])\n",
        "    if \"state_fips\"  in df.columns: df[\"state_fips\"] = pad_state(df[\"state_fips\"])\n",
        "    if \"county_fips\" in df.columns: df[\"county_fips\"] = pad_county(df[\"county_fips\"])\n",
        "    return df\n",
        "\n",
        "old = tidy_omb(old)\n",
        "new = tidy_omb(new)\n",
        "\n",
        "# county→CBSA (current & legacy)\n",
        "c2c_current = new[[\"state_fips\",\"county_fips\",\"cbsa_code\"]].dropna().drop_duplicates()\n",
        "c2c_current = c2c_current.rename(columns={\"cbsa_code\":\"cbsa_current\"})\n",
        "c2c_legacy  = old[[\"state_fips\",\"county_fips\",\"cbsa_code\"]].dropna().drop_duplicates()\n",
        "c2c_legacy  = c2c_legacy.rename(columns={\"cbsa_code\":\"cbsa_legacy\"})\n",
        "\n",
        "# deterministic legacy→current via county overlaps (majority vote)\n",
        "ovl = c2c_legacy.merge(c2c_current, on=[\"state_fips\",\"county_fips\"], how=\"inner\")\n",
        "votes = (ovl.groupby([\"cbsa_legacy\",\"cbsa_current\"]).size()\n",
        "           .reset_index(name=\"n\")\n",
        "           .sort_values([\"cbsa_legacy\",\"n\"], ascending=[True, False])\n",
        "           .groupby(\"cbsa_legacy\").head(1))\n",
        "det_map = dict(zip(votes[\"cbsa_legacy\"], votes[\"cbsa_current\"]))\n",
        "\n",
        "# add any one-off corrections you know about\n",
        "det_map.update({\n",
        "    \"17410\":\"17420\",   # Cleveland–Elyria (legacy → current)\n",
        "    \"19430\":\"19380\",   # Dayton (legacy → current)\n",
        "})\n",
        "print(\"det_map size:\", len(det_map))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE_v7qTkCTbM",
        "outputId": "894aac41-ffcc-4584-cb2e-8a9201139815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "det_map size: 903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # K3 — 2017: build the 4-column MSA key table\n",
        "\n",
        "IN = \"/content/drive/MyDrive/Saksham_MEFI\"\n",
        "OUT = \"/content/output\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "b17 = pd.read_csv(f\"{IN}/SMART_2017_individual.csv\", dtype=str, low_memory=False)\n",
        "b17 = build_county_keys(b17)\n",
        "b17 = normalize_cbsa_raw(b17)\n",
        "\n",
        "# Choose final current CBSA in simple order:\n",
        "# 1) raw mapped via det_map (handles legacy), else 2) county→current, else 3) 99999\n",
        "tmp = b17.merge(c2c_current, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "tmp[\"cbsa_code_current\"] = tmp[\"cbsa_code_raw\"].map(det_map)              # legacy→current if raw was legacy\n",
        "tmp[\"cbsa_code_current\"] = tmp[\"cbsa_code_current\"].fillna(tmp[\"cbsa_current\"])\n",
        "tmp[\"cbsa_code_current\"] = pad_cbsa(tmp[\"cbsa_code_current\"])\n",
        "# keep explicit outside flag\n",
        "tmp.loc[tmp[\"cbsa_code_raw\"].astype(str).str.strip()==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "# final fallback to outside\n",
        "tmp.loc[tmp[\"cbsa_code_current\"].isna(), \"cbsa_code_current\"] = \"99999\"\n",
        "\n",
        "msa_keys_2017 = (tmp[[\"county_fips5\",\"cbsa_code_raw\",\"cbsa_code_current\"]]\n",
        "                 .assign(mefi_year=2017)\n",
        "                 .drop_duplicates())\n",
        "\n",
        "msa_keys_2017.to_csv(f\"{OUT}/msa_keys_2017.csv\", index=False)\n",
        "\n",
        "print(msa_keys_2017.head(5))\n",
        "print(\"2017 keys — rows:\", len(msa_keys_2017),\n",
        "      \"| outside(99999):\", int((msa_keys_2017[\"cbsa_code_current\"]==\"99999\").sum()),\n",
        "      \"| missing current:\", int(msa_keys_2017[\"cbsa_code_current\"].isna().sum()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS9pzbJ4IBa_",
        "outputId": "704b45c7-c85a-41ae-bbc9-aef75474f253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      county_fips5 cbsa_code_raw cbsa_code_current  mefi_year\n",
            "0              NaN         10100             10100       2017\n",
            "512            NaN         10580             10580       2017\n",
            "1144           NaN         10740             10740       2017\n",
            "2798           NaN         10900             10900       2017\n",
            "3664           NaN         11260             11260       2017\n",
            "2017 keys — rows: 136 | outside(99999): 18 | missing current: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K4 — 2022: build the 4-column MSA key table\n",
        "\n",
        "b22 = pd.read_csv(f\"{IN}/SMART_2022_individual.csv\", dtype=str, low_memory=False)\n",
        "b22 = build_county_keys(b22)\n",
        "b22 = normalize_cbsa_raw(b22)\n",
        "\n",
        "tmp = b22.merge(c2c_current, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "# 2022 raw might already be current; if legacy, det_map fixes; else fall back to county→current\n",
        "tmp[\"cbsa_code_current\"] = tmp[\"cbsa_code_raw\"].map(det_map).fillna(tmp[\"cbsa_code_raw\"])\n",
        "tmp[\"cbsa_code_current\"] = tmp[\"cbsa_code_current\"].fillna(tmp[\"cbsa_current\"])\n",
        "tmp[\"cbsa_code_current\"] = pad_cbsa(tmp[\"cbsa_code_current\"])\n",
        "# keep explicit outside flag\n",
        "tmp.loc[tmp[\"cbsa_code_raw\"].astype(str).str.strip()==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "# final fallback to outside\n",
        "tmp.loc[tmp[\"cbsa_code_current\"].isna(), \"cbsa_code_current\"] = \"99999\"\n",
        "\n",
        "msa_keys_2022 = (tmp[[\"county_fips5\",\"cbsa_code_raw\",\"cbsa_code_current\"]]\n",
        "                 .assign(mefi_year=2017)   # per Phase‑1: 2022 uses MEFI 2017\n",
        "                 .drop_duplicates())\n",
        "\n",
        "msa_keys_2022.to_csv(f\"{OUT}/msa_keys_2022.csv\", index=False)\n",
        "\n",
        "print(msa_keys_2022.head(5))\n",
        "print(\"2022 keys — rows:\", len(msa_keys_2022),\n",
        "      \"| outside(99999):\", int((msa_keys_2022[\"cbsa_code_current\"]==\"99999\").sum()),\n",
        "      \"| missing current:\", int(msa_keys_2022[\"cbsa_code_current\"].isna().sum()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpxSBFdvIHXR",
        "outputId": "c481412f-891e-4722-f716-427d3587ef77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      county_fips5 cbsa_code_raw cbsa_code_current  mefi_year\n",
            "0              NaN         10100             10100       2017\n",
            "804            NaN         10380             10380       2017\n",
            "1308           NaN         10420             10420       2017\n",
            "2026           NaN         10580             10580       2017\n",
            "3084           NaN         10740             10740       2017\n",
            "2022 keys — rows: 131 | outside(99999): 0 | missing current: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K5 — Quick validation summary for the key tables\n",
        "\n",
        "def key_summary(df, label):\n",
        "    n = len(df)\n",
        "    n_out = int((df[\"cbsa_code_current\"]==\"99999\").sum())\n",
        "    n_miss = int(df[\"cbsa_code_current\"].isna().sum())\n",
        "    print(f\"{label}: rows={n:,} | outside(99999)={n_out:,} | missing_current={n_miss:,}\")\n",
        "\n",
        "key_summary(msa_keys_2017, \"2017 key\")\n",
        "key_summary(msa_keys_2022, \"2022 key\")\n",
        "print(\"Wrote:\", f\"{OUT}/msa_keys_2017.csv\", \"|\", f\"{OUT}/msa_keys_2022.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKU0vE9iIYZQ",
        "outputId": "41732ede-4a0b-4949-a4cf-8f95a5879976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017 key: rows=136 | outside(99999)=18 | missing_current=0\n",
            "2022 key: rows=131 | outside(99999)=0 | missing_current=0\n",
            "Wrote: /content/output/msa_keys_2017.csv | /content/output/msa_keys_2022.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique MSAs in 2017 (excluding outside)\n",
        "n_msas_2017 = (msa_keys_2017\n",
        "               .loc[msa_keys_2017[\"cbsa_code_current\"] != \"99999\", \"cbsa_code_current\"]\n",
        "               .nunique())\n",
        "print(\"2017 — unique MSAs (in sample):\", n_msas_2017)\n",
        "\n",
        "# Peek at the first 10 CBSA codes\n",
        "print(msa_keys_2017.loc[msa_keys_2017[\"cbsa_code_current\"] != \"99999\", \"cbsa_code_current\"]\n",
        "      .drop_duplicates().head(10).to_list())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8E0RiwFIcH_",
        "outputId": "cc276cb3-e755-4eb6-ce19-9afab11f7ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017 — unique MSAs (in sample): 118\n",
            "['10100', '10580', '10740', '10900', '11260', '12060', '12260', '12420', '12580', '12940']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique MSAs in 2022 (excluding outside)\n",
        "n_msas_2022 = (msa_keys_2022\n",
        "               .loc[msa_keys_2022[\"cbsa_code_current\"] != \"99999\", \"cbsa_code_current\"]\n",
        "               .nunique())\n",
        "print(\"2022 — unique MSAs (in sample):\", n_msas_2022)\n",
        "\n",
        "print(msa_keys_2022.loc[msa_keys_2022[\"cbsa_code_current\"] != \"99999\", \"cbsa_code_current\"]\n",
        "      .drop_duplicates().head(10).to_list())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI5yBM4-MIvb",
        "outputId": "991a83b6-0b3d-41f3-9e4f-6753ff06419c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022 — unique MSAs (in sample): 131\n",
            "['10100', '10380', '10420', '10580', '10740', '11260', '12060', '12260', '12420', '12580']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2017: one row per current CBSA, with an example raw code (for audit) and the mapped MEFI year\n",
        "msa_only_2017 = (msa_keys_2017\n",
        "                 .groupby(\"cbsa_code_current\", as_index=False)\n",
        "                 .agg(cbsa_code_raw_example=(\"cbsa_code_raw\", \"first\"))\n",
        "                 .assign(mefi_year=2017))\n",
        "\n",
        "# 2022: one row per current CBSA, mapped to MEFI 2017\n",
        "msa_only_2022 = (msa_keys_2022\n",
        "                 .groupby(\"cbsa_code_current\", as_index=False)\n",
        "                 .agg(cbsa_code_raw_example=(\"cbsa_code_raw\", \"first\"))\n",
        "                 .assign(mefi_year=2017))\n",
        "\n",
        "# Save (these are the minimal 3-column keys you can join on later)\n",
        "msa_only_2017.to_csv(f\"{OUT}/msa_only_keys_2017.csv\", index=False)\n",
        "msa_only_2022.to_csv(f\"{OUT}/msa_only_keys_2022.csv\", index=False)\n",
        "\n",
        "print(\"Rows (2017 MSA-only, excl. 99999):\",\n",
        "      (msa_only_2017[\"cbsa_code_current\"]!=\"99999\").sum())\n",
        "print(\"Rows (2022 MSA-only, excl. 99999):\",\n",
        "      (msa_only_2022[\"cbsa_code_current\"]!=\"99999\").sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGDtgUGYMPCc",
        "outputId": "2512fa3a-a38a-476e-d926-556275a73fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows (2017 MSA-only, excl. 99999): 118\n",
            "Rows (2022 MSA-only, excl. 99999): 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T1 — Helpers\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "IN = \"/content/drive/MyDrive/Saksham_MEFI\"   # adjust if your files live elsewhere\n",
        "\n",
        "def _pad_any(series, width):\n",
        "    s = pd.Series(series)\n",
        "    def to_fixed(v):\n",
        "        if v is None or (isinstance(v, float) and np.isnan(v)):\n",
        "            return np.nan\n",
        "        try:\n",
        "            iv = int(float(v))\n",
        "            return f\"{iv:0{width}d}\"\n",
        "        except Exception:\n",
        "            t = str(v).strip()\n",
        "            if t == \"\":\n",
        "                return np.nan\n",
        "            if t.endswith(\".0\") and t[:-2].isdigit():\n",
        "                t = t[:-2]\n",
        "            return t.zfill(width)\n",
        "    return s.map(to_fixed)\n",
        "\n",
        "def pad_cbsa(s):   return _pad_any(s, 5)\n",
        "def pad_state(s):  return _pad_any(s, 2)\n",
        "def pad_county(s): return _pad_any(s, 3)\n"
      ],
      "metadata": {
        "id": "e3v835v7MWlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T2 — Unique MMSA counts for 2017 & 2022\n",
        "paths = {\n",
        "    2017: f\"{IN}/SMART_2017_individual.csv\",\n",
        "    2022: f\"{IN}/SMART_2022_individual.csv\",\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for yr, p in paths.items():\n",
        "    df = pd.read_csv(p, dtype=str, low_memory=False)\n",
        "    # Prefer _MMSA; fall back to CBSA_CODE if _MMSA is not present\n",
        "    if \"_MMSA\" in df.columns:\n",
        "        raw = df[\"_MMSA\"]\n",
        "        label = \"_MMSA\"\n",
        "    elif \"CBSA_CODE\" in df.columns:\n",
        "        raw = df[\"CBSA_CODE\"]\n",
        "        label = \"CBSA_CODE\"\n",
        "    else:\n",
        "        rows.append({\"year\": yr, \"id_field\": \"(none)\", \"unique_ids\": 0,\n",
        "                     \"unique_ids_excl_99999\": 0, \"count_99999\": 0, \"missing_ids\": len(df)})\n",
        "        continue\n",
        "\n",
        "    s = pad_cbsa(raw)\n",
        "    s = s.where(s.notna() & (s.str.strip() != \"\"), np.nan)\n",
        "    n_total_nonnull = s.notna().sum()\n",
        "    n_unique = s.dropna().nunique()\n",
        "    n_99999 = (s == \"99999\").sum()\n",
        "    n_unique_excl_out = s[(s != \"99999\") & s.notna()].nunique()\n",
        "    n_missing = s.isna().sum()\n",
        "\n",
        "    rows.append({\n",
        "        \"year\": yr,\n",
        "        \"id_field\": label,\n",
        "        \"unique_ids\": int(n_unique),\n",
        "        \"unique_ids_excl_99999\": int(n_unique_excl_out),\n",
        "        \"count_99999\": int(n_99999),\n",
        "        \"missing_ids\": int(n_missing),\n",
        "        \"non_null_rows\": int(n_total_nonnull)\n",
        "    })\n",
        "\n",
        "mmsa_summary = pd.DataFrame(rows).sort_values(\"year\")\n",
        "mmsa_summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "rkXRfH3-OQAf",
        "outputId": "3bebae7d-2c0f-4116-e614-80ed0a6bca2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year id_field  unique_ids  unique_ids_excl_99999  count_99999  missing_ids  \\\n",
              "0  2017    _MMSA         136                    136            0            0   \n",
              "1  2022    _MMSA         131                    131            0            0   \n",
              "\n",
              "   non_null_rows  \n",
              "0         230875  \n",
              "1         237730  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce980c82-dba4-4220-9d67-0906d306df32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>id_field</th>\n",
              "      <th>unique_ids</th>\n",
              "      <th>unique_ids_excl_99999</th>\n",
              "      <th>count_99999</th>\n",
              "      <th>missing_ids</th>\n",
              "      <th>non_null_rows</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017</td>\n",
              "      <td>_MMSA</td>\n",
              "      <td>136</td>\n",
              "      <td>136</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>230875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022</td>\n",
              "      <td>_MMSA</td>\n",
              "      <td>131</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>237730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce980c82-dba4-4220-9d67-0906d306df32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce980c82-dba4-4220-9d67-0906d306df32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce980c82-dba4-4220-9d67-0906d306df32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-678a8867-5441-4dd9-ab47-43856043215e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-678a8867-5441-4dd9-ab47-43856043215e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-678a8867-5441-4dd9-ab47-43856043215e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_98250b27-b5f6-4516-aac1-3a70ab51bf4e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('mmsa_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_98250b27-b5f6-4516-aac1-3a70ab51bf4e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('mmsa_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mmsa_summary",
              "summary": "{\n  \"name\": \"mmsa_summary\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2017,\n        \"max\": 2022,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2022,\n          2017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_field\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"_MMSA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 131,\n        \"max\": 136,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          131\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_ids_excl_99999\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 131,\n        \"max\": 136,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          131\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_99999\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missing_ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"non_null_rows\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4847,\n        \"min\": 230875,\n        \"max\": 237730,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          237730\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# T3 — Unique county FIPS counts for 2007, 2008, 2012\n",
        "paths = {\n",
        "    2007: f\"{IN}/SMART_2007_individual.csv\",\n",
        "    2008: f\"{IN}/SMART_2008_individual.csv\",\n",
        "    2012: f\"{IN}/SMART_2012_individual.csv\",\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for yr, p in paths.items():\n",
        "    df = pd.read_csv(p, dtype=str, low_memory=False)\n",
        "    # Build 5-digit county FIPS from either COUNTY_FIPS or _STATE + _CNTY\n",
        "    if \"COUNTY_FIPS\" in df.columns:\n",
        "        county5 = _pad_any(df[\"COUNTY_FIPS\"], 5)\n",
        "    else:\n",
        "        county5 = pad_state(df[\"_STATE\"]) + pad_county(df[\"_CNTY\"])\n",
        "    county5 = county5.where(county5.notna() & (county5.str.strip() != \"\"), np.nan)\n",
        "\n",
        "    n_unique_counties = county5.dropna().nunique()\n",
        "    n_missing = county5.isna().sum()\n",
        "    rows.append({\n",
        "        \"year\": yr,\n",
        "        \"unique_counties\": int(n_unique_counties),\n",
        "        \"missing_county_ids\": int(n_missing),\n",
        "        \"rows\": len(df)\n",
        "    })\n",
        "\n",
        "county_summary = pd.DataFrame(rows).sort_values(\"year\")\n",
        "county_summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "NRUN9x5uOSXv",
        "outputId": "80d04b57-8985-409b-9871-f41aec3030fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year  unique_counties  missing_county_ids    rows\n",
              "0  2007              298                   0  222499\n",
              "1  2008              266                   0  206029\n",
              "2  2012              210                   0  223988"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33bb94f9-b890-4c0d-83a1-8e70711938b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>unique_counties</th>\n",
              "      <th>missing_county_ids</th>\n",
              "      <th>rows</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>222499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008</td>\n",
              "      <td>266</td>\n",
              "      <td>0</td>\n",
              "      <td>206029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012</td>\n",
              "      <td>210</td>\n",
              "      <td>0</td>\n",
              "      <td>223988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33bb94f9-b890-4c0d-83a1-8e70711938b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33bb94f9-b890-4c0d-83a1-8e70711938b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33bb94f9-b890-4c0d-83a1-8e70711938b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7714c437-8173-4020-88b5-9fb84d97cd15\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7714c437-8173-4020-88b5-9fb84d97cd15')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7714c437-8173-4020-88b5-9fb84d97cd15 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b8fec6aa-71f1-4909-9d39-480320ad6028\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('county_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b8fec6aa-71f1-4909-9d39-480320ad6028 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('county_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "county_summary",
              "summary": "{\n  \"name\": \"county_summary\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2007,\n        \"max\": 2012,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2007,\n          2008,\n          2012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_counties\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44,\n        \"min\": 210,\n        \"max\": 298,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          298,\n          266,\n          210\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missing_county_ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rows\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9966,\n        \"min\": 206029,\n        \"max\": 223988,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          222499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRFSS year, how many MSAs in your SMART sample do / don’t have a matching MEFI record (using the OMB crosswalks), and report simple match‑rate “scores” (1 = matched, 0 = not matched)."
      ],
      "metadata": {
        "id": "dIZtpM55ToX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# M1 — Helpers (safe with ints/floats/strings)\n",
        "import numpy as np, pandas as pd, os\n",
        "\n",
        "IN = \"/content/drive/MyDrive/Saksham_MEFI\"   # adjust if your files live elsewhere\n",
        "\n",
        "\n",
        "def _pad_any(series, width):\n",
        "    s = pd.Series(series)\n",
        "    def to_fixed(v):\n",
        "        if v is None or (isinstance(v, float) and np.isnan(v)):\n",
        "            return np.nan\n",
        "        try:\n",
        "            iv = int(float(v))\n",
        "            return f\"{iv:0{width}d}\"\n",
        "        except Exception:\n",
        "            t = str(v).strip()\n",
        "            if t == \"\":\n",
        "                return np.nan\n",
        "            if t.endswith(\".0\") and t[:-2].isdigit():\n",
        "                t = t[:-2]\n",
        "            return t.zfill(width)\n",
        "    return s.map(to_fixed)\n",
        "\n",
        "def pad_cbsa(s):   return _pad_any(s, 5)\n",
        "def pad_state(s):  return _pad_any(s, 2)\n",
        "def pad_county(s): return _pad_any(s, 3)\n",
        "\n",
        "def build_county_fips5(df):\n",
        "    if \"COUNTY_FIPS\" in df.columns:\n",
        "        return _pad_any(df[\"COUNTY_FIPS\"], 5)\n",
        "    else:\n",
        "        return pad_state(df[\"_STATE\"]) + pad_county(df[\"_CNTY\"])\n",
        "\n",
        "def get_raw_mmsa(df):\n",
        "    if \"_MMSA\" in df.columns:\n",
        "        s = pad_cbsa(df[\"_MMSA\"])\n",
        "    elif \"CBSA_CODE\" in df.columns:\n",
        "        s = pad_cbsa(df[\"CBSA_CODE\"])\n",
        "    else:\n",
        "        s = pd.Series([np.nan]*len(df))\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "0FZJeM3gOT-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OMB lists + crosswalks + deterministic legacy→current map"
      ],
      "metadata": {
        "id": "VOqlUUl6__o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# M2 — OMB lists + crosswalks + deterministic legacy→current map\n",
        "old_path = f\"{IN}/list1.xls\"          # 2013–2020 vintage you added\n",
        "new_path = f\"{IN}/list1_2023.xlsx\"     # 2023 OMB list\n",
        "old = pd.read_excel(old_path, sheet_name=0, header=2, dtype=str)\n",
        "new = pd.read_excel(new_path, sheet_name=0, header=2, dtype=str)\n",
        "\n",
        "def tidy_omb(df):\n",
        "    df = df.copy()\n",
        "    ren = {}\n",
        "    for c in df.columns:\n",
        "        lc = str(c).strip().lower()\n",
        "        if lc.startswith(\"cbsa code\"): ren[c] = \"cbsa_code\"\n",
        "        if \"cbsa title\" in lc:         ren[c] = \"cbsa_title\"\n",
        "        if lc == \"fips state code\":    ren[c] = \"state_fips\"\n",
        "        if lc == \"fips county code\":   ren[c] = \"county_fips\"\n",
        "        if \"metropolitan/micropolitan\" in lc: ren[c] = \"cbsa_class_raw\"\n",
        "    df = df.rename(columns=ren)\n",
        "    if \"cbsa_code\"   in df.columns: df[\"cbsa_code\"] = pad_cbsa(df[\"cbsa_code\"])\n",
        "    if \"state_fips\"  in df.columns: df[\"state_fips\"] = pad_state(df[\"state_fips\"])\n",
        "    if \"county_fips\" in df.columns: df[\"county_fips\"] = pad_county(df[\"county_fips\"])\n",
        "    return df\n",
        "\n",
        "old = tidy_omb(old)\n",
        "new = tidy_omb(new)\n",
        "\n",
        "# county → current CBSA (2023)\n",
        "c2c_current = (new[[\"state_fips\",\"county_fips\",\"cbsa_code\"]]\n",
        "               .dropna().drop_duplicates()\n",
        "               .rename(columns={\"cbsa_code\":\"cbsa_current\"}))\n",
        "\n",
        "# county → legacy CBSA (2013–2020)\n",
        "c2c_legacy = (old[[\"state_fips\",\"county_fips\",\"cbsa_code\"]]\n",
        "              .dropna().drop_duplicates()\n",
        "              .rename(columns={\"cbsa_code\":\"cbsa_legacy\"}))\n",
        "\n",
        "# deterministic legacy→current via county overlap (majority vote)\n",
        "ovl = c2c_legacy.merge(c2c_current, on=[\"state_fips\",\"county_fips\"], how=\"inner\")\n",
        "votes = (ovl.groupby([\"cbsa_legacy\",\"cbsa_current\"]).size()\n",
        "           .reset_index(name=\"n\")\n",
        "           .sort_values([\"cbsa_legacy\",\"n\"], ascending=[True, False])\n",
        "           .groupby(\"cbsa_legacy\").head(1))\n",
        "det_map = dict(zip(votes[\"cbsa_legacy\"], votes[\"cbsa_current\"]))\n",
        "\n",
        "# add known one-offs you already observed\n",
        "det_map.update({\n",
        "    \"17410\":\"17420\",   # Cleveland–Elyria\n",
        "    \"19430\":\"19380\",   # Dayton\n",
        "})\n",
        "print(\"det_map size:\", len(det_map))\n",
        "\n",
        "# CBSA class (Metropolitan vs Micropolitan) from title text\n",
        "def derive_class_from_title(s):\n",
        "    s = pd.Series(s, dtype=\"string\").str.lower()\n",
        "    out = pd.Series(index=s.index, dtype=\"string\")\n",
        "    out.loc[s.str.contains(\"micropolitan\", na=False)] = \"Micropolitan\"\n",
        "    out.loc[s.str.contains(\"metropolitan\", na=False) & ~s.str.contains(\"micropolitan\", na=False)] = \"Metropolitan\"\n",
        "    return out\n",
        "\n",
        "cbsa_class_lut = pd.concat([\n",
        "    new[[\"cbsa_code\",\"cbsa_title\"]].assign(cbsa_class=derive_class_from_title(new[\"cbsa_title\"]))[[\"cbsa_code\",\"cbsa_class\"]],\n",
        "    old[[\"cbsa_code\",\"cbsa_title\"]].assign(cbsa_class=derive_class_from_title(old[\"cbsa_title\"]))[[\"cbsa_code\",\"cbsa_class\"]],\n",
        "], ignore_index=True).dropna(subset=[\"cbsa_code\"]).drop_duplicates(\"cbsa_code\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZxntGwcTsNN",
        "outputId": "1cbb8bb3-4020-4e12-88eb-782ba9ae8ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "det_map size: 903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M3 — MEFI CBSA sets by release year (from 'scores' sheet)\n",
        "mefi_path = f\"{IN}/MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx\"\n",
        "scores = pd.read_excel(mefi_path, sheet_name=\"scores\", header=[0,1], dtype=str)\n",
        "\n",
        "# Find CBSA Code column\n",
        "id_col = None\n",
        "for c in scores.columns:\n",
        "    if isinstance(c, tuple) and c[1] == \"CBSA Code\":\n",
        "        id_col = c; break\n",
        "if id_col is None:\n",
        "    # fallback: any column that looks like 5-digit code\n",
        "    for c in scores.columns:\n",
        "        if scores[c].astype(str).str.fullmatch(r\"\\d{5}\").mean() > 0.3:\n",
        "            id_col = c; break\n",
        "\n",
        "codes = pad_cbsa(scores[id_col])\n",
        "\n",
        "def mefi_codes_for(year):\n",
        "    # a year is present if there are (Overall, year) columns (or any Area column for that year)\n",
        "    cols = [c for c in scores.columns if isinstance(c, tuple) and str(c[1]) == str(year)]\n",
        "    if not cols: return set()\n",
        "    return set(codes.dropna())\n",
        "\n",
        "mefi_sets = {y: mefi_codes_for(y) for y in (2007, 2012, 2017)}\n",
        "for y, s in mefi_sets.items():\n",
        "    print(f\"MEFI {y}: {len(s)} CBSAs in table\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86bHDRbATu18",
        "outputId": "5fc8710c-266c-435e-f0fb-f3558ad7ebe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEFI 2007: 383 CBSAs in table\n",
            "MEFI 2012: 383 CBSAs in table\n",
            "MEFI 2017: 383 CBSAs in table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# M4 — Map SMART rows to current CBSA codes using OMB crosswalks\n",
        "def map_brfss_to_cbsa_current(df, year):\n",
        "    df = df.copy()\n",
        "    # Outside-of-CBSA marker to keep out of coverage denominator\n",
        "    df[\"cbsa_code_raw\"] = get_raw_mmsa(df)\n",
        "    # 5-digit county key\n",
        "    county5 = build_county_fips5(df)\n",
        "    df[\"state_fips\"]  = county5.str[:2]\n",
        "    df[\"county_fips\"] = county5.str[2:]\n",
        "\n",
        "    if year in (2017, 2022):\n",
        "        # Try: raw may be current or legacy; map legacy via det_map; else county→current\n",
        "        df = df.merge(c2c_current, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "        mapped = df[\"cbsa_code_raw\"].map(det_map).fillna(df[\"cbsa_code_raw\"]).fillna(df[\"cbsa_current\"])\n",
        "    else:\n",
        "        # Older years: county→legacy then legacy→current; fallback county→current\n",
        "        df = df.merge(c2c_legacy,  on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "        df = df.merge(c2c_current, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "        mapped = df[\"cbsa_legacy\"].map(det_map).fillna(df[\"cbsa_current\"])\n",
        "\n",
        "    df[\"cbsa_code_current\"] = pad_cbsa(mapped)\n",
        "    # Respect explicit 99999 if present in raw\n",
        "    df.loc[df[\"cbsa_code_raw\"].astype(str).str.strip()==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "    # Final fallback: if still null, mark as outside\n",
        "    df.loc[df[\"cbsa_code_current\"].isna(), \"cbsa_code_current\"] = \"99999\"\n",
        "    return df[[\"cbsa_code_raw\",\"cbsa_code_current\",\"state_fips\",\"county_fips\"]]\n"
      ],
      "metadata": {
        "id": "yWno94s3T4RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def coerce_state_county_keys(df):\n",
        "    \"\"\"Return a copy with string-padded state_fips (2) and county_fips (3).\"\"\"\n",
        "    out = df.copy()\n",
        "    out[\"state_fips\"]  = pad_state(out[\"state_fips\"])\n",
        "    out[\"county_fips\"] = pad_county(out[\"county_fips\"])\n",
        "    return out\n",
        "\n",
        "def split_and_pad_state_county(county5_series):\n",
        "    \"\"\"Pad county5 to 5 chars, then slice to state(2)/county(3) as strings.\"\"\"\n",
        "    s = _pad_any(county5_series, 5)\n",
        "    state  = s.map(lambda v: v[:2] if isinstance(v, str) else np.nan)\n",
        "    county = s.map(lambda v: v[2:] if isinstance(v, str) else np.nan)\n",
        "    # ensure final padding/dtypes\n",
        "    return pad_state(state), pad_county(county)\n"
      ],
      "metadata": {
        "id": "aa1Po9PLdzfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# M5.PATCH-1 — robust mapper: avoid .str, handle ints/floats/strings safely\n",
        "# M5 — For each BRFSS year, compute match (1) / no match (0) vs the mapped MEFI year\n",
        "\n",
        "BRFSS_FILES = {\n",
        "    2007: f\"{IN}/SMART_2007_individual.csv\",\n",
        "    2008: f\"{IN}/SMART_2008_individual.csv\",\n",
        "    2012: f\"{IN}/SMART_2012_individual.csv\",\n",
        "    2017: f\"{IN}/SMART_2017_individual.csv\",\n",
        "    2022: f\"{IN}/SMART_2022_individual.csv\",\n",
        "}\n",
        "\n",
        "YEAR_MAP = {2007:2007, 2008:2007, 2012:2012, 2017:2017, 2022:2017}  # Phase‑1 mapping\n",
        "summary_rows = []\n",
        "unmatched_examples = {}\n",
        "\n",
        "for yr, path in BRFSS_FILES.items():\n",
        "    df = pd.read_csv(path, dtype=str, low_memory=False)\n",
        "    keys = map_brfss_to_cbsa_current(df, yr)\n",
        "    keys[\"cbsa_code_current\"] = pad_cbsa(keys[\"cbsa_code_current\"])\n",
        "\n",
        "    # Unique MSAs in sample (exclude 99999)\n",
        "    msas = (keys.loc[keys[\"cbsa_code_current\"]!=\"99999\", [\"cbsa_code_current\"]]\n",
        "                 .drop_duplicates().rename(columns={\"cbsa_code_current\":\"CBSA\"}))\n",
        "    n_unique_all = len(msas)\n",
        "\n",
        "    # Attach class (Metropolitan/Micropolitan) for the MSA-only view\n",
        "    msas = msas.merge(cbsa_class_lut, left_on=\"CBSA\", right_on=\"cbsa_code\", how=\"left\").drop(columns=[\"cbsa_code\"])\n",
        "    msas[\"cbsa_class\"] = msas[\"cbsa_class\"].fillna(\"Unknown\")\n",
        "\n",
        "    # Identify MEFI universe for this mapped year\n",
        "    my = YEAR_MAP[yr]\n",
        "    mefi_universe = mefi_sets.get(my, set())\n",
        "\n",
        "    msas[\"in_mefi\"] = msas[\"CBSA\"].isin(mefi_universe)\n",
        "    # All CBSAs (excl. 99999)\n",
        "    unmatched_all = msas.loc[~msas[\"in_mefi\"], \"CBSA\"].tolist()\n",
        "    # MSA-only\n",
        "    msas_metro = msas.loc[msas[\"cbsa_class\"]==\"Metropolitan\"].copy()\n",
        "    unmatched_metro = msas_metro.loc[~msas_metro[\"in_mefi\"], \"CBSA\"].tolist()\n",
        "\n",
        "    # Respondent-weighted view (per row, excl. 99999)\n",
        "    keys_nonout = keys.loc[keys[\"cbsa_code_current\"]!=\"99999\"].copy()\n",
        "    keys_nonout[\"in_mefi\"] = keys_nonout[\"cbsa_code_current\"].isin(mefi_universe)\n",
        "    resp_match_rate_all = keys_nonout[\"in_mefi\"].mean() if len(keys_nonout) else np.nan\n",
        "    # MSA-only respondent-weighted\n",
        "    keys_nonout = keys_nonout.merge(cbsa_class_lut, left_on=\"cbsa_code_current\", right_on=\"cbsa_code\", how=\"left\")\n",
        "    resp_match_rate_metro = keys_nonout.loc[keys_nonout[\"cbsa_class\"]==\"Metropolitan\", \"in_mefi\"].mean()\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"brfss_year\": yr,\n",
        "        \"mefi_year\": my,\n",
        "        \"unique_msas_all\": n_unique_all,\n",
        "        \"unique_msas_metro\": int((msas[\"cbsa_class\"]==\"Metropolitan\").sum()),\n",
        "        \"unmatched_msas_all\": len(unmatched_all),\n",
        "        \"unmatched_msas_metro\": len(unmatched_metro),\n",
        "        \"match_rate_all (MSA-unweighted)\": round(msas[\"in_mefi\"].mean()*100, 2) if len(msas) else np.nan,\n",
        "        \"match_rate_metro (MSA-unweighted)\": round(msas_metro[\"in_mefi\"].mean()*100, 2) if len(msas_metro) else np.nan,\n",
        "        \"match_rate_all (respondent-weighted)\": round(resp_match_rate_all*100, 2) if pd.notna(resp_match_rate_all) else np.nan,\n",
        "        \"match_rate_metro (respondent-weighted)\": round(resp_match_rate_metro*100, 2) if pd.notna(resp_match_rate_metro) else np.nan,\n",
        "    })\n",
        "\n",
        "    # keep a few examples (human friendly)\n",
        "    unmatched_examples[yr] = {\n",
        "        \"all\": unmatched_all[:10],\n",
        "        \"metro\": unmatched_metro[:10]\n",
        "    }\n",
        "\n",
        "coverage_summary = pd.DataFrame(summary_rows).sort_values([\"brfss_year\"])\n",
        "coverage_summary\n",
        "\n",
        "def _split_state_county_from5(county5_series):\n",
        "    \"\"\"\n",
        "    Ensure 5-digit strings, then slice to (state_fips, county_fips) without using .str on non-strings.\n",
        "    \"\"\"\n",
        "    s = _pad_any(county5_series, 5)  # returns strings or NaN\n",
        "    state = s.map(lambda v: v[:2] if isinstance(v, str) else np.nan)\n",
        "    county = s.map(lambda v: v[2:] if isinstance(v, str) else np.nan)\n",
        "    return state, county\n",
        "\n",
        "def map_brfss_to_cbsa_current(df, year):\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1) Raw MSA code (MMSA or CBSA_CODE) padded to 5; keep '99999'\n",
        "    df[\"cbsa_code_raw\"] = get_raw_mmsa(df)\n",
        "\n",
        "    # 2) Build 5-digit county key and split to state/county; FORCE strings\n",
        "    county5 = build_county_fips5(df)  # already robust padding\n",
        "    df[\"state_fips\"], df[\"county_fips\"] = split_and_pad_state_county(county5)\n",
        "\n",
        "    # 3) FORCE rhs keys to strings too (prevents float64/object mismatch)\n",
        "    _c2c_curr = coerce_state_county_keys(c2c_current)\n",
        "    _c2c_lega = coerce_state_county_keys(c2c_legacy)\n",
        "\n",
        "    # 4) Map to CURRENT CBSA\n",
        "    if year in (2017, 2022):\n",
        "        # raw may be current or legacy; map legacy via det_map; else county→current\n",
        "        df = df.merge(_c2c_curr, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "        mapped = (\n",
        "            df[\"cbsa_code_raw\"].map(det_map)   # legacy→current if raw legacy\n",
        "              .fillna(df[\"cbsa_code_raw\"])     # else keep raw (already current)\n",
        "              .fillna(df[\"cbsa_current\"])      # else county→current\n",
        "        )\n",
        "    else:\n",
        "        # older years: county→legacy then legacy→current; fallback county→current\n",
        "        df = df.merge(_c2c_lega, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "        df = df.merge(_c2c_curr, on=[\"state_fips\",\"county_fips\"], how=\"left\")\n",
        "        mapped = df[\"cbsa_legacy\"].map(det_map).fillna(df[\"cbsa_current\"])\n",
        "\n",
        "    # 5) Finalize current CBSA; preserve explicit 99999; last-resort 99999\n",
        "    df[\"cbsa_code_current\"] = pad_cbsa(mapped)\n",
        "    df.loc[df[\"cbsa_code_raw\"].astype(str).str.strip()==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "    df.loc[df[\"cbsa_code_current\"].isna(), \"cbsa_code_current\"] = \"99999\"\n",
        "\n",
        "    return df[[\"cbsa_code_raw\",\"cbsa_code_current\",\"state_fips\",\"county_fips\"]]\n"
      ],
      "metadata": {
        "id": "NcoLtDXnT9s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# M6 — Show a few unmatched CBSA codes (all vs Metropolitan-only)\n",
        "for yr in sorted(unmatched_examples):\n",
        "    print(f\"\\nYear {yr} (→ MEFI {YEAR_MAP[yr]}):\")\n",
        "    print(\"  Unmatched (all, first 10):       \", unmatched_examples[yr][\"all\"])\n",
        "    print(\"  Unmatched (Metropolitan, first 10):\", unmatched_examples[yr][\"metro\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TPw6rmxUCFw",
        "outputId": "f2553434-6738-4f53-fe77-14730753dc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Year 2007 (→ MEFI 2007):\n",
            "  Unmatched (all, first 10):        ['11200', '17410', '19430']\n",
            "  Unmatched (Metropolitan, first 10): []\n",
            "\n",
            "Year 2008 (→ MEFI 2007):\n",
            "  Unmatched (all, first 10):        ['11200', '14580', '33500', '17410', '19430']\n",
            "  Unmatched (Metropolitan, first 10): []\n",
            "\n",
            "Year 2012 (→ MEFI 2012):\n",
            "  Unmatched (all, first 10):        ['11200', '17410', '19430', '41980']\n",
            "  Unmatched (Metropolitan, first 10): []\n",
            "\n",
            "Year 2017 (→ MEFI 2017):\n",
            "  Unmatched (all, first 10):        ['10100', '14454', '15764', '15804', '30150', '17410', '19124', '19430', '23104', '33500']\n",
            "  Unmatched (Metropolitan, first 10): []\n",
            "\n",
            "Year 2022 (→ MEFI 2017):\n",
            "  Unmatched (all, first 10):        ['10100', '10380', '14454', '15764', '15804', '17410', '19124', '23104', '23224', '25740']\n",
            "  Unmatched (Metropolitan, first 10): []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INT-1 — Helpers to coerce to pandas nullable int (Int64)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def to_int64(s):\n",
        "    \"\"\"Coerce to pandas nullable integer Int64 (handles '', None, NaN).\"\"\"\n",
        "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "def split_state_county_int(county5_series):\n",
        "    \"\"\"\n",
        "    Given a 5-digit county FIPS (any type), return (state_fips_int, county_fips_int) as Int64.\n",
        "    Works even if input is string/float/int/missing.\n",
        "    \"\"\"\n",
        "    n = pd.to_numeric(county5_series, errors=\"coerce\").astype(\"Int64\")\n",
        "    state  = (n // 1000).astype(\"Int64\")   # first two digits\n",
        "    county = (n % 1000).astype(\"Int64\")    # last three digits\n",
        "    return state, county\n"
      ],
      "metadata": {
        "id": "YcvLOCJ5UD70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INT-2 — Integer-typed crosswalks\n",
        "c2c_current_int = c2c_current.copy()\n",
        "c2c_current_int[\"state_fips\"]  = to_int64(c2c_current_int[\"state_fips\"])\n",
        "c2c_current_int[\"county_fips\"] = to_int64(c2c_current_int[\"county_fips\"])\n",
        "\n",
        "c2c_legacy_int = c2c_legacy.copy()\n",
        "c2c_legacy_int[\"state_fips\"]  = to_int64(c2c_legacy_int[\"state_fips\"])\n",
        "c2c_legacy_int[\"county_fips\"] = to_int64(c2c_legacy_int[\"county_fips\"])\n",
        "\n",
        "# (Optional) sanity\n",
        "print(\"c2c_current_int dtypes:\", c2c_current_int[[\"state_fips\",\"county_fips\"]].dtypes.to_dict())\n",
        "print(\"c2c_legacy_int  dtypes:\", c2c_legacy_int[[\"state_fips\",\"county_fips\"]].dtypes.to_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldo9tK17GFyv",
        "outputId": "55f07a72-2af5-44c7-b2f9-ba9c5d85ddf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c2c_current_int dtypes: {'state_fips': Int64Dtype(), 'county_fips': Int64Dtype()}\n",
            "c2c_legacy_int  dtypes: {'state_fips': Int64Dtype(), 'county_fips': Int64Dtype()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_brfss_to_cbsa_current(df, year):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Raw MSA code for the row (MMSA or CBSA_CODE), keep as 5-char string; preserve '99999'\n",
        "    def get_raw_mmsa(_df):\n",
        "        if \"_MMSA\" in _df.columns:\n",
        "            base = _df[\"_MMSA\"]\n",
        "        elif \"CBSA_CODE\" in _df.columns:\n",
        "            base = _df[\"CBSA_CODE\"]\n",
        "        else:\n",
        "            base = pd.Series([np.nan]*len(_df))\n",
        "        # pad to 5, but strings are fine (we keep CBSA identifiers as strings)\n",
        "        s = base.astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
        "        s = s.mask(s.isin([\"\", \"nan\", \"NaN\", \"None\"]))\n",
        "        return s.str.zfill(5)\n",
        "\n",
        "    df[\"cbsa_code_raw\"] = get_raw_mmsa(df)\n",
        "\n",
        "    # Build county_fips5 and split **to integers**\n",
        "    if \"COUNTY_FIPS\" in df.columns:\n",
        "        county5 = df[\"COUNTY_FIPS\"]\n",
        "    else:\n",
        "        # fall back to _STATE + _CNTY\n",
        "        county5 = (df[\"_STATE\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip().str.zfill(2) +\n",
        "                   df[\"_CNTY\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip().str.zfill(3))\n",
        "    df[\"state_fips\"], df[\"county_fips\"] = split_state_county_int(county5)\n",
        "\n",
        "    # Choose which RHS crosswalk to use (both sides are Int64 now)\n",
        "    if year in (2017, 2022):\n",
        "        rhs = c2c_current_int\n",
        "        df = df.merge(rhs, on=[\"state_fips\",\"county_fips\"], how=\"left\", validate=\"m:1\")\n",
        "        # raw may be legacy; det_map converts legacy→current; else keep raw (already current); else county→current\n",
        "        mapped = (df[\"cbsa_code_raw\"].map(det_map).fillna(df[\"cbsa_code_raw\"]).fillna(df[\"cbsa_current\"]))\n",
        "    else:\n",
        "        rhsL = c2c_legacy_int\n",
        "        rhsC = c2c_current_int\n",
        "        df = df.merge(rhsL, on=[\"state_fips\",\"county_fips\"], how=\"left\", validate=\"m:1\")\n",
        "        df = df.merge(rhsC, on=[\"state_fips\",\"county_fips\"], how=\"left\", validate=\"m:1\", suffixes=(\"_legacy\",\"_current\"))\n",
        "        mapped = df[\"cbsa_legacy\"].map(det_map).fillna(df[\"cbsa_current\"])\n",
        "\n",
        "    # Finalize current CBSA as 5-char string; preserve explicit 99999; last-resort set to 99999\n",
        "    df[\"cbsa_code_current\"] = mapped.astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip().str.zfill(5)\n",
        "    df.loc[df[\"cbsa_code_raw\"]==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "    df.loc[df[\"cbsa_code_current\"].isin([\"\", \"nan\", \"NaN\", \"None\"]), \"cbsa_code_current\"] = \"99999\"\n",
        "\n",
        "    return df[[\"cbsa_code_raw\",\"cbsa_code_current\",\"state_fips\",\"county_fips\"]]\n"
      ],
      "metadata": {
        "id": "cVCqxQmUGHl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P-1 — MD (Metropolitan Division) → parent CBSA mapping from both OMB lists\n",
        "\n",
        "def build_md_to_cbsa_map(df):\n",
        "    # Try to locate the two columns under common header variants\n",
        "    cols = {c.strip().lower(): c for c in df.columns}\n",
        "    md_col   = None\n",
        "    cbsa_col = None\n",
        "    for k,c in cols.items():\n",
        "        if k.startswith(\"metropolitan division code\"): md_col = c\n",
        "        if k.startswith(\"cbsa code\"): cbsa_col = c\n",
        "    if md_col is None or cbsa_col is None:\n",
        "        return {}\n",
        "    md = (pd.DataFrame({\"md\": df[md_col].astype(str).str.replace(r\"\\.0$\",\"\",regex=True).str.zfill(5),\n",
        "                        \"cbsa\": df[cbsa_col].astype(str).str.replace(r\"\\.0$\",\"\",regex=True).str.zfill(5)})\n",
        "          .dropna().drop_duplicates())\n",
        "    md = md[(md[\"md\"] != \"\") & (md[\"cbsa\"] != \"\")]\n",
        "    return dict(zip(md[\"md\"], md[\"cbsa\"]))\n",
        "\n",
        "md2cbsa = {}\n",
        "md2cbsa.update(build_md_to_cbsa_map(old))  # 2013–2020 list\n",
        "md2cbsa.update(build_md_to_cbsa_map(new))  # 2023 list\n",
        "\n",
        "print(\"Metropolitan Division codes mapped → parent CBSA:\", len(md2cbsa))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZGNsxRAGKqU",
        "outputId": "6a45802a-4ccd-48f9-b6e6-acb628d4ef24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metropolitan Division codes mapped → parent CBSA: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P-2 — Robust mapper: raw legacy→current for ALL years, then county crosswalk, then MD→CBSA, then 99999\n",
        "\n",
        "def map_brfss_to_cbsa_current(df, year):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Raw MSA code (MMSA or CBSA_CODE) as 5-char string; keep '99999'\n",
        "    if \"_MMSA\" in df.columns:\n",
        "        base = df[\"_MMSA\"]\n",
        "    elif \"CBSA_CODE\" in df.columns:\n",
        "        base = df[\"CBSA_CODE\"]\n",
        "    else:\n",
        "        base = pd.Series([np.nan]*len(df))\n",
        "    df[\"cbsa_code_raw\"] = base.astype(str).str.replace(r\"\\.0$\",\"\",regex=True).str.strip()\n",
        "    df[\"cbsa_code_raw\"] = df[\"cbsa_code_raw\"].mask(df[\"cbsa_code_raw\"].isin([\"\",\"nan\",\"NaN\",\"None\"]))\n",
        "    df[\"cbsa_code_raw\"] = df[\"cbsa_code_raw\"].str.zfill(5)\n",
        "\n",
        "    # Split county FIPS to Int64 keys\n",
        "    if \"COUNTY_FIPS\" in df.columns:\n",
        "        county5 = df[\"COUNTY_FIPS\"]\n",
        "    else:\n",
        "        county5 = (df[\"_STATE\"].astype(str).str.replace(r\"\\.0$\",\"\",regex=True).str.strip().str.zfill(2) +\n",
        "                   df[\"_CNTY\"].astype(str).str.replace(r\"\\.0$\",\"\",regex=True).str.strip().str.zfill(3))\n",
        "    n = pd.to_numeric(county5, errors=\"coerce\").astype(\"Int64\")\n",
        "    df[\"state_fips\"]  = (n // 1000).astype(\"Int64\")\n",
        "    df[\"county_fips\"] = (n % 1000).astype(\"Int64\")\n",
        "\n",
        "    # Prepare RHS crosswalks as Int64\n",
        "    c2c_curr = c2c_current.copy()\n",
        "    c2c_curr[\"state_fips\"]  = pd.to_numeric(c2c_curr[\"state_fips\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    c2c_curr[\"county_fips\"] = pd.to_numeric(c2c_curr[\"county_fips\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    c2c_lega = c2c_legacy.copy()\n",
        "    c2c_lega[\"state_fips\"]  = pd.to_numeric(c2c_lega[\"state_fips\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    c2c_lega[\"county_fips\"] = pd.to_numeric(c2c_lega[\"county_fips\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # 1) Start with RAW: legacy→current (det_map) or keep raw if already current\n",
        "    raw_mapped = df[\"cbsa_code_raw\"].map(det_map).fillna(df[\"cbsa_code_raw\"])\n",
        "\n",
        "    # 2) County-based mapping\n",
        "    if year in (2017, 2022):\n",
        "        df = df.merge(c2c_curr, on=[\"state_fips\",\"county_fips\"], how=\"left\", validate=\"m:1\")\n",
        "        county_guess = df[\"cbsa_current\"]\n",
        "    else:\n",
        "        df = df.merge(c2c_lega, on=[\"state_fips\",\"county_fips\"], how=\"left\", validate=\"m:1\")\n",
        "        df = df.merge(c2c_curr, on=[\"state_fips\",\"county_fips\"], how=\"left\", validate=\"m:1\", suffixes=(\"_legacy\",\"_current\"))\n",
        "        county_guess = df[\"cbsa_legacy\"].map(det_map).fillna(df[\"cbsa_current\"])\n",
        "\n",
        "    # 3) Choose best: raw_mapped → county_guess\n",
        "    chosen = raw_mapped.fillna(county_guess)\n",
        "\n",
        "    # 4) Collapse Metropolitan Division codes → parent CBSA (if present)\n",
        "    chosen = chosen.map(lambda c: md2cbsa.get(str(c).zfill(5), str(c).zfill(5)) if pd.notna(c) else np.nan)\n",
        "\n",
        "    # 5) Finalize: 5-char; preserve raw 99999; last-resort 99999\n",
        "    df[\"cbsa_code_current\"] = chosen.astype(str).str.replace(r\"\\.0$\",\"\",regex=True).str.zfill(5)\n",
        "    df.loc[df[\"cbsa_code_raw\"]==\"99999\", \"cbsa_code_current\"] = \"99999\"\n",
        "    df.loc[df[\"cbsa_code_current\"].isin([\"\", \"nan\", \"NaN\", \"None\"]), \"cbsa_code_current\"] = \"99999\"\n",
        "\n",
        "    return df[[\"cbsa_code_raw\",\"cbsa_code_current\",\"state_fips\",\"county_fips\"]]\n"
      ],
      "metadata": {
        "id": "EraL_h5pIXgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C1 — Setup & helpers\n",
        "import os, numpy as np, pandas as pd\n",
        "IN = \"/content/drive/MyDrive/Saksham_MEFI\"\n",
        "OUT = \"/content/output\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "def _pad_any(series, width):\n",
        "    s = pd.Series(series)\n",
        "    def to_fixed(v):\n",
        "        if v is None or (isinstance(v, float) and np.isnan(v)): return np.nan\n",
        "        try:\n",
        "            iv = int(float(v))\n",
        "            return f\"{iv:0{width}d}\"\n",
        "        except Exception:\n",
        "            t = str(v).strip()\n",
        "            if t == \"\": return np.nan\n",
        "            if t.endswith(\".0\") and t[:-2].isdigit(): t = t[:-2]\n",
        "            return t.zfill(width)\n",
        "    return s.map(to_fixed)\n",
        "\n",
        "def pad_cbsa(s):   return _pad_any(s, 5)\n",
        "def pad_state(s):  return _pad_any(s, 2)\n",
        "def pad_county(s): return _pad_any(s, 3)\n",
        "\n",
        "def build_county_keys(df):\n",
        "    df = df.copy()\n",
        "    if \"COUNTY_FIPS\" in df.columns:\n",
        "        df[\"county_fips5\"] = _pad_any(df[\"COUNTY_FIPS\"], 5)\n",
        "    else:\n",
        "        df[\"county_fips5\"] = pad_state(df[\"_STATE\"]) + pad_county(df[\"_CNTY\"])\n",
        "    return df\n",
        "\n",
        "def normalize_cbsa_raw(df):\n",
        "    df = df.copy()\n",
        "    if \"CBSA_CODE\" in df.columns and df[\"CBSA_CODE\"].notna().any():\n",
        "        raw = df[\"CBSA_CODE\"]\n",
        "    elif \"_MMSA\" in df.columns:\n",
        "        raw = df[\"_MMSA\"]\n",
        "    else:\n",
        "        raw = pd.Series([np.nan]*len(df))\n",
        "    df[\"cbsa_code_raw\"] = pad_cbsa(raw)\n",
        "    # carry outside flag\n",
        "    if \"_MMSA\" in df.columns:  df.loc[df[\"_MMSA\"].astype(str).str.strip()==\"99999\", \"cbsa_code_raw\"] = \"99999\"\n",
        "    if \"CBSA_CODE\" in df.columns: df.loc[df[\"CBSA_CODE\"].astype(str).str.strip()==\"99999\", \"cbsa_code_raw\"] = \"99999\"\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "sUq2KtWQIZ2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C2 — Load key tables for 2017 & 2022\n",
        "keys17_path = f\"{OUT}/msa_keys_2017.csv\"\n",
        "keys22_path = f\"{OUT}/msa_keys_2022.csv\"\n",
        "\n",
        "msa_keys_2017 = pd.read_csv(keys17_path, dtype=str)\n",
        "msa_keys_2022 = pd.read_csv(keys22_path, dtype=str)\n",
        "\n",
        "for df in (msa_keys_2017, msa_keys_2022):\n",
        "    df[\"county_fips5\"] = _pad_any(df[\"county_fips5\"], 5)\n",
        "    df[\"cbsa_code_raw\"] = pad_cbsa(df[\"cbsa_code_raw\"])\n",
        "    df[\"cbsa_code_current\"] = pad_cbsa(df[\"cbsa_code_current\"])\n",
        "    df[\"mefi_year\"] = pd.to_numeric(df[\"mefi_year\"], errors=\"coerce\").astype(\"Int64\")\n"
      ],
      "metadata": {
        "id": "g3OMRRiHIc92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C3 — Load MEFI 2017 (tidy long for joining)\n",
        "mefi_xlsx = f\"{IN}/MEFI+2022+dataset+for+researchers,+1-5-23 (4).xlsx\"\n",
        "\n",
        "def load_mefi_2017(mefi_path):\n",
        "    # Core scores from \"scores (panel)\" or fallback to \"scores\" wide\n",
        "    try:\n",
        "        panel = pd.read_excel(mefi_path, sheet_name=\"scores (panel)\", dtype=str)\n",
        "        c_cbsa = [c for c in panel.columns if \"CBSA Code\" in str(c)][0]\n",
        "        c_year = [c for c in panel.columns if str(c).strip().lower()==\"year\"][0]\n",
        "        c_ov   = [c for c in panel.columns if \"overall\" in str(c).lower()][0]\n",
        "        a1     = [c for c in panel.columns if \"area 1\" in str(c).lower()][0]\n",
        "        a2     = [c for c in panel.columns if \"area 2\" in str(c).lower()][0]\n",
        "        a3     = [c for c in panel.columns if \"area 3\" in str(c).lower()][0]\n",
        "        core = (panel[[c_cbsa, c_year, c_ov, a1, a2, a3]].copy())\n",
        "        core.columns = [\"cbsa_code\",\"mefi_year\",\"mefi_overall\",\"mefi_area1\",\"mefi_area2\",\"mefi_area3\"]\n",
        "        core = core[core[\"mefi_year\"].astype(str)==\"2017\"].copy()\n",
        "        core[\"cbsa_code\"] = pad_cbsa(core[\"cbsa_code\"])\n",
        "        core[\"mefi_year\"] = 2017\n",
        "    except Exception:\n",
        "        wide = pd.read_excel(mefi_path, sheet_name=\"scores\", header=[0,1], dtype=str)\n",
        "        id_col = None\n",
        "        for c in wide.columns:\n",
        "            if isinstance(c, tuple) and c[1]==\"CBSA Code\": id_col=c; break\n",
        "        if id_col is None:\n",
        "            for c in wide.columns:\n",
        "                if wide[c].astype(str).str.fullmatch(r\"\\d{5}\").mean()>0.3: id_col=c; break\n",
        "        core = pd.DataFrame({\n",
        "            \"cbsa_code\": pad_cbsa(wide[id_col]),\n",
        "            \"mefi_year\": 2017,\n",
        "            \"mefi_overall\": pd.to_numeric(wide[(\"Overall\", 2017)], errors=\"coerce\"),\n",
        "            \"mefi_area1\":  pd.to_numeric(wide[(\"Area 1: Government Spending\", 2017)], errors=\"coerce\"),\n",
        "            \"mefi_area2\":  pd.to_numeric(wide[(\"Area 2: Taxes\", 2017)], errors=\"coerce\"),\n",
        "            \"mefi_area3\":  pd.to_numeric(wide[(\"Area 3: Labor Market Regulation\", 2017)], errors=\"coerce\"),\n",
        "        })\n",
        "\n",
        "    # Sub-areas 1A..3C (from per-sheet tables)\n",
        "    sub_parts = []\n",
        "    for sub in [\"1A\",\"1B\",\"1C\",\"2A\",\"2B\",\"2C\",\"3A\",\"3B\",\"3C\"]:\n",
        "        try:\n",
        "            df = pd.read_excel(mefi_path, sheet_name=sub, header=[0,1], dtype=str)\n",
        "            metro_cols = [c for c in df.columns if isinstance(c, tuple) and c[1]==\"Metro Area\"]\n",
        "            score_col  = [c for c in df.columns if isinstance(c, tuple) and c[0].startswith(f\"{sub} (score)\") and c[1]==2017]\n",
        "            if not metro_cols or not score_col: continue\n",
        "            tmp = pd.DataFrame({\n",
        "                \"metro_area\": df[metro_cols[0]],\n",
        "                \"value\": pd.to_numeric(df[score_col[0]], errors=\"coerce\")\n",
        "            })\n",
        "\n",
        "            # map Metro Area name → CBSA Code using both lists you loaded earlier\n",
        "            list_old = pd.read_excel(f\"{IN}/list1.xlsx\", sheet_name=0, header=2, dtype=str)\n",
        "            list_new = pd.read_excel(f\"{IN}/list1_2023.xlsx\", sheet_name=0, header=2, dtype=str)\n",
        "            for d in (list_old, list_new):\n",
        "                d.rename(columns={c:\"cbsa_code\" for c in d.columns if str(c).strip().lower().startswith(\"cbsa code\")}, inplace=True)\n",
        "                d.rename(columns={c:\"cbsa_title\" for c in d.columns if \"cbsa title\" in str(c).strip().lower()}, inplace=True)\n",
        "                if \"cbsa_code\" in d.columns: d[\"cbsa_code\"]=pad_cbsa(d[\"cbsa_code\"])\n",
        "            names = pd.concat([\n",
        "                list_new[[\"cbsa_code\",\"cbsa_title\"]].rename(columns={\"cbsa_title\":\"metro_area\"}),\n",
        "                list_old[[\"cbsa_code\",\"cbsa_title\"]].rename(columns={\"cbsa_title\":\"metro_area\"})\n",
        "            ], ignore_index=True).dropna().drop_duplicates()\n",
        "            tmp = tmp.merge(names, on=\"metro_area\", how=\"left\").dropna(subset=[\"cbsa_code\"])\n",
        "            tmp[\"mefi_year\"] = 2017\n",
        "            tmp[\"metric\"] = f\"mefi_{sub.lower()}\"\n",
        "            sub_parts.append(tmp[[\"cbsa_code\",\"mefi_year\",\"metric\",\"value\"]])\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    sub_long = pd.concat(sub_parts, ignore_index=True) if sub_parts else pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\",\"metric\",\"value\"])\n",
        "    sub_wide = (sub_long.pivot_table(index=[\"cbsa_code\",\"mefi_year\"], columns=\"metric\", values=\"value\", aggfunc=\"first\")\n",
        "                         .reset_index())\n",
        "\n",
        "    # Population (prefer 'scores' sheet 2017 population column)\n",
        "    pop = pd.DataFrame(columns=[\"cbsa_code\",\"mefi_year\",\"mefi_population\"])\n",
        "    try:\n",
        "        wide = pd.read_excel(mefi_path, sheet_name=\"scores\", header=[0,1], dtype=str)\n",
        "        id_col = None\n",
        "        for c in wide.columns:\n",
        "            if isinstance(c, tuple) and c[1]==\"CBSA Code\": id_col=c; break\n",
        "        if id_col is None:\n",
        "            for c in wide.columns:\n",
        "                if wide[c].astype(str).str.fullmatch(r\"\\d{5}\").mean()>0.3: id_col=c; break\n",
        "        pop_cols = [c for c in wide.columns if isinstance(c, tuple) and \"population\" in str(c[1]).lower()]\n",
        "        sel = None\n",
        "        for c in pop_cols:\n",
        "            if str(c[1]).split()[0] == \"2017\": sel=c; break\n",
        "        if sel is not None:\n",
        "            pop = pd.DataFrame({\n",
        "                \"cbsa_code\": pad_cbsa(wide[id_col]),\n",
        "                \"mefi_year\": 2017,\n",
        "                \"mefi_population\": pd.to_numeric(wide[sel], errors=\"coerce\")\n",
        "            })\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    out = core.merge(sub_wide, on=[\"cbsa_code\",\"mefi_year\"], how=\"left\")\n",
        "    if not pop.empty:\n",
        "        out = out.merge(pop, on=[\"cbsa_code\",\"mefi_year\"], how=\"left\")\n",
        "    assert not out.duplicated([\"cbsa_code\",\"mefi_year\"]).any()\n",
        "    return out\n",
        "\n",
        "mefi_2017_long = load_mefi_2017(mefi_xlsx)\n",
        "print(mefi_2017_long.shape, mefi_2017_long.columns.tolist()[:12])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mfMgqZFv4fZ",
        "outputId": "471f7a7a-9cbc-4cb9-8446-1ef7ba6f93e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(383, 7) ['cbsa_code', 'mefi_year', 'mefi_overall', 'mefi_area1', 'mefi_area2', 'mefi_area3', 'mefi_population']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C4 — 2017 merge\n",
        "b17 = pd.read_csv(f\"{IN}/SMART_2017_individual.csv\", dtype=str, low_memory=False)\n",
        "b17 = build_county_keys(b17)\n",
        "b17 = normalize_cbsa_raw(b17)\n",
        "\n",
        "# Attach current CBSA + MEFI year using your key table\n",
        "b17 = b17.merge(msa_keys_2017, on=[\"county_fips5\",\"cbsa_code_raw\"], how=\"left\", validate=\"m:1\")\n",
        "# Define join keys\n",
        "b17[\"CBSA_CODE\"] = pad_cbsa(b17[\"cbsa_code_current\"])\n",
        "b17[\"MEFI_YEAR\"] = b17[\"mefi_year\"].astype(\"Int64\")\n",
        "\n",
        "# Join MEFI (2017) on (CBSA_CODE, MEFI_YEAR)\n",
        "mefi_j = mefi_2017_long.rename(columns={\"cbsa_code\":\"CBSA_CODE\",\"mefi_year\":\"MEFI_YEAR\"})\n",
        "enrich17 = b17.merge(mefi_j, on=[\"CBSA_CODE\",\"MEFI_YEAR\"], how=\"left\", validate=\"m:1\")\n",
        "\n",
        "# Optional: suffix MEFI columns with _2017 for clarity\n",
        "mefi_cols = [c for c in mefi_j.columns if c not in (\"CBSA_CODE\",\"MEFI_YEAR\")]\n",
        "ren = {c: f\"{c}_2017\" for c in mefi_cols}\n",
        "enrich17 = b17.merge(mefi_j.rename(columns=ren), left_on=[\"CBSA_CODE\",\"MEFI_YEAR\"], right_on=[\"CBSA_CODE\",\"MEFI_YEAR\"], how=\"left\", validate=\"m:1\")\n",
        "\n",
        "# QA: coverage on non-99999 rows\n",
        "mask_in = enrich17[\"CBSA_CODE\"]!=\"99999\"\n",
        "cov = enrich17.loc[mask_in, \"mefi_overall_2017\"].notna().mean()\n",
        "print(f\"2017 coverage on in-scope rows: {cov:.2%} (expected 100%)\")\n",
        "\n",
        "# Export\n",
        "p17 = f\"{OUT}/brfss_mefi_2017.csv\"\n",
        "enrich17.to_csv(p17, index=False)\n",
        "print(\"Wrote:\", p17)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P49wlLuAv6cH",
        "outputId": "24b41079-9b83-4850-a92c-cf5061404d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017 coverage on in-scope rows: 94.57% (expected 100%)\n",
            "Wrote: /content/output/brfss_mefi_2017.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C5 — 2022 merge\n",
        "b22 = pd.read_csv(f\"{IN}/SMART_2022_individual.csv\", dtype=str, low_memory=False)\n",
        "b22 = build_county_keys(b22)\n",
        "b22 = normalize_cbsa_raw(b22)\n",
        "\n",
        "# Attach current CBSA + MEFI year using your key table (2022 maps to MEFI 2017)\n",
        "b22 = b22.merge(msa_keys_2022, on=[\"county_fips5\",\"cbsa_code_raw\"], how=\"left\", validate=\"m:1\")\n",
        "b22[\"CBSA_CODE\"] = pad_cbsa(b22[\"cbsa_code_current\"])\n",
        "b22[\"MEFI_YEAR\"] = b22[\"mefi_year\"].astype(\"Int64\")  # should be 2017 per keys\n",
        "\n",
        "# Reuse mefi_j with 2017 metrics (already suffixed in C4)\n",
        "enrich22 = b22.merge(mefi_j.rename(columns=ren), on=[\"CBSA_CODE\",\"MEFI_YEAR\"], how=\"left\", validate=\"m:1\")\n",
        "\n",
        "# QA: coverage on non-99999 rows\n",
        "mask_in = enrich22[\"CBSA_CODE\"]!=\"99999\"\n",
        "cov = enrich22.loc[mask_in, \"mefi_overall_2017\"].notna().mean()\n",
        "print(f\"2022 coverage on in-scope rows: {cov:.2%} (expected 100%)\")\n",
        "\n",
        "# Export\n",
        "p22 = f\"{OUT}/brfss_mefi_2022.csv\"\n",
        "enrich22.to_csv(p22, index=False)\n",
        "print(\"Wrote:\", p22)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWe1gSb-wGw1",
        "outputId": "88f4ef36-df02-4923-e3f7-530b10ded7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022 coverage on in-scope rows: 71.67% (expected 100%)\n",
            "Wrote: /content/output/brfss_mefi_2022.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# C6 — QA recap (row invariance + nulls on 99999 only)\n",
        "def qa(enriched, year):\n",
        "    n_in = len(enriched)\n",
        "    n_mefi = enriched[[c for c in enriched.columns if c.startswith(\"mefi_overall_\")]].notna().sum().iloc[0]\n",
        "    non_out = enriched[\"CBSA_CODE\"]!=\"99999\"\n",
        "    mefi_non_out = enriched.loc[non_out, [c for c in enriched.columns if c.startswith(\"mefi_overall_\")]].notna().sum().iloc[0]\n",
        "    print(f\"{year}: rows={n_in:,} | rows with MEFI overall (all rows)={n_mefi:,} | (non-99999 only)={mefi_non_out:,}\")\n",
        "\n",
        "qa(enrich17, 2017)\n",
        "qa(enrich22, 2022)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2PvemE7wLu7",
        "outputId": "2869459b-59b3-4985-9301-441b2d67153e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017: rows=230,875 | rows with MEFI overall (all rows)=172,194 | (non-99999 only)=172,194\n",
            "2022: rows=237,730 | rows with MEFI overall (all rows)=170,390 | (non-99999 only)=170,390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2007-2013 data was mapped in normal way vs 2017-2022 data needed to have special changes made to them in order to roll them over from legacy mappings to current mapping, various steps had been taken for this"
      ],
      "metadata": {
        "id": "GOG50HOAALW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking if this is the thing that is needed\n"
      ],
      "metadata": {
        "id": "yZ-NZh7_1hRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p17 = f\"{OUT}/brfss_mefi_2017.csv\"\n",
        "p22 = f\"{OUT}/brfss_mefi_2022.csv\"\n",
        "\n",
        "e17 = pd.read_csv(p17, dtype=str, low_memory=False)\n",
        "e22 = pd.read_csv(p22, dtype=str, low_memory=False)\n",
        "\n",
        "# Anchor column: the overall score is mandatory in MEFI 2017\n",
        "ANCHOR = \"mefi_overall_2017\"\n",
        "\n",
        "# Normalize CBSA_CODE just in case (strip/pad)\n",
        "def zfill5(s):\n",
        "    s = s.astype(str).str.replace(r\"\\.0$\", \"\", regex=True).str.strip()\n",
        "    s = s.mask(s.isin([\"\", \"nan\", \"NaN\", \"None\"]))\n",
        "    return s.str.zfill(5)\n",
        "\n",
        "for df in (e17, e22):\n",
        "    df[\"CBSA_CODE\"] = zfill5(df[\"CBSA_CODE\"])"
      ],
      "metadata": {
        "id": "Ws0sMfqmxpXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V2 — 2017: prove blanks == 99999 and only 99999\n",
        "is_out = e17[\"CBSA_CODE\"] == \"99999\"\n",
        "is_null = e17[ANCHOR].isna()\n",
        "\n",
        "print(\"2017 confusion table (rows):\")\n",
        "print(pd.crosstab(is_out.rename(\"CBSA=99999\"), is_null.rename(\"MEFI_overall_2017 is NULL\")))\n",
        "\n",
        "# Hard assertions\n",
        "bad1 = (~is_out) & is_null      # non-99999 but MEFI null → should NOT exist\n",
        "bad2 = ( is_out) & (~is_null)   # 99999 but MEFI non-null → should NOT exist\n",
        "assert bad1.sum() == 0, f\"Found {bad1.sum()} rows where CBSA_CODE != '99999' but MEFI is NULL.\"\n",
        "assert bad2.sum() == 0, f\"Found {bad2.sum()} rows where CBSA_CODE == '99999' but MEFI is NOT NULL.\"\n",
        "\n",
        "print(\"✅ 2017 OK: All MEFI blanks are exactly CBSA=99999, and all CBSA=99999 rows have blank MEFI.\")\n"
      ],
      "metadata": {
        "id": "2ucv57fO1nLJ",
        "outputId": "ac7e21bc-4788-479a-e187-15c3ce8f7aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017 confusion table (rows):\n",
            "MEFI_overall_2017 is NULL   False  True \n",
            "CBSA=99999                              \n",
            "False                      172194   9882\n",
            "True                            0  48799\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Found 9882 rows where CBSA_CODE != '99999' but MEFI is NULL.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3946520314.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbad1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mis_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mis_null\u001b[0m      \u001b[0;31m# non-99999 but MEFI null → should NOT exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbad2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mis_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mis_null\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 99999 but MEFI non-null → should NOT exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mbad1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Found {bad1.sum()} rows where CBSA_CODE != '99999' but MEFI is NULL.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mbad2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Found {bad2.sum()} rows where CBSA_CODE == '99999' but MEFI is NOT NULL.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Found 9882 rows where CBSA_CODE != '99999' but MEFI is NULL."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaMkbJiK1qJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}